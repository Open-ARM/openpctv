diff --git a/configure.ac b/configure.ac
index 03f1bca..fc7d372 100644
--- a/configure.ac
+++ b/configure.ac
@@ -527,6 +527,9 @@ if test "x$enable_asm" = xyes; then
     esac
 fi
 
+AC_CHECK_HEADER([xlocale.h], [DEFINES="$DEFINES -DHAVE_XLOCALE_H"])
+AC_CHECK_FUNC([strtof], [DEFINES="$DEFINES -DHAVE_STRTOF"])
+
 dnl Check to see if dlopen is in default libraries (like Solaris, which
 dnl has it in libc), or if libdl is needed to get it.
 AC_CHECK_FUNC([dlopen], [DEFINES="$DEFINES -DHAVE_DLOPEN"],
@@ -1970,7 +1973,7 @@ if test -n "$with_gallium_drivers"; then
 fi
 
 dnl Set LLVM_LIBS - This is done after the driver configuration so
-dnl that drivers can add additonal components to LLVM_COMPONENTS.
+dnl that drivers can add additional components to LLVM_COMPONENTS.
 dnl Previously, gallium drivers were updating LLVM_LIBS directly
 dnl by calling llvm-config --libs ${DRIVER_LLVM_COMPONENTS}, but
 dnl this was causing the same libraries to be appear multiple times
@@ -2003,11 +2006,16 @@ if test "x$MESA_LLVM" != x0; then
 	invocation and rebuild.])])
 
            dnl We don't need to update LLVM_LIBS in this case because the LLVM
-           dnl install uses a shared object for each compoenent and we have
+           dnl install uses a shared object for each component and we have
            dnl already added all of these objects to LLVM_LIBS.
         fi
     else
-        AC_MSG_WARN([Building mesa with staticly linked LLVM may cause compilation issues])
+        AC_MSG_WARN([Building mesa with statically linked LLVM may cause compilation issues])
+        dnl We need to link to llvm system libs when using static libs
+        dnl However, only llvm 3.5+ provides --system-libs
+        if test $LLVM_VERSION_MAJOR -eq 3 -a $LLVM_VERSION_MINOR -ge 5; then
+            LLVM_LIBS="$LLVM_LIBS `$LLVM_CONFIG --system-libs`"
+        fi
     fi
 fi
 
diff --git a/docs/GL3.txt b/docs/GL3.txt
index 6a988d5..2854431 100644
--- a/docs/GL3.txt
+++ b/docs/GL3.txt
@@ -98,8 +98,8 @@ GL 4.0, GLSL 4.00:
   GL_ARB_draw_indirect                                 DONE (i965, nvc0, radeonsi, llvmpipe, softpipe)
   GL_ARB_gpu_shader5                                   DONE (i965, nvc0)
   - 'precise' qualifier                                DONE
-  - Dynamically uniform sampler array indices          DONE ()
-  - Dynamically uniform UBO array indices              DONE ()
+  - Dynamically uniform sampler array indices          DONE (r600)
+  - Dynamically uniform UBO array indices              DONE (r600)
   - Implicit signed -> unsigned conversions            DONE
   - Fused multiply-add                                 DONE ()
   - Packing/bitfield/conversion functions              DONE (r600)
@@ -107,7 +107,7 @@ GL 4.0, GLSL 4.00:
   - Geometry shader instancing                         DONE (r600)
   - Geometry shader multiple streams                   DONE ()
   - Enhanced per-sample shading                        DONE (r600)
-  - Interpolation functions                            DONE ()
+  - Interpolation functions                            DONE (r600)
   - New overload resolution rules                      DONE
   GL_ARB_gpu_shader_fp64                               started (Dave)
   GL_ARB_sample_shading                                DONE (i965, nv50, nvc0, r600, radeonsi)
@@ -188,14 +188,14 @@ GL 4.5, GLSL 4.50:
 
   GL_ARB_ES3_1_compatibility                           not started
   GL_ARB_clip_control                                  DONE (llvmpipe, softpipe, r300, r600, radeonsi)
-  GL_ARB_conditional_render_inverted                   DONE (i965, nvc0, llvmpipe, softpipe)
+  GL_ARB_conditional_render_inverted                   DONE (i965, nv50, nvc0, llvmpipe, softpipe)
   GL_ARB_cull_distance                                 not started
   GL_ARB_derivative_control                            DONE (i965, nv50, nvc0, r600)
   GL_ARB_direct_state_access                           not started
   GL_ARB_get_texture_sub_image                         started (Brian Paul)
   GL_ARB_shader_texture_image_samples                  not started
   GL_ARB_texture_barrier                               DONE (nv50, nvc0, r300, r600, radeonsi)
-  GL_KHR_context_flush_control                         not started
+  GL_KHR_context_flush_control                         DONE (all - but needs GLX/EXT extension to be useful)
   GL_KHR_robust_buffer_access_behavior                 not started
   GL_KHR_robustness                                    90% done (the ARB variant)
 
diff --git a/docs/relnotes/10.4.html b/docs/relnotes/10.4.html
index 67c3087..d0fbd3b 100644
--- a/docs/relnotes/10.4.html
+++ b/docs/relnotes/10.4.html
@@ -44,9 +44,11 @@ Note: some of the new features are only available with certain drivers.
 </p>
 
 <ul>
+<li>GL_ARB_conditional_render_inverted on nv50</li>
 <li>GL_ARB_sample_shading on r600</li>
 <li>GL_ARB_texture_view on nv50, nvc0</li>
 <li>GL_ARB_clip_control on llvmpipe, softpipe, r300, r600, radeonsi</li>
+<li>GL_KHR_context_flush_control on all drivers</li>
 </ul>
 
 
diff --git a/include/GLES2/gl2ext.h b/include/GLES2/gl2ext.h
index a5e3f47..2b67c6e 100644
--- a/include/GLES2/gl2ext.h
+++ b/include/GLES2/gl2ext.h
@@ -33,14 +33,14 @@ extern "C" {
 ** used to make the header, and the header can be found at
 **   http://www.opengl.org/registry/
 **
-** Khronos $Revision: 25922 $ on $Date: 2014-03-17 03:54:32 -0700 (Mon, 17 Mar 2014) $
+** Khronos $Revision: 28335 $ on $Date: 2014-09-26 18:55:45 -0700 (Fri, 26 Sep 2014) $
 */
 
 #ifndef GL_APIENTRYP
 #define GL_APIENTRYP GL_APIENTRY*
 #endif
 
-/* Generated on date 20140317 */
+/* Generated on date 20140926 */
 
 /* Generated C header for:
  * API: gles2
@@ -54,7 +54,6 @@ extern "C" {
 
 #ifndef GL_KHR_blend_equation_advanced
 #define GL_KHR_blend_equation_advanced 1
-#define GL_BLEND_ADVANCED_COHERENT_KHR    0x9285
 #define GL_MULTIPLY_KHR                   0x9294
 #define GL_SCREEN_KHR                     0x9295
 #define GL_OVERLAY_KHR                    0x9296
@@ -76,6 +75,17 @@ GL_APICALL void GL_APIENTRY glBlendBarrierKHR (void);
 #endif
 #endif /* GL_KHR_blend_equation_advanced */
 
+#ifndef GL_KHR_blend_equation_advanced_coherent
+#define GL_KHR_blend_equation_advanced_coherent 1
+#define GL_BLEND_ADVANCED_COHERENT_KHR    0x9285
+#endif /* GL_KHR_blend_equation_advanced_coherent */
+
+#ifndef GL_KHR_context_flush_control
+#define GL_KHR_context_flush_control 1
+#define GL_CONTEXT_RELEASE_BEHAVIOR_KHR   0x82FB
+#define GL_CONTEXT_RELEASE_BEHAVIOR_FLUSH_KHR 0x82FC
+#endif /* GL_KHR_context_flush_control */
+
 #ifndef GL_KHR_debug
 #define GL_KHR_debug 1
 typedef void (GL_APIENTRY  *GLDEBUGPROCKHR)(GLenum source,GLenum type,GLuint id,GLenum severity,GLsizei length,const GLchar *message,const void *userParam);
@@ -145,6 +155,34 @@ GL_APICALL void GL_APIENTRY glGetPointervKHR (GLenum pname, void **params);
 #endif
 #endif /* GL_KHR_debug */
 
+#ifndef GL_KHR_robust_buffer_access_behavior
+#define GL_KHR_robust_buffer_access_behavior 1
+#endif /* GL_KHR_robust_buffer_access_behavior */
+
+#ifndef GL_KHR_robustness
+#define GL_KHR_robustness 1
+#define GL_CONTEXT_ROBUST_ACCESS_KHR      0x90F3
+#define GL_LOSE_CONTEXT_ON_RESET_KHR      0x8252
+#define GL_GUILTY_CONTEXT_RESET_KHR       0x8253
+#define GL_INNOCENT_CONTEXT_RESET_KHR     0x8254
+#define GL_UNKNOWN_CONTEXT_RESET_KHR      0x8255
+#define GL_RESET_NOTIFICATION_STRATEGY_KHR 0x8256
+#define GL_NO_RESET_NOTIFICATION_KHR      0x8261
+#define GL_CONTEXT_LOST_KHR               0x0507
+typedef GLenum (GL_APIENTRYP PFNGLGETGRAPHICSRESETSTATUSKHRPROC) (void);
+typedef void (GL_APIENTRYP PFNGLREADNPIXELSKHRPROC) (GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type, GLsizei bufSize, void *data);
+typedef void (GL_APIENTRYP PFNGLGETNUNIFORMFVKHRPROC) (GLuint program, GLint location, GLsizei bufSize, GLfloat *params);
+typedef void (GL_APIENTRYP PFNGLGETNUNIFORMIVKHRPROC) (GLuint program, GLint location, GLsizei bufSize, GLint *params);
+typedef void (GL_APIENTRYP PFNGLGETNUNIFORMUIVKHRPROC) (GLuint program, GLint location, GLsizei bufSize, GLuint *params);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL GLenum GL_APIENTRY glGetGraphicsResetStatusKHR (void);
+GL_APICALL void GL_APIENTRY glReadnPixelsKHR (GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type, GLsizei bufSize, void *data);
+GL_APICALL void GL_APIENTRY glGetnUniformfvKHR (GLuint program, GLint location, GLsizei bufSize, GLfloat *params);
+GL_APICALL void GL_APIENTRY glGetnUniformivKHR (GLuint program, GLint location, GLsizei bufSize, GLint *params);
+GL_APICALL void GL_APIENTRY glGetnUniformuivKHR (GLuint program, GLint location, GLsizei bufSize, GLuint *params);
+#endif
+#endif /* GL_KHR_robustness */
+
 #ifndef GL_KHR_texture_compression_astc_hdr
 #define GL_KHR_texture_compression_astc_hdr 1
 #define GL_COMPRESSED_RGBA_ASTC_4x4_KHR   0x93B0
@@ -200,6 +238,10 @@ GL_APICALL void GL_APIENTRY glEGLImageTargetRenderbufferStorageOES (GLenum targe
 #define GL_SAMPLER_EXTERNAL_OES           0x8D66
 #endif /* GL_OES_EGL_image_external */
 
+#ifndef GL_OES_compressed_ETC1_RGB8_sub_texture
+#define GL_OES_compressed_ETC1_RGB8_sub_texture 1
+#endif /* GL_OES_compressed_ETC1_RGB8_sub_texture */
+
 #ifndef GL_OES_compressed_ETC1_RGB8_texture
 #define GL_OES_compressed_ETC1_RGB8_texture 1
 #define GL_ETC1_RGB8_OES                  0x8D64
@@ -512,6 +554,10 @@ GL_APICALL void GL_APIENTRY glGetPerfMonitorCounterDataAMD (GLuint monitor, GLen
 #define GL_Z400_BINARY_AMD                0x8740
 #endif /* GL_AMD_program_binary_Z400 */
 
+#ifndef GL_ANDROID_extension_pack_es31a
+#define GL_ANDROID_extension_pack_es31a 1
+#endif /* GL_ANDROID_extension_pack_es31a */
+
 #ifndef GL_ANGLE_depth_texture
 #define GL_ANGLE_depth_texture 1
 #endif /* GL_ANGLE_depth_texture */
@@ -587,6 +633,23 @@ GL_APICALL void GL_APIENTRY glGetTranslatedShaderSourceANGLE (GLuint shader, GLs
 #endif
 #endif /* GL_ANGLE_translated_shader_source */
 
+#ifndef GL_APPLE_clip_distance
+#define GL_APPLE_clip_distance 1
+#define GL_MAX_CLIP_DISTANCES_APPLE       0x0D32
+#define GL_CLIP_DISTANCE0_APPLE           0x3000
+#define GL_CLIP_DISTANCE1_APPLE           0x3001
+#define GL_CLIP_DISTANCE2_APPLE           0x3002
+#define GL_CLIP_DISTANCE3_APPLE           0x3003
+#define GL_CLIP_DISTANCE4_APPLE           0x3004
+#define GL_CLIP_DISTANCE5_APPLE           0x3005
+#define GL_CLIP_DISTANCE6_APPLE           0x3006
+#define GL_CLIP_DISTANCE7_APPLE           0x3007
+#endif /* GL_APPLE_clip_distance */
+
+#ifndef GL_APPLE_color_buffer_packed_float
+#define GL_APPLE_color_buffer_packed_float 1
+#endif /* GL_APPLE_color_buffer_packed_float */
+
 #ifndef GL_APPLE_copy_texture_levels
 #define GL_APPLE_copy_texture_levels 1
 typedef void (GL_APIENTRYP PFNGLCOPYTEXTURELEVELSAPPLEPROC) (GLuint destinationTexture, GLuint sourceTexture, GLint sourceBaseLevel, GLsizei sourceLevelCount);
@@ -667,6 +730,14 @@ GL_APICALL void GL_APIENTRY glGetSyncivAPPLE (GLsync sync, GLenum pname, GLsizei
 #define GL_TEXTURE_MAX_LEVEL_APPLE        0x813D
 #endif /* GL_APPLE_texture_max_level */
 
+#ifndef GL_APPLE_texture_packed_float
+#define GL_APPLE_texture_packed_float 1
+#define GL_UNSIGNED_INT_10F_11F_11F_REV_APPLE 0x8C3B
+#define GL_UNSIGNED_INT_5_9_9_9_REV_APPLE 0x8C3E
+#define GL_R11F_G11F_B10F_APPLE           0x8C3A
+#define GL_RGB9_E5_APPLE                  0x8C3D
+#endif /* GL_APPLE_texture_packed_float */
+
 #ifndef GL_ARM_mali_program_binary
 #define GL_ARM_mali_program_binary 1
 #define GL_MALI_PROGRAM_BINARY_ARM        0x8F61
@@ -691,6 +762,13 @@ GL_APICALL void GL_APIENTRY glGetSyncivAPPLE (GLsync sync, GLenum pname, GLsizei
 #define GL_ARM_shader_framebuffer_fetch_depth_stencil 1
 #endif /* GL_ARM_shader_framebuffer_fetch_depth_stencil */
 
+#ifndef GL_DMP_program_binary
+#define GL_DMP_program_binary 1
+#define GL_SMAPHS30_PROGRAM_BINARY_DMP    0x9251
+#define GL_SMAPHS_PROGRAM_BINARY_DMP      0x9252
+#define GL_DMP_PROGRAM_BINARY_DMP         0x9253
+#endif /* GL_DMP_program_binary */
+
 #ifndef GL_DMP_shader_binary
 #define GL_DMP_shader_binary 1
 #define GL_SHADER_BINARY_DMP              0x9250
@@ -712,6 +790,14 @@ GL_APICALL void GL_APIENTRY glGetSyncivAPPLE (GLsync sync, GLenum pname, GLsizei
 #define GL_UNSIGNED_NORMALIZED_EXT        0x8C17
 #endif /* GL_EXT_color_buffer_half_float */
 
+#ifndef GL_EXT_copy_image
+#define GL_EXT_copy_image 1
+typedef void (GL_APIENTRYP PFNGLCOPYIMAGESUBDATAEXTPROC) (GLuint srcName, GLenum srcTarget, GLint srcLevel, GLint srcX, GLint srcY, GLint srcZ, GLuint dstName, GLenum dstTarget, GLint dstLevel, GLint dstX, GLint dstY, GLint dstZ, GLsizei srcWidth, GLsizei srcHeight, GLsizei srcDepth);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL void GL_APIENTRY glCopyImageSubDataEXT (GLuint srcName, GLenum srcTarget, GLint srcLevel, GLint srcX, GLint srcY, GLint srcZ, GLuint dstName, GLenum dstTarget, GLint dstLevel, GLint dstX, GLint dstY, GLint dstZ, GLsizei srcWidth, GLsizei srcHeight, GLsizei srcDepth);
+#endif
+#endif /* GL_EXT_copy_image */
+
 #ifndef GL_EXT_debug_label
 #define GL_EXT_debug_label 1
 #define GL_PROGRAM_PIPELINE_OBJECT_EXT    0x8A4F
@@ -829,6 +915,30 @@ GL_APICALL void GL_APIENTRY glDrawBuffersEXT (GLsizei n, const GLenum *bufs);
 #endif
 #endif /* GL_EXT_draw_buffers */
 
+#ifndef GL_EXT_draw_buffers_indexed
+#define GL_EXT_draw_buffers_indexed 1
+#define GL_MIN                            0x8007
+#define GL_MAX                            0x8008
+typedef void (GL_APIENTRYP PFNGLENABLEIEXTPROC) (GLenum target, GLuint index);
+typedef void (GL_APIENTRYP PFNGLDISABLEIEXTPROC) (GLenum target, GLuint index);
+typedef void (GL_APIENTRYP PFNGLBLENDEQUATIONIEXTPROC) (GLuint buf, GLenum mode);
+typedef void (GL_APIENTRYP PFNGLBLENDEQUATIONSEPARATEIEXTPROC) (GLuint buf, GLenum modeRGB, GLenum modeAlpha);
+typedef void (GL_APIENTRYP PFNGLBLENDFUNCIEXTPROC) (GLuint buf, GLenum src, GLenum dst);
+typedef void (GL_APIENTRYP PFNGLBLENDFUNCSEPARATEIEXTPROC) (GLuint buf, GLenum srcRGB, GLenum dstRGB, GLenum srcAlpha, GLenum dstAlpha);
+typedef void (GL_APIENTRYP PFNGLCOLORMASKIEXTPROC) (GLuint index, GLboolean r, GLboolean g, GLboolean b, GLboolean a);
+typedef GLboolean (GL_APIENTRYP PFNGLISENABLEDIEXTPROC) (GLenum target, GLuint index);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL void GL_APIENTRY glEnableiEXT (GLenum target, GLuint index);
+GL_APICALL void GL_APIENTRY glDisableiEXT (GLenum target, GLuint index);
+GL_APICALL void GL_APIENTRY glBlendEquationiEXT (GLuint buf, GLenum mode);
+GL_APICALL void GL_APIENTRY glBlendEquationSeparateiEXT (GLuint buf, GLenum modeRGB, GLenum modeAlpha);
+GL_APICALL void GL_APIENTRY glBlendFunciEXT (GLuint buf, GLenum src, GLenum dst);
+GL_APICALL void GL_APIENTRY glBlendFuncSeparateiEXT (GLuint buf, GLenum srcRGB, GLenum dstRGB, GLenum srcAlpha, GLenum dstAlpha);
+GL_APICALL void GL_APIENTRY glColorMaskiEXT (GLuint index, GLboolean r, GLboolean g, GLboolean b, GLboolean a);
+GL_APICALL GLboolean GL_APIENTRY glIsEnablediEXT (GLenum target, GLuint index);
+#endif
+#endif /* GL_EXT_draw_buffers_indexed */
+
 #ifndef GL_EXT_draw_instanced
 #define GL_EXT_draw_instanced 1
 typedef void (GL_APIENTRYP PFNGLDRAWARRAYSINSTANCEDEXTPROC) (GLenum mode, GLint start, GLsizei count, GLsizei primcount);
@@ -839,6 +949,55 @@ GL_APICALL void GL_APIENTRY glDrawElementsInstancedEXT (GLenum mode, GLsizei cou
 #endif
 #endif /* GL_EXT_draw_instanced */
 
+#ifndef GL_EXT_geometry_point_size
+#define GL_EXT_geometry_point_size 1
+#endif /* GL_EXT_geometry_point_size */
+
+#ifndef GL_EXT_geometry_shader
+#define GL_EXT_geometry_shader 1
+#define GL_GEOMETRY_SHADER_EXT            0x8DD9
+#define GL_GEOMETRY_SHADER_BIT_EXT        0x00000004
+#define GL_GEOMETRY_LINKED_VERTICES_OUT_EXT 0x8916
+#define GL_GEOMETRY_LINKED_INPUT_TYPE_EXT 0x8917
+#define GL_GEOMETRY_LINKED_OUTPUT_TYPE_EXT 0x8918
+#define GL_GEOMETRY_SHADER_INVOCATIONS_EXT 0x887F
+#define GL_LAYER_PROVOKING_VERTEX_EXT     0x825E
+#define GL_LINES_ADJACENCY_EXT            0x000A
+#define GL_LINE_STRIP_ADJACENCY_EXT       0x000B
+#define GL_TRIANGLES_ADJACENCY_EXT        0x000C
+#define GL_TRIANGLE_STRIP_ADJACENCY_EXT   0x000D
+#define GL_MAX_GEOMETRY_UNIFORM_COMPONENTS_EXT 0x8DDF
+#define GL_MAX_GEOMETRY_UNIFORM_BLOCKS_EXT 0x8A2C
+#define GL_MAX_COMBINED_GEOMETRY_UNIFORM_COMPONENTS_EXT 0x8A32
+#define GL_MAX_GEOMETRY_INPUT_COMPONENTS_EXT 0x9123
+#define GL_MAX_GEOMETRY_OUTPUT_COMPONENTS_EXT 0x9124
+#define GL_MAX_GEOMETRY_OUTPUT_VERTICES_EXT 0x8DE0
+#define GL_MAX_GEOMETRY_TOTAL_OUTPUT_COMPONENTS_EXT 0x8DE1
+#define GL_MAX_GEOMETRY_SHADER_INVOCATIONS_EXT 0x8E5A
+#define GL_MAX_GEOMETRY_TEXTURE_IMAGE_UNITS_EXT 0x8C29
+#define GL_MAX_GEOMETRY_ATOMIC_COUNTER_BUFFERS_EXT 0x92CF
+#define GL_MAX_GEOMETRY_ATOMIC_COUNTERS_EXT 0x92D5
+#define GL_MAX_GEOMETRY_IMAGE_UNIFORMS_EXT 0x90CD
+#define GL_MAX_GEOMETRY_SHADER_STORAGE_BLOCKS_EXT 0x90D7
+#define GL_FIRST_VERTEX_CONVENTION_EXT    0x8E4D
+#define GL_LAST_VERTEX_CONVENTION_EXT     0x8E4E
+#define GL_UNDEFINED_VERTEX_EXT           0x8260
+#define GL_PRIMITIVES_GENERATED_EXT       0x8C87
+#define GL_FRAMEBUFFER_DEFAULT_LAYERS_EXT 0x9312
+#define GL_MAX_FRAMEBUFFER_LAYERS_EXT     0x9317
+#define GL_FRAMEBUFFER_INCOMPLETE_LAYER_TARGETS_EXT 0x8DA8
+#define GL_FRAMEBUFFER_ATTACHMENT_LAYERED_EXT 0x8DA7
+#define GL_REFERENCED_BY_GEOMETRY_SHADER_EXT 0x9309
+typedef void (GL_APIENTRYP PFNGLFRAMEBUFFERTEXTUREEXTPROC) (GLenum target, GLenum attachment, GLuint texture, GLint level);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL void GL_APIENTRY glFramebufferTextureEXT (GLenum target, GLenum attachment, GLuint texture, GLint level);
+#endif
+#endif /* GL_EXT_geometry_shader */
+
+#ifndef GL_EXT_gpu_shader5
+#define GL_EXT_gpu_shader5 1
+#endif /* GL_EXT_gpu_shader5 */
+
 #ifndef GL_EXT_instanced_arrays
 #define GL_EXT_instanced_arrays 1
 #define GL_VERTEX_ATTRIB_ARRAY_DIVISOR_EXT 0x88FE
@@ -911,12 +1070,23 @@ GL_APICALL void GL_APIENTRY glGetIntegeri_vEXT (GLenum target, GLuint index, GLi
 #define GL_ANY_SAMPLES_PASSED_CONSERVATIVE_EXT 0x8D6A
 #endif /* GL_EXT_occlusion_query_boolean */
 
+#ifndef GL_EXT_primitive_bounding_box
+#define GL_EXT_primitive_bounding_box 1
+#define GL_PRIMITIVE_BOUNDING_BOX_EXT     0x92BE
+typedef void (GL_APIENTRYP PFNGLPRIMITIVEBOUNDINGBOXEXTPROC) (GLfloat minX, GLfloat minY, GLfloat minZ, GLfloat minW, GLfloat maxX, GLfloat maxY, GLfloat maxZ, GLfloat maxW);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL void GL_APIENTRY glPrimitiveBoundingBoxEXT (GLfloat minX, GLfloat minY, GLfloat minZ, GLfloat minW, GLfloat maxX, GLfloat maxY, GLfloat maxZ, GLfloat maxW);
+#endif
+#endif /* GL_EXT_primitive_bounding_box */
+
 #ifndef GL_EXT_pvrtc_sRGB
 #define GL_EXT_pvrtc_sRGB 1
 #define GL_COMPRESSED_SRGB_PVRTC_2BPPV1_EXT 0x8A54
 #define GL_COMPRESSED_SRGB_PVRTC_4BPPV1_EXT 0x8A55
 #define GL_COMPRESSED_SRGB_ALPHA_PVRTC_2BPPV1_EXT 0x8A56
 #define GL_COMPRESSED_SRGB_ALPHA_PVRTC_4BPPV1_EXT 0x8A57
+#define GL_COMPRESSED_SRGB_ALPHA_PVRTC_2BPPV2_IMG 0x93F0
+#define GL_COMPRESSED_SRGB_ALPHA_PVRTC_4BPPV2_IMG 0x93F1
 #endif /* GL_EXT_pvrtc_sRGB */
 
 #ifndef GL_EXT_read_format_bgra
@@ -1064,10 +1234,18 @@ GL_APICALL void GL_APIENTRY glProgramUniformMatrix4x3fvEXT (GLuint program, GLin
 #define GL_FRAGMENT_SHADER_DISCARDS_SAMPLES_EXT 0x8A52
 #endif /* GL_EXT_shader_framebuffer_fetch */
 
+#ifndef GL_EXT_shader_implicit_conversions
+#define GL_EXT_shader_implicit_conversions 1
+#endif /* GL_EXT_shader_implicit_conversions */
+
 #ifndef GL_EXT_shader_integer_mix
 #define GL_EXT_shader_integer_mix 1
 #endif /* GL_EXT_shader_integer_mix */
 
+#ifndef GL_EXT_shader_io_blocks
+#define GL_EXT_shader_io_blocks 1
+#endif /* GL_EXT_shader_io_blocks */
+
 #ifndef GL_EXT_shader_pixel_local_storage
 #define GL_EXT_shader_pixel_local_storage 1
 #define GL_MAX_SHADER_PIXEL_LOCAL_STORAGE_FAST_SIZE_EXT 0x8F63
@@ -1087,6 +1265,109 @@ GL_APICALL void GL_APIENTRY glProgramUniformMatrix4x3fvEXT (GLuint program, GLin
 #define GL_SAMPLER_2D_SHADOW_EXT          0x8B62
 #endif /* GL_EXT_shadow_samplers */
 
+#ifndef GL_EXT_tessellation_point_size
+#define GL_EXT_tessellation_point_size 1
+#endif /* GL_EXT_tessellation_point_size */
+
+#ifndef GL_EXT_tessellation_shader
+#define GL_EXT_tessellation_shader 1
+#define GL_PATCHES_EXT                    0x000E
+#define GL_PATCH_VERTICES_EXT             0x8E72
+#define GL_TESS_CONTROL_OUTPUT_VERTICES_EXT 0x8E75
+#define GL_TESS_GEN_MODE_EXT              0x8E76
+#define GL_TESS_GEN_SPACING_EXT           0x8E77
+#define GL_TESS_GEN_VERTEX_ORDER_EXT      0x8E78
+#define GL_TESS_GEN_POINT_MODE_EXT        0x8E79
+#define GL_ISOLINES_EXT                   0x8E7A
+#define GL_QUADS_EXT                      0x0007
+#define GL_FRACTIONAL_ODD_EXT             0x8E7B
+#define GL_FRACTIONAL_EVEN_EXT            0x8E7C
+#define GL_MAX_PATCH_VERTICES_EXT         0x8E7D
+#define GL_MAX_TESS_GEN_LEVEL_EXT         0x8E7E
+#define GL_MAX_TESS_CONTROL_UNIFORM_COMPONENTS_EXT 0x8E7F
+#define GL_MAX_TESS_EVALUATION_UNIFORM_COMPONENTS_EXT 0x8E80
+#define GL_MAX_TESS_CONTROL_TEXTURE_IMAGE_UNITS_EXT 0x8E81
+#define GL_MAX_TESS_EVALUATION_TEXTURE_IMAGE_UNITS_EXT 0x8E82
+#define GL_MAX_TESS_CONTROL_OUTPUT_COMPONENTS_EXT 0x8E83
+#define GL_MAX_TESS_PATCH_COMPONENTS_EXT  0x8E84
+#define GL_MAX_TESS_CONTROL_TOTAL_OUTPUT_COMPONENTS_EXT 0x8E85
+#define GL_MAX_TESS_EVALUATION_OUTPUT_COMPONENTS_EXT 0x8E86
+#define GL_MAX_TESS_CONTROL_UNIFORM_BLOCKS_EXT 0x8E89
+#define GL_MAX_TESS_EVALUATION_UNIFORM_BLOCKS_EXT 0x8E8A
+#define GL_MAX_TESS_CONTROL_INPUT_COMPONENTS_EXT 0x886C
+#define GL_MAX_TESS_EVALUATION_INPUT_COMPONENTS_EXT 0x886D
+#define GL_MAX_COMBINED_TESS_CONTROL_UNIFORM_COMPONENTS_EXT 0x8E1E
+#define GL_MAX_COMBINED_TESS_EVALUATION_UNIFORM_COMPONENTS_EXT 0x8E1F
+#define GL_MAX_TESS_CONTROL_ATOMIC_COUNTER_BUFFERS_EXT 0x92CD
+#define GL_MAX_TESS_EVALUATION_ATOMIC_COUNTER_BUFFERS_EXT 0x92CE
+#define GL_MAX_TESS_CONTROL_ATOMIC_COUNTERS_EXT 0x92D3
+#define GL_MAX_TESS_EVALUATION_ATOMIC_COUNTERS_EXT 0x92D4
+#define GL_MAX_TESS_CONTROL_IMAGE_UNIFORMS_EXT 0x90CB
+#define GL_MAX_TESS_EVALUATION_IMAGE_UNIFORMS_EXT 0x90CC
+#define GL_MAX_TESS_CONTROL_SHADER_STORAGE_BLOCKS_EXT 0x90D8
+#define GL_MAX_TESS_EVALUATION_SHADER_STORAGE_BLOCKS_EXT 0x90D9
+#define GL_PRIMITIVE_RESTART_FOR_PATCHES_SUPPORTED 0x8221
+#define GL_IS_PER_PATCH_EXT               0x92E7
+#define GL_REFERENCED_BY_TESS_CONTROL_SHADER_EXT 0x9307
+#define GL_REFERENCED_BY_TESS_EVALUATION_SHADER_EXT 0x9308
+#define GL_TESS_CONTROL_SHADER_EXT        0x8E88
+#define GL_TESS_EVALUATION_SHADER_EXT     0x8E87
+#define GL_TESS_CONTROL_SHADER_BIT_EXT    0x00000008
+#define GL_TESS_EVALUATION_SHADER_BIT_EXT 0x00000010
+typedef void (GL_APIENTRYP PFNGLPATCHPARAMETERIEXTPROC) (GLenum pname, GLint value);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL void GL_APIENTRY glPatchParameteriEXT (GLenum pname, GLint value);
+#endif
+#endif /* GL_EXT_tessellation_shader */
+
+#ifndef GL_EXT_texture_border_clamp
+#define GL_EXT_texture_border_clamp 1
+#define GL_TEXTURE_BORDER_COLOR_EXT       0x1004
+#define GL_CLAMP_TO_BORDER_EXT            0x812D
+typedef void (GL_APIENTRYP PFNGLTEXPARAMETERIIVEXTPROC) (GLenum target, GLenum pname, const GLint *params);
+typedef void (GL_APIENTRYP PFNGLTEXPARAMETERIUIVEXTPROC) (GLenum target, GLenum pname, const GLuint *params);
+typedef void (GL_APIENTRYP PFNGLGETTEXPARAMETERIIVEXTPROC) (GLenum target, GLenum pname, GLint *params);
+typedef void (GL_APIENTRYP PFNGLGETTEXPARAMETERIUIVEXTPROC) (GLenum target, GLenum pname, GLuint *params);
+typedef void (GL_APIENTRYP PFNGLSAMPLERPARAMETERIIVEXTPROC) (GLuint sampler, GLenum pname, const GLint *param);
+typedef void (GL_APIENTRYP PFNGLSAMPLERPARAMETERIUIVEXTPROC) (GLuint sampler, GLenum pname, const GLuint *param);
+typedef void (GL_APIENTRYP PFNGLGETSAMPLERPARAMETERIIVEXTPROC) (GLuint sampler, GLenum pname, GLint *params);
+typedef void (GL_APIENTRYP PFNGLGETSAMPLERPARAMETERIUIVEXTPROC) (GLuint sampler, GLenum pname, GLuint *params);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL void GL_APIENTRY glTexParameterIivEXT (GLenum target, GLenum pname, const GLint *params);
+GL_APICALL void GL_APIENTRY glTexParameterIuivEXT (GLenum target, GLenum pname, const GLuint *params);
+GL_APICALL void GL_APIENTRY glGetTexParameterIivEXT (GLenum target, GLenum pname, GLint *params);
+GL_APICALL void GL_APIENTRY glGetTexParameterIuivEXT (GLenum target, GLenum pname, GLuint *params);
+GL_APICALL void GL_APIENTRY glSamplerParameterIivEXT (GLuint sampler, GLenum pname, const GLint *param);
+GL_APICALL void GL_APIENTRY glSamplerParameterIuivEXT (GLuint sampler, GLenum pname, const GLuint *param);
+GL_APICALL void GL_APIENTRY glGetSamplerParameterIivEXT (GLuint sampler, GLenum pname, GLint *params);
+GL_APICALL void GL_APIENTRY glGetSamplerParameterIuivEXT (GLuint sampler, GLenum pname, GLuint *params);
+#endif
+#endif /* GL_EXT_texture_border_clamp */
+
+#ifndef GL_EXT_texture_buffer
+#define GL_EXT_texture_buffer 1
+#define GL_TEXTURE_BUFFER_EXT             0x8C2A
+#define GL_TEXTURE_BUFFER_BINDING_EXT     0x8C2A
+#define GL_MAX_TEXTURE_BUFFER_SIZE_EXT    0x8C2B
+#define GL_TEXTURE_BINDING_BUFFER_EXT     0x8C2C
+#define GL_TEXTURE_BUFFER_DATA_STORE_BINDING_EXT 0x8C2D
+#define GL_TEXTURE_BUFFER_OFFSET_ALIGNMENT_EXT 0x919F
+#define GL_SAMPLER_BUFFER_EXT             0x8DC2
+#define GL_INT_SAMPLER_BUFFER_EXT         0x8DD0
+#define GL_UNSIGNED_INT_SAMPLER_BUFFER_EXT 0x8DD8
+#define GL_IMAGE_BUFFER_EXT               0x9051
+#define GL_INT_IMAGE_BUFFER_EXT           0x905C
+#define GL_UNSIGNED_INT_IMAGE_BUFFER_EXT  0x9067
+#define GL_TEXTURE_BUFFER_OFFSET_EXT      0x919D
+#define GL_TEXTURE_BUFFER_SIZE_EXT        0x919E
+typedef void (GL_APIENTRYP PFNGLTEXBUFFEREXTPROC) (GLenum target, GLenum internalformat, GLuint buffer);
+typedef void (GL_APIENTRYP PFNGLTEXBUFFERRANGEEXTPROC) (GLenum target, GLenum internalformat, GLuint buffer, GLintptr offset, GLsizeiptr size);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL void GL_APIENTRY glTexBufferEXT (GLenum target, GLenum internalformat, GLuint buffer);
+GL_APICALL void GL_APIENTRY glTexBufferRangeEXT (GLenum target, GLenum internalformat, GLuint buffer, GLintptr offset, GLsizeiptr size);
+#endif
+#endif /* GL_EXT_texture_buffer */
+
 #ifndef GL_EXT_texture_compression_dxt1
 #define GL_EXT_texture_compression_dxt1 1
 #define GL_COMPRESSED_RGB_S3TC_DXT1_EXT   0x83F0
@@ -1099,6 +1380,19 @@ GL_APICALL void GL_APIENTRY glProgramUniformMatrix4x3fvEXT (GLuint program, GLin
 #define GL_COMPRESSED_RGBA_S3TC_DXT5_EXT  0x83F3
 #endif /* GL_EXT_texture_compression_s3tc */
 
+#ifndef GL_EXT_texture_cube_map_array
+#define GL_EXT_texture_cube_map_array 1
+#define GL_TEXTURE_CUBE_MAP_ARRAY_EXT     0x9009
+#define GL_TEXTURE_BINDING_CUBE_MAP_ARRAY_EXT 0x900A
+#define GL_SAMPLER_CUBE_MAP_ARRAY_EXT     0x900C
+#define GL_SAMPLER_CUBE_MAP_ARRAY_SHADOW_EXT 0x900D
+#define GL_INT_SAMPLER_CUBE_MAP_ARRAY_EXT 0x900E
+#define GL_UNSIGNED_INT_SAMPLER_CUBE_MAP_ARRAY_EXT 0x900F
+#define GL_IMAGE_CUBE_MAP_ARRAY_EXT       0x9054
+#define GL_INT_IMAGE_CUBE_MAP_ARRAY_EXT   0x905F
+#define GL_UNSIGNED_INT_IMAGE_CUBE_MAP_ARRAY_EXT 0x906A
+#endif /* GL_EXT_texture_cube_map_array */
+
 #ifndef GL_EXT_texture_filter_anisotropic
 #define GL_EXT_texture_filter_anisotropic 1
 #define GL_TEXTURE_MAX_ANISOTROPY_EXT     0x84FE
@@ -1161,6 +1455,19 @@ GL_APICALL void GL_APIENTRY glTextureStorage3DEXT (GLuint texture, GLenum target
 #define GL_UNSIGNED_INT_2_10_10_10_REV_EXT 0x8368
 #endif /* GL_EXT_texture_type_2_10_10_10_REV */
 
+#ifndef GL_EXT_texture_view
+#define GL_EXT_texture_view 1
+#define GL_TEXTURE_VIEW_MIN_LEVEL_EXT     0x82DB
+#define GL_TEXTURE_VIEW_NUM_LEVELS_EXT    0x82DC
+#define GL_TEXTURE_VIEW_MIN_LAYER_EXT     0x82DD
+#define GL_TEXTURE_VIEW_NUM_LAYERS_EXT    0x82DE
+#define GL_TEXTURE_IMMUTABLE_LEVELS       0x82DF
+typedef void (GL_APIENTRYP PFNGLTEXTUREVIEWEXTPROC) (GLuint texture, GLenum target, GLuint origtexture, GLenum internalformat, GLuint minlevel, GLuint numlevels, GLuint minlayer, GLuint numlayers);
+#ifdef GL_GLEXT_PROTOTYPES
+GL_APICALL void GL_APIENTRY glTextureViewEXT (GLuint texture, GLenum target, GLuint origtexture, GLenum internalformat, GLuint minlevel, GLuint numlevels, GLuint minlayer, GLuint numlayers);
+#endif
+#endif /* GL_EXT_texture_view */
+
 #ifndef GL_EXT_unpack_subimage
 #define GL_EXT_unpack_subimage 1
 #define GL_UNPACK_ROW_LENGTH_EXT          0x0CF2
diff --git a/scons/gallium.py b/scons/gallium.py
index dd5ca56..e3786d2 100755
--- a/scons/gallium.py
+++ b/scons/gallium.py
@@ -301,6 +301,10 @@ def generate(env):
             cppdefines += ['HAVE_ALIAS']
         else:
             cppdefines += ['GLX_ALIAS_UNSUPPORTED']
+
+        if env['platform'] in ('linux', 'darwin'):
+            cppdefines += ['HAVE_XLOCALE_H']
+
     if env['platform'] == 'haiku':
         cppdefines += [
             'HAVE_PTHREAD',
diff --git a/src/egl/drivers/dri2/egl_dri2.c b/src/egl/drivers/dri2/egl_dri2.c
index 20a7243..dcc3239 100644
--- a/src/egl/drivers/dri2/egl_dri2.c
+++ b/src/egl/drivers/dri2/egl_dri2.c
@@ -666,6 +666,7 @@ static EGLBoolean
 dri2_terminate(_EGLDriver *drv, _EGLDisplay *disp)
 {
    struct dri2_egl_display *dri2_dpy = dri2_egl_display(disp);
+   unsigned i;
 
    _eglReleaseDisplayResources(drv, disp);
    _eglCleanupDisplay(disp);
@@ -706,6 +707,9 @@ dri2_terminate(_EGLDriver *drv, _EGLDisplay *disp)
       break;
    }
 
+   for (i = 0; dri2_dpy->driver_configs[i]; i++)
+      free((__DRIconfig *) dri2_dpy->driver_configs[i]);
+   free(dri2_dpy->driver_configs);
    free(dri2_dpy);
    disp->DriverData = NULL;
 
diff --git a/src/egl/drivers/dri2/platform_drm.c b/src/egl/drivers/dri2/platform_drm.c
index ab71f4b..753c60f 100644
--- a/src/egl/drivers/dri2/platform_drm.c
+++ b/src/egl/drivers/dri2/platform_drm.c
@@ -418,6 +418,14 @@ dri2_drm_swap_buffers(_EGLDriver *drv, _EGLDisplay *disp, _EGLSurface *draw)
          for (i = 0; i < ARRAY_SIZE(dri2_surf->color_buffers); i++)
             if (dri2_surf->color_buffers[i].age > 0)
                dri2_surf->color_buffers[i].age++;
+
+         /* Make sure we have a back buffer in case we're swapping without
+          * ever rendering. */
+         if (get_back_bo(dri2_surf) < 0) {
+            _eglError(EGL_BAD_ALLOC, "dri2_swap_buffers");
+            return EGL_FALSE;
+         }
+
          dri2_surf->current = dri2_surf->back;
          dri2_surf->current->age = 1;
          dri2_surf->back = NULL;
diff --git a/src/gallium/auxiliary/gallivm/lp_bld_debug.cpp b/src/gallium/auxiliary/gallivm/lp_bld_debug.cpp
index bad65c2..4f9546a 100644
--- a/src/gallium/auxiliary/gallivm/lp_bld_debug.cpp
+++ b/src/gallium/auxiliary/gallivm/lp_bld_debug.cpp
@@ -410,6 +410,7 @@ disassemble(const void* func, llvm::raw_ostream & Out)
 extern "C" void
 lp_disassemble(LLVMValueRef func, const void *code) {
    raw_debug_ostream Out;
+   Out << LLVMGetValueName(func) << ":\n";
    disassemble(code, Out);
 }
 
diff --git a/src/gallium/auxiliary/gallivm/lp_bld_misc.cpp b/src/gallium/auxiliary/gallivm/lp_bld_misc.cpp
index 6bc4d81..fe3c754 100644
--- a/src/gallium/auxiliary/gallivm/lp_bld_misc.cpp
+++ b/src/gallium/auxiliary/gallivm/lp_bld_misc.cpp
@@ -433,7 +433,9 @@ lp_build_create_jit_compiler_for_module(LLVMExecutionEngineRef *OutJIT,
    options.JITEmitDebugInfo = true;
 #endif
 
-#if defined(DEBUG) || defined(PROFILE)
+   /* XXX: Workaround http://llvm.org/PR21435 */
+#if defined(DEBUG) || defined(PROFILE) || \
+    (HAVE_LLVM >= 0x0303 && (defined(PIPE_ARCH_X86) || defined(PIPE_ARCH_X86_64)))
 #if HAVE_LLVM < 0x0304
    options.NoFramePointerElimNonLeaf = true;
 #endif
diff --git a/src/gallium/auxiliary/tgsi/tgsi_parse.c b/src/gallium/auxiliary/tgsi/tgsi_parse.c
index 5bf8f48..f2370ed 100644
--- a/src/gallium/auxiliary/tgsi/tgsi_parse.c
+++ b/src/gallium/auxiliary/tgsi/tgsi_parse.c
@@ -291,6 +291,16 @@ tgsi_alloc_tokens(unsigned num_tokens)
 }
 
 
+/**
+ * Free tokens allocated by tgsi_alloc_tokens() or tgsi_dup_tokens()
+ */
+void
+tgsi_free_tokens(const struct tgsi_token *tokens)
+{
+   FREE((void *) tokens);
+}
+
+
 void
 tgsi_dump_tokens(const struct tgsi_token *tokens)
 {
diff --git a/src/gallium/auxiliary/tgsi/tgsi_parse.h b/src/gallium/auxiliary/tgsi/tgsi_parse.h
index 2e450a4..bfcca48 100644
--- a/src/gallium/auxiliary/tgsi/tgsi_parse.h
+++ b/src/gallium/auxiliary/tgsi/tgsi_parse.h
@@ -150,6 +150,9 @@ tgsi_dup_tokens(const struct tgsi_token *tokens);
 struct tgsi_token *
 tgsi_alloc_tokens(unsigned num_tokens);
 
+void
+tgsi_free_tokens(const struct tgsi_token *tokens);
+
 
 #if defined __cplusplus
 }
diff --git a/src/gallium/auxiliary/util/u_pstipple.c b/src/gallium/auxiliary/util/u_pstipple.c
index 509f815..1e1ec4a 100644
--- a/src/gallium/auxiliary/util/u_pstipple.c
+++ b/src/gallium/auxiliary/util/u_pstipple.c
@@ -180,9 +180,7 @@ struct pstip_transform_context {
    int maxInput;
    uint samplersUsed;  /**< bitfield of samplers used */
    int freeSampler;  /** an available sampler for the pstipple */
-   int texTemp;  /**< temp registers */
    int numImmed;
-   boolean firstInstruction;
    uint coordOrigin;
 };
 
@@ -243,7 +241,7 @@ free_bit(uint bitfield)
 
 
 /**
- * TGSI instruction transform callback.
+ * TGSI transform prolog
  * Before the first instruction, insert our new code to sample the
  * stipple texture (using the fragment coord register) then kill the
  * fragment if the stipple texture bit is off.
@@ -256,165 +254,95 @@ free_bit(uint bitfield)
  *   [...original code...]
  */
 static void
-pstip_transform_inst(struct tgsi_transform_context *ctx,
-                     struct tgsi_full_instruction *inst)
+pstip_transform_prolog(struct tgsi_transform_context *ctx)
 {
    struct pstip_transform_context *pctx =
       (struct pstip_transform_context *) ctx;
+   int wincoordInput;
+   int texTemp;
+
+   /* find free texture sampler */
+   pctx->freeSampler = free_bit(pctx->samplersUsed);
+   if (pctx->freeSampler >= PIPE_MAX_SAMPLERS)
+      pctx->freeSampler = PIPE_MAX_SAMPLERS - 1;
+
+   if (pctx->wincoordInput < 0)
+      wincoordInput = pctx->maxInput + 1;
+   else
+      wincoordInput = pctx->wincoordInput;
+
+   if (pctx->wincoordInput < 0) {
+      /* declare new position input reg */
+      tgsi_transform_input_decl(ctx, wincoordInput,
+                                TGSI_SEMANTIC_POSITION, 1,
+                                TGSI_INTERPOLATE_LINEAR);
+   }
 
-   if (pctx->firstInstruction) {
-      /* emit our new declarations before the first instruction */
-
-      struct tgsi_full_declaration decl;
-      struct tgsi_full_instruction newInst;
-      uint i;
-      int wincoordInput;
-
-      /* find free texture sampler */
-      pctx->freeSampler = free_bit(pctx->samplersUsed);
-      if (pctx->freeSampler >= PIPE_MAX_SAMPLERS)
-         pctx->freeSampler = PIPE_MAX_SAMPLERS - 1;
-
-      if (pctx->wincoordInput < 0)
-         wincoordInput = pctx->maxInput + 1;
-      else
-         wincoordInput = pctx->wincoordInput;
-
-      /* find one free temp register */
-      for (i = 0; i < 32; i++) {
-         if ((pctx->tempsUsed & (1 << i)) == 0) {
-            /* found a free temp */
-            if (pctx->texTemp < 0)
-               pctx->texTemp  = i;
-            else
-               break;
-         }
-      }
-      assert(pctx->texTemp >= 0);
-
-      if (pctx->wincoordInput < 0) {
-         /* declare new position input reg */
-         decl = tgsi_default_full_declaration();
-         decl.Declaration.File = TGSI_FILE_INPUT;
-         decl.Declaration.Interpolate = 1;
-         decl.Declaration.Semantic = 1;
-         decl.Semantic.Name = TGSI_SEMANTIC_POSITION;
-         decl.Semantic.Index = 0;
-         decl.Range.First = 
-            decl.Range.Last = wincoordInput;
-         decl.Interp.Interpolate = TGSI_INTERPOLATE_LINEAR;
-         ctx->emit_declaration(ctx, &decl);
-      }
+   /* declare new sampler */
+   tgsi_transform_sampler_decl(ctx, pctx->freeSampler);
 
-      /* declare new sampler */
-      decl = tgsi_default_full_declaration();
-      decl.Declaration.File = TGSI_FILE_SAMPLER;
-      decl.Range.First = 
-      decl.Range.Last = pctx->freeSampler;
-      ctx->emit_declaration(ctx, &decl);
-
-      /* declare new temp regs */
-      decl = tgsi_default_full_declaration();
-      decl.Declaration.File = TGSI_FILE_TEMPORARY;
-      decl.Range.First = 
-      decl.Range.Last = pctx->texTemp;
-      ctx->emit_declaration(ctx, &decl);
-
-      /* emit immediate = {1/32, 1/32, 1, 1}
-       * The index/position of this immediate will be pctx->numImmed
-       */
-      {
-         static const float value[4] = { 1.0/32, 1.0/32, 1.0, 1.0 };
-         struct tgsi_full_immediate immed;
-         uint size = 4;
-         immed = tgsi_default_full_immediate();
-         immed.Immediate.NrTokens = 1 + size; /* one for the token itself */
-         immed.u[0].Float = value[0];
-         immed.u[1].Float = value[1];
-         immed.u[2].Float = value[2];
-         immed.u[3].Float = value[3];
-         ctx->emit_immediate(ctx, &immed);
-      }
-
-      pctx->firstInstruction = FALSE;
-
-
-      /* 
-       * Insert new MUL/TEX/KILL_IF instructions at start of program
-       * Take gl_FragCoord, divide by 32 (stipple size), sample the
-       * texture and kill fragment if needed.
-       *
-       * We'd like to use non-normalized texcoords to index into a RECT
-       * texture, but we can only use REPEAT wrap mode with normalized
-       * texcoords.  Darn.
-       */
-
-      /* XXX invert wincoord if origin isn't lower-left... */
-
-      /* MUL texTemp, INPUT[wincoord], 1/32; */
-      newInst = tgsi_default_full_instruction();
-      newInst.Instruction.Opcode = TGSI_OPCODE_MUL;
-      newInst.Instruction.NumDstRegs = 1;
-      newInst.Dst[0].Register.File = TGSI_FILE_TEMPORARY;
-      newInst.Dst[0].Register.Index = pctx->texTemp;
-      newInst.Instruction.NumSrcRegs = 2;
-      newInst.Src[0].Register.File = TGSI_FILE_INPUT;
-      newInst.Src[0].Register.Index = wincoordInput;
-      newInst.Src[1].Register.File = TGSI_FILE_IMMEDIATE;
-      newInst.Src[1].Register.Index = pctx->numImmed;
-      ctx->emit_instruction(ctx, &newInst);
-
-      /* TEX texTemp, texTemp, sampler; */
-      newInst = tgsi_default_full_instruction();
-      newInst.Instruction.Opcode = TGSI_OPCODE_TEX;
-      newInst.Instruction.NumDstRegs = 1;
-      newInst.Dst[0].Register.File = TGSI_FILE_TEMPORARY;
-      newInst.Dst[0].Register.Index = pctx->texTemp;
-      newInst.Instruction.NumSrcRegs = 2;
-      newInst.Instruction.Texture = TRUE;
-      newInst.Texture.Texture = TGSI_TEXTURE_2D;
-      newInst.Src[0].Register.File = TGSI_FILE_TEMPORARY;
-      newInst.Src[0].Register.Index = pctx->texTemp;
-      newInst.Src[1].Register.File = TGSI_FILE_SAMPLER;
-      newInst.Src[1].Register.Index = pctx->freeSampler;
-      ctx->emit_instruction(ctx, &newInst);
-
-      /* KILL_IF -texTemp;   # if -texTemp < 0, kill fragment */
-      newInst = tgsi_default_full_instruction();
-      newInst.Instruction.Opcode = TGSI_OPCODE_KILL_IF;
-      newInst.Instruction.NumDstRegs = 0;
-      newInst.Instruction.NumSrcRegs = 1;
-      newInst.Src[0].Register.File = TGSI_FILE_TEMPORARY;
-      newInst.Src[0].Register.Index = pctx->texTemp;
-      newInst.Src[0].Register.Negate = 1;
-      ctx->emit_instruction(ctx, &newInst);
+   /* Declare temp[0] reg if not already declared.
+    * We can always use temp[0] since this code is before
+    * the rest of the shader.
+    */
+   texTemp = 0;
+   if ((pctx->tempsUsed & (1 << texTemp)) == 0) {
+      tgsi_transform_temp_decl(ctx, texTemp);
    }
 
-   /* emit this instruction */
-   ctx->emit_instruction(ctx, inst);
+   /* emit immediate = {1/32, 1/32, 1, 1}
+    * The index/position of this immediate will be pctx->numImmed
+    */
+   tgsi_transform_immediate_decl(ctx, 1.0/32.0, 1.0/32.0, 1.0, 1.0);
+
+   /* 
+    * Insert new MUL/TEX/KILL_IF instructions at start of program
+    * Take gl_FragCoord, divide by 32 (stipple size), sample the
+    * texture and kill fragment if needed.
+    *
+    * We'd like to use non-normalized texcoords to index into a RECT
+    * texture, but we can only use REPEAT wrap mode with normalized
+    * texcoords.  Darn.
+    */
+
+   /* XXX invert wincoord if origin isn't lower-left... */
+
+   /* MUL texTemp, INPUT[wincoord], 1/32; */
+   tgsi_transform_op2_inst(ctx, TGSI_OPCODE_MUL,
+                           TGSI_FILE_TEMPORARY, texTemp,
+                           TGSI_WRITEMASK_XYZW,
+                           TGSI_FILE_INPUT, wincoordInput,
+                           TGSI_FILE_IMMEDIATE, pctx->numImmed);
+
+   /* TEX texTemp, texTemp, sampler; */
+   tgsi_transform_tex_2d_inst(ctx,
+                              TGSI_FILE_TEMPORARY, texTemp,
+                              TGSI_FILE_TEMPORARY, texTemp,
+                              pctx->freeSampler);
+
+   /* KILL_IF -texTemp;   # if -texTemp < 0, kill fragment */
+   tgsi_transform_kill_inst(ctx,
+                            TGSI_FILE_TEMPORARY, texTemp,
+                            TGSI_SWIZZLE_W);
 }
 
 
 /**
  * Given a fragment shader, return a new fragment shader which
  * samples a stipple texture and executes KILL.
+ * \param samplerUnitOut  returns the index of the sampler unit which
+ *                        will be used to sample the stipple texture
  */
-struct pipe_shader_state *
-util_pstipple_create_fragment_shader(struct pipe_context *pipe,
-                                     struct pipe_shader_state *fs,
+struct tgsi_token *
+util_pstipple_create_fragment_shader(const struct tgsi_token *tokens,
                                      unsigned *samplerUnitOut)
 {
-   struct pipe_shader_state *new_fs;
    struct pstip_transform_context transform;
-   const uint newLen = tgsi_num_tokens(fs->tokens) + NUM_NEW_TOKENS;
-
-   new_fs = MALLOC(sizeof(*new_fs));
-   if (!new_fs)
-      return NULL;
+   const uint newLen = tgsi_num_tokens(tokens) + NUM_NEW_TOKENS;
+   struct tgsi_token *new_tokens;
 
-   new_fs->tokens = tgsi_alloc_tokens(newLen);
-   if (!new_fs->tokens) {
-      FREE(new_fs);
+   new_tokens = tgsi_alloc_tokens(newLen);
+   if (!new_tokens) {
       return NULL;
    }
 
@@ -423,21 +351,17 @@ util_pstipple_create_fragment_shader(struct pipe_context *pipe,
    memset(&transform, 0, sizeof(transform));
    transform.wincoordInput = -1;
    transform.maxInput = -1;
-   transform.texTemp = -1;
-   transform.firstInstruction = TRUE;
    transform.coordOrigin = TGSI_FS_COORD_ORIGIN_UPPER_LEFT;
-   transform.base.transform_instruction = pstip_transform_inst;
+   transform.base.prolog = pstip_transform_prolog;
    transform.base.transform_declaration = pstip_transform_decl;
    transform.base.transform_immediate = pstip_transform_immed;
 
-   tgsi_scan_shader(fs->tokens, &transform.info);
+   tgsi_scan_shader(tokens, &transform.info);
 
    transform.coordOrigin =
       transform.info.properties[TGSI_PROPERTY_FS_COORD_ORIGIN];
 
-   tgsi_transform_shader(fs->tokens,
-                         (struct tgsi_token *) new_fs->tokens,
-                         newLen, &transform.base);
+   tgsi_transform_shader(tokens, new_tokens, newLen, &transform.base);
 
 #if 0 /* DEBUG */
    tgsi_dump(fs->tokens, 0);
@@ -447,6 +371,6 @@ util_pstipple_create_fragment_shader(struct pipe_context *pipe,
    assert(transform.freeSampler < PIPE_MAX_SAMPLERS);
    *samplerUnitOut = transform.freeSampler;
 
-   return new_fs;
+   return new_tokens;
 }
 
diff --git a/src/gallium/auxiliary/util/u_pstipple.h b/src/gallium/auxiliary/util/u_pstipple.h
index 6fbed80..13155e7 100644
--- a/src/gallium/auxiliary/util/u_pstipple.h
+++ b/src/gallium/auxiliary/util/u_pstipple.h
@@ -47,9 +47,8 @@ util_pstipple_create_sampler_view(struct pipe_context *pipe,
 extern void *
 util_pstipple_create_sampler(struct pipe_context *pipe);
 
-extern struct pipe_shader_state *
-util_pstipple_create_fragment_shader(struct pipe_context *pipe,
-                                     struct pipe_shader_state *fs,
+struct tgsi_token *
+util_pstipple_create_fragment_shader(const struct tgsi_token *tokens,
                                      unsigned *samplerUnitOut);
 
 
diff --git a/src/gallium/docs/source/tgsi.rst b/src/gallium/docs/source/tgsi.rst
index 7d5918f..2e01971 100644
--- a/src/gallium/docs/source/tgsi.rst
+++ b/src/gallium/docs/source/tgsi.rst
@@ -837,16 +837,37 @@ This instruction replicates its result.
 .. opcode:: NRM - 3-component Vector Normalise
 
 .. math::
+  
+  u = src.x \times src.x + src.y \times src.y + src.z \times src.z
 
-  dst.x = src.x / (src.x \times src.x + src.y \times src.y + src.z \times src.z)
+  v = \frac{1}{\sqrt{u}}
 
-  dst.y = src.y / (src.x \times src.x + src.y \times src.y + src.z \times src.z)
+  dst.x = src.x \times v
 
-  dst.z = src.z / (src.x \times src.x + src.y \times src.y + src.z \times src.z)
+  dst.y = src.y \times v
+
+  dst.z = src.z \times v
 
   dst.w = 1
 
 
+.. opcode:: NRM4 - 4-component Vector Normalise
+
+.. math::
+  
+  u = src.x \times src.x + src.y \times src.y + src.z \times src.z + src.w \times src.w
+
+  v = \frac{1}{\sqrt{u}}
+
+  dst.x = src.x \times v
+
+  dst.y = src.y \times v
+
+  dst.z = src.z \times v
+
+  dst.w = src.w \times v
+
+
 .. opcode:: DIV - Divide
 
 .. math::
@@ -1888,15 +1909,6 @@ Some require glsl version 1.30 (UIF/BREAKC/SWITCH/CASE/DEFAULT/ENDSWITCH).
    Ends a switch expression.
 
 
-.. opcode:: NRM4 - 4-component Vector Normalise
-
-This instruction replicates its result.
-
-.. math::
-
-  dst = \frac{src.x}{src.x \times src.x + src.y \times src.y + src.z \times src.z + src.w \times src.w}
-
-
 Interpolation ISA
 ^^^^^^^^^^^^^^^^^
 
diff --git a/src/gallium/drivers/freedreno/freedreno_gmem.c b/src/gallium/drivers/freedreno/freedreno_gmem.c
index 7f6c847..392c547 100644
--- a/src/gallium/drivers/freedreno/freedreno_gmem.c
+++ b/src/gallium/drivers/freedreno/freedreno_gmem.c
@@ -105,7 +105,7 @@ calculate_tiles(struct fd_context *ctx)
 		max_width /= 2;
 	}
 
-	if (fd_mesa_debug & FD_DBG_DSCIS) {
+	if (fd_mesa_debug & FD_DBG_NOSCIS) {
 		minx = 0;
 		miny = 0;
 		width = pfb->width;
@@ -324,7 +324,7 @@ fd_gmem_render_tiles(struct fd_context *ctx)
 		if (ctx->cleared || ctx->gmem_reason || (ctx->num_draws > 5)) {
 			DBG("GMEM: cleared=%x, gmem_reason=%x, num_draws=%u",
 				ctx->cleared, ctx->gmem_reason, ctx->num_draws);
-		} else if (!(fd_mesa_debug & FD_DBG_DBYPASS)) {
+		} else if (!(fd_mesa_debug & FD_DBG_NOBYPASS)) {
 			sysmem = true;
 		}
 	}
diff --git a/src/gallium/drivers/freedreno/freedreno_screen.c b/src/gallium/drivers/freedreno/freedreno_screen.c
index 7a3cd95..e873af9 100644
--- a/src/gallium/drivers/freedreno/freedreno_screen.c
+++ b/src/gallium/drivers/freedreno/freedreno_screen.c
@@ -61,9 +61,9 @@ static const struct debug_named_value debug_options[] = {
 		{"disasm",    FD_DBG_DISASM, "Dump TGSI and adreno shader disassembly"},
 		{"dclear",    FD_DBG_DCLEAR, "Mark all state dirty after clear"},
 		{"flush",     FD_DBG_FLUSH,  "Force flush after every draw"},
-		{"dscis",     FD_DBG_DSCIS,  "Disable scissor optimization"},
+		{"noscis",    FD_DBG_NOSCIS, "Disable scissor optimization"},
 		{"direct",    FD_DBG_DIRECT, "Force inline (SS_DIRECT) state loads"},
-		{"dbypass",   FD_DBG_DBYPASS,"Disable GMEM bypass"},
+		{"nobypass",  FD_DBG_NOBYPASS, "Disable GMEM bypass"},
 		{"fraghalf",  FD_DBG_FRAGHALF, "Use half-precision in fragment shader"},
 		{"nobin",     FD_DBG_NOBIN,  "Disable hw binning"},
 		{"noopt",     FD_DBG_NOOPT , "Disable optimization passes in compiler"},
@@ -352,7 +352,7 @@ fd_screen_get_shader_param(struct pipe_screen *pscreen, unsigned shader,
 	case PIPE_SHADER_CAP_MAX_CONTROL_FLOW_DEPTH:
 		return 8; /* XXX */
 	case PIPE_SHADER_CAP_MAX_INPUTS:
-        case PIPE_SHADER_CAP_MAX_OUTPUTS:
+	case PIPE_SHADER_CAP_MAX_OUTPUTS:
 		return 16;
 	case PIPE_SHADER_CAP_MAX_TEMPS:
 		return 64; /* Max native temporaries. */
diff --git a/src/gallium/drivers/freedreno/freedreno_util.h b/src/gallium/drivers/freedreno/freedreno_util.h
index 36a5995..5508514 100644
--- a/src/gallium/drivers/freedreno/freedreno_util.h
+++ b/src/gallium/drivers/freedreno/freedreno_util.h
@@ -57,9 +57,9 @@ enum adreno_stencil_op fd_stencil_op(unsigned op);
 #define FD_DBG_DISASM   0x0002
 #define FD_DBG_DCLEAR   0x0004
 #define FD_DBG_FLUSH    0x0008
-#define FD_DBG_DSCIS    0x0010
+#define FD_DBG_NOSCIS   0x0010
 #define FD_DBG_DIRECT   0x0020
-#define FD_DBG_DBYPASS  0x0040
+#define FD_DBG_NOBYPASS 0x0040
 #define FD_DBG_FRAGHALF 0x0080
 #define FD_DBG_NOBIN    0x0100
 #define FD_DBG_NOOPT    0x0200
diff --git a/src/gallium/drivers/freedreno/ir3/disasm-a3xx.c b/src/gallium/drivers/freedreno/ir3/disasm-a3xx.c
index 8c3704b..602be65 100644
--- a/src/gallium/drivers/freedreno/ir3/disasm-a3xx.c
+++ b/src/gallium/drivers/freedreno/ir3/disasm-a3xx.c
@@ -749,16 +749,8 @@ static void print_instr(uint32_t *dwords, int level, int n)
 	uint32_t opc = instr_opc(instr);
 	const char *name;
 
-	printf("%s%04d[%08xx_%08xx] ", levels[level], n, dwords[1], dwords[0]);
-
-#if 0
-	/* print unknown bits: */
-	if (debug & PRINT_RAW)
-		printf("[%08xx_%08xx] ", dwords[1] & 0x001ff800, dwords[0] & 0x00000000);
-
 	if (debug & PRINT_VERBOSE)
-		printf("%d,%02d ", instr->opc_cat, opc);
-#endif
+		printf("%s%04d[%08xx_%08xx] ", levels[level], n, dwords[1], dwords[0]);
 
 	/* NOTE: order flags are printed is a bit fugly.. but for now I
 	 * try to match the order in llvm-a3xx disassembler for easy
diff --git a/src/gallium/drivers/freedreno/ir3/ir3.h b/src/gallium/drivers/freedreno/ir3/ir3.h
index 21992f6..8a5e9fd 100644
--- a/src/gallium/drivers/freedreno/ir3/ir3.h
+++ b/src/gallium/drivers/freedreno/ir3/ir3.h
@@ -216,6 +216,19 @@ struct ir3_instruction {
 		 */
 #define DEPTH_UNUSED  ~0
 		unsigned depth;
+
+		/* Used just during cp stage, which comes before depth pass.
+		 * For fanin, where we need a sequence of consecutive registers,
+		 * keep track of each src instructions left (ie 'n-1') and right
+		 * (ie 'n+1') neighbor.  The front-end must insert enough mov's
+		 * to ensure that each instruction has at most one left and at
+		 * most one right neighbor.  During the copy-propagation pass,
+		 * we only remove mov's when we can preserve this constraint.
+		 */
+		struct {
+			struct ir3_instruction *left, *right;
+			uint16_t left_cnt, right_cnt;
+		} cp;
 	};
 	struct ir3_instruction *next;
 #ifdef DEBUG
@@ -230,6 +243,7 @@ struct ir3 {
 	struct ir3_instruction **instrs;
 	unsigned baryfs_count, baryfs_sz;
 	struct ir3_instruction **baryfs;
+	struct ir3_block *block;
 	unsigned heap_idx;
 	struct ir3_heap_chunk *chunk;
 };
diff --git a/src/gallium/drivers/freedreno/ir3/ir3_cmdline.c b/src/gallium/drivers/freedreno/ir3/ir3_cmdline.c
index 652ec16..96d89d6 100644
--- a/src/gallium/drivers/freedreno/ir3/ir3_cmdline.c
+++ b/src/gallium/drivers/freedreno/ir3/ir3_cmdline.c
@@ -42,7 +42,7 @@
 #include "instr-a3xx.h"
 #include "ir3.h"
 
-static void dump_info(struct ir3_shader_variant *so)
+static void dump_info(struct ir3_shader_variant *so, const char *str)
 {
 	struct ir3_info info;
 	uint32_t *bin;
@@ -51,12 +51,35 @@ static void dump_info(struct ir3_shader_variant *so)
 	// for debug, dump some before/after info:
 	bin = ir3_assemble(so->ir, &info);
 	if (fd_mesa_debug & FD_DBG_DISASM) {
+		struct ir3_block *block = so->ir->block;
 		unsigned i;
 
-		debug_printf("%s: disasm:\n", type);
+		debug_printf("; %s: %s\n", type, str);
+
+		for (i = 0; i < block->ninputs; i++) {
+			uint8_t regid;
+			if (!block->inputs[i])
+				continue;
+			regid = block->inputs[i]->regs[0]->num;
+			debug_printf("@in(r%d.%c)\tin%d\n",
+					(regid >> 2), "xyzw"[regid & 0x3], i);
+		}
+
+		for (i = 0; i < block->noutputs; i++) {
+			uint8_t regid;
+			if (!block->outputs[i])
+				continue;
+			/* kill shows up as a virtual output.. skip it! */
+			if (is_kill(block->outputs[i]))
+				continue;
+			regid = block->outputs[i]->regs[0]->num;
+			debug_printf("@out(r%d.%c)\tout%d\n",
+					(regid >> 2), "xyzw"[regid & 0x3], i);
+		}
+
 		disasm_a3xx(bin, info.sizedwords, 0, so->type);
 
-		debug_printf("%s: outputs:", type);
+		debug_printf("; %s: outputs:", type);
 		for (i = 0; i < so->outputs_count; i++) {
 			uint8_t regid = so->outputs[i].regid;
 			ir3_semantic sem = so->outputs[i].semantic;
@@ -65,7 +88,7 @@ static void dump_info(struct ir3_shader_variant *so)
 					sem2name(sem), sem2idx(sem));
 		}
 		debug_printf("\n");
-		debug_printf("%s: inputs:", type);
+		debug_printf("; %s: inputs:", type);
 		for (i = 0; i < so->inputs_count; i++) {
 			uint8_t regid = so->inputs[i].regid;
 			ir3_semantic sem = so->inputs[i].semantic;
@@ -78,7 +101,7 @@ static void dump_info(struct ir3_shader_variant *so)
 		}
 		debug_printf("\n");
 	}
-	debug_printf("%s: %u instructions, %d half, %d full\n\n",
+	debug_printf("; %s: %u instructions, %d half, %d full\n\n",
 			type, info.instrs_count, info.max_half_reg + 1, info.max_reg + 1);
 	free(bin);
 }
@@ -144,13 +167,20 @@ int main(int argc, char **argv)
 	struct tgsi_token toks[65536];
 	struct tgsi_parse_context parse;
 	struct ir3_shader_variant v;
-	struct ir3_shader_key key = {
-	};
+	struct ir3_shader_key key = {};
+	const char *info;
 	void *ptr;
 	size_t size;
 
 	fd_mesa_debug |= FD_DBG_DISASM;
 
+	/* cmdline args which impact shader variant get spit out in a
+	 * comment on the first line..  a quick/dirty way to preserve
+	 * that info so when ir3test recompiles the shader with a new
+	 * compiler version, we use the same shader-key settings:
+	 */
+	debug_printf("; options:");
+
 	while (n < argc) {
 		if (!strcmp(argv[n], "--verbose")) {
 			fd_mesa_debug |=  FD_DBG_OPTDUMP | FD_DBG_MSGS | FD_DBG_OPTMSGS;
@@ -159,42 +189,49 @@ int main(int argc, char **argv)
 		}
 
 		if (!strcmp(argv[n], "--binning-pass")) {
+			debug_printf(" %s", argv[n]);
 			key.binning_pass = true;
 			n++;
 			continue;
 		}
 
 		if (!strcmp(argv[n], "--color-two-side")) {
+			debug_printf(" %s", argv[n]);
 			key.color_two_side = true;
 			n++;
 			continue;
 		}
 
 		if (!strcmp(argv[n], "--half-precision")) {
+			debug_printf(" %s", argv[n]);
 			key.half_precision = true;
 			n++;
 			continue;
 		}
 
 		if (!strcmp(argv[n], "--alpha")) {
+			debug_printf(" %s", argv[n]);
 			key.alpha = true;
 			n++;
 			continue;
 		}
 
 		if (!strcmp(argv[n], "--saturate-s")) {
+			debug_printf(" %s %s", argv[n], argv[n+1]);
 			key.vsaturate_s = key.fsaturate_s = strtol(argv[n+1], NULL, 0);
 			n += 2;
 			continue;
 		}
 
 		if (!strcmp(argv[n], "--saturate-t")) {
+			debug_printf(" %s %s", argv[n], argv[n+1]);
 			key.vsaturate_t = key.fsaturate_t = strtol(argv[n+1], NULL, 0);
 			n += 2;
 			continue;
 		}
 
 		if (!strcmp(argv[n], "--saturate-r")) {
+			debug_printf(" %s %s", argv[n], argv[n+1]);
 			key.vsaturate_r = key.fsaturate_r = strtol(argv[n+1], NULL, 0);
 			n += 2;
 			continue;
@@ -213,6 +250,7 @@ int main(int argc, char **argv)
 
 		break;
 	}
+	debug_printf("\n");
 
 	filename = argv[n];
 
@@ -243,22 +281,26 @@ int main(int argc, char **argv)
 
 	if (!(fd_mesa_debug & FD_DBG_NOOPT)) {
 		/* with new compiler: */
+		info = "new compiler";
 		ret = ir3_compile_shader(&v, toks, key, true);
 
 		if (ret) {
 			reset_variant(&v, "new compiler failed, trying without copy propagation!");
+			info = "new compiler (no copy propagation)";
 			ret = ir3_compile_shader(&v, toks, key, false);
 			if (ret)
 				reset_variant(&v, "new compiler failed, trying fallback!\n");
 		}
 	}
 
-	if (ret)
+	if (ret) {
+		info = "old compiler";
 		ret = ir3_compile_shader_old(&v, toks, key);
+	}
 
 	if (ret) {
 		fprintf(stderr, "old compiler failed!\n");
 		return ret;
 	}
-	dump_info(&v);
+	dump_info(&v, info);
 }
diff --git a/src/gallium/drivers/freedreno/ir3/ir3_compiler.c b/src/gallium/drivers/freedreno/ir3/ir3_compiler.c
index 233f174..aaf362d 100644
--- a/src/gallium/drivers/freedreno/ir3/ir3_compiler.c
+++ b/src/gallium/drivers/freedreno/ir3/ir3_compiler.c
@@ -1222,64 +1222,40 @@ get_tex_coord(struct ir3_compile_context *ctx,
 	struct tgsi_src_register *coord = &inst->Src[0].Register;
 	struct ir3_instruction *instr;
 	unsigned tex = inst->Texture.Texture;
-	bool needs_mov = false;
-
-	/* cat5 instruction cannot seem to handle const or relative: */
-	if (is_rel_or_const(coord))
-		needs_mov = true;
-
-	/* 1D textures we fix up w/ 0.5 as 2nd coord: */
-	if (is_1d(tex))
-		needs_mov = true;
-
-	/* The texture sample instructions need to coord in successive
-	 * registers/components (ie. src.xy but not src.yx).  And TXP
-	 * needs the .w component in .z for 2D..  so in some cases we
-	 * might need to emit some mov instructions to shuffle things
-	 * around:
-	 */
-	if (!needs_mov)
-		needs_mov = !check_swiz(coord, tinf->order);
-
-	if (needs_mov) {
-		struct tgsi_dst_register tmp_dst;
-		struct tgsi_src_register *tmp_src;
-		unsigned j;
-
-		type_t type_mov = get_ftype(ctx);
-
-		/* need to move things around: */
-		tmp_src = get_internal_temp(ctx, &tmp_dst);
-
-		for (j = 0; j < 4; j++) {
-			if (tinf->order[j] < 0)
-				continue;
-			instr = instr_create(ctx, 1, 0);  /* mov */
-			instr->cat1.src_type = type_mov;
-			instr->cat1.dst_type = type_mov;
-			add_dst_reg(ctx, instr, &tmp_dst, j);
-			add_src_reg(ctx, instr, coord,
-					src_swiz(coord, tinf->order[j]));
-		}
+	struct tgsi_dst_register tmp_dst;
+	struct tgsi_src_register *tmp_src;
+	type_t type_mov = get_ftype(ctx);
+	unsigned j;
 
-		/* fix up .y coord: */
-		if (is_1d(tex)) {
-			struct ir3_register *imm;
-			instr = instr_create(ctx, 1, 0);  /* mov */
-			instr->cat1.src_type = type_mov;
-			instr->cat1.dst_type = type_mov;
-			add_dst_reg(ctx, instr, &tmp_dst, 1);  /* .y */
-			imm = ir3_reg_create(instr, 0, IR3_REG_IMMED);
-			if (inst->Instruction.Opcode == TGSI_OPCODE_TXF)
-				imm->iim_val = 0;
-			else
-				imm->fim_val = 0.5;
-		}
+	/* need to move things around: */
+	tmp_src = get_internal_temp(ctx, &tmp_dst);
 
-		coord = tmp_src;
+	for (j = 0; j < 4; j++) {
+		if (tinf->order[j] < 0)
+			continue;
+		instr = instr_create(ctx, 1, 0);  /* mov */
+		instr->cat1.src_type = type_mov;
+		instr->cat1.dst_type = type_mov;
+		add_dst_reg(ctx, instr, &tmp_dst, j);
+		add_src_reg(ctx, instr, coord,
+				src_swiz(coord, tinf->order[j]));
+	}
+
+	/* fix up .y coord: */
+	if (is_1d(tex)) {
+		struct ir3_register *imm;
+		instr = instr_create(ctx, 1, 0);  /* mov */
+		instr->cat1.src_type = type_mov;
+		instr->cat1.dst_type = type_mov;
+		add_dst_reg(ctx, instr, &tmp_dst, 1);  /* .y */
+		imm = ir3_reg_create(instr, 0, IR3_REG_IMMED);
+		if (inst->Instruction.Opcode == TGSI_OPCODE_TXF)
+			imm->iim_val = 0;
+		else
+			imm->fim_val = 0.5;
 	}
 
-	return coord;
+	return tmp_src;
 }
 
 static void
@@ -3102,6 +3078,7 @@ ir3_compile_shader(struct ir3_shader_variant *so,
 	compile_instructions(&ctx);
 
 	block = ctx.block;
+	so->ir->block = block;
 
 	/* keep track of the inputs from TGSI perspective.. */
 	inputs = block->inputs;
diff --git a/src/gallium/drivers/freedreno/ir3/ir3_cp.c b/src/gallium/drivers/freedreno/ir3/ir3_cp.c
index 83bcb7a..2076b62 100644
--- a/src/gallium/drivers/freedreno/ir3/ir3_cp.c
+++ b/src/gallium/drivers/freedreno/ir3/ir3_cp.c
@@ -26,31 +26,101 @@
  *    Rob Clark <robclark@freedesktop.org>
  */
 
+#include "freedreno_util.h"
+
 #include "ir3.h"
 
 /*
  * Copy Propagate:
  *
- * TODO probably want some sort of visitor sort of interface to
- * avoid duplicating the same graph traversal logic everywhere..
- *
  */
 
 static void block_cp(struct ir3_block *block);
 static struct ir3_instruction * instr_cp(struct ir3_instruction *instr, bool keep);
 
+/* XXX move this somewhere useful (and rename?) */
+static struct ir3_instruction *ssa(struct ir3_register *reg)
+{
+	if (reg->flags & IR3_REG_SSA)
+		return reg->instr;
+	return NULL;
+}
+
+static bool conflicts(struct ir3_instruction *a, struct ir3_instruction *b)
+{
+	return (a && b) && (a != b);
+}
+
+static void set_neighbors(struct ir3_instruction *instr,
+		struct ir3_instruction *left, struct ir3_instruction *right)
+{
+	debug_assert(!conflicts(instr->cp.left, left));
+	if (left) {
+		instr->cp.left_cnt++;
+		instr->cp.left = left;
+	}
+	debug_assert(!conflicts(instr->cp.right, right));
+	if (right) {
+		instr->cp.right_cnt++;
+		instr->cp.right = right;
+	}
+}
+
+/* remove neighbor reference, clearing left/right neighbor ptrs when
+ * there are no more references:
+ */
+static void remove_neighbors(struct ir3_instruction *instr)
+{
+	if (instr->cp.left) {
+		if (--instr->cp.left_cnt == 0)
+			instr->cp.left = NULL;
+	}
+	if (instr->cp.right) {
+		if (--instr->cp.right_cnt == 0)
+			instr->cp.right = NULL;
+	}
+}
+
+/* stop condition for iteration: */
+static bool check_stop(struct ir3_instruction *instr)
+{
+	if (ir3_instr_check_mark(instr))
+		return true;
+
+	/* stay within the block.. don't try to operate across
+	 * basic block boundaries or we'll have problems when
+	 * dealing with multiple basic blocks:
+	 */
+	if (is_meta(instr) && (instr->opc == OPC_META_INPUT))
+		return true;
+
+	return false;
+}
+
 static bool is_eligible_mov(struct ir3_instruction *instr)
 {
 	if ((instr->category == 1) &&
 			(instr->cat1.src_type == instr->cat1.dst_type)) {
 		struct ir3_register *dst = instr->regs[0];
 		struct ir3_register *src = instr->regs[1];
+		struct ir3_instruction *src_instr = ssa(src);
 		if (dst->flags & IR3_REG_ADDR)
 			return false;
-		if ((src->flags & IR3_REG_SSA) &&
-				/* TODO: propagate abs/neg modifiers if possible */
-				!(src->flags & (IR3_REG_ABS | IR3_REG_NEGATE | IR3_REG_RELATIV)))
+		/* TODO: propagate abs/neg modifiers if possible */
+		if (src->flags & (IR3_REG_ABS | IR3_REG_NEGATE | IR3_REG_RELATIV))
+			return false;
+		if (src_instr) {
+			/* check that eliminating the move won't result in
+			 * a neighbor conflict, ie. if an instruction feeds
+			 * into multiple fanins it can still only have at
+			 * most one left and one right neighbor:
+			 */
+			if (conflicts(instr->cp.left, src_instr->cp.left))
+				return false;
+			if (conflicts(instr->cp.right, src_instr->cp.right))
+				return false;
 			return true;
+		}
 	}
 	return false;
 }
@@ -95,6 +165,9 @@ instr_cp_fanin(struct ir3_instruction *instr)
 			/* we can't have 2 registers referring to the same instruction, so
 			 * go through and check if any already refer to the candidate
 			 * instruction. if so, don't do the propagation.
+			 *
+			 * NOTE: we need to keep this, despite the neighbor
+			 * conflict checks, to avoid A<->B<->A..
 			 */
 			for (j = 1; j < instr->regs_count; j++)
 				if (instr->regs[j]->instr == cand)
@@ -107,22 +180,23 @@ instr_cp_fanin(struct ir3_instruction *instr)
 	walk_children(instr, false);
 
 	return instr;
-
 }
 
 static struct ir3_instruction *
 instr_cp(struct ir3_instruction *instr, bool keep)
 {
 	/* if we've already visited this instruction, bail now: */
-	if (ir3_instr_check_mark(instr))
+	if (check_stop(instr))
 		return instr;
 
 	if (is_meta(instr) && (instr->opc == OPC_META_FI))
 		return instr_cp_fanin(instr);
 
-	if (is_eligible_mov(instr) && !keep) {
-		struct ir3_register *src = instr->regs[1];
-		return instr_cp(src->instr, false);
+	if (!keep && is_eligible_mov(instr)) {
+		struct ir3_instruction *src_instr = ssa(instr->regs[1]);
+		set_neighbors(src_instr, instr->cp.left, instr->cp.right);
+		remove_neighbors(instr);
+		return instr_cp(src_instr, false);
 	}
 
 	walk_children(instr, false);
@@ -159,8 +233,88 @@ static void block_cp(struct ir3_block *block)
 	}
 }
 
+/*
+ * Find instruction neighbors:
+ */
+
+static void instr_find_neighbors(struct ir3_instruction *instr)
+{
+	unsigned i;
+
+	if (check_stop(instr))
+		return;
+
+	if (is_meta(instr) && (instr->opc == OPC_META_FI)) {
+		unsigned n = instr->regs_count;
+		for (i = 1; i < n; i++) {
+			struct ir3_instruction *src_instr = ssa(instr->regs[i]);
+			if (src_instr) {
+				struct ir3_instruction *left = (i > 1) ?
+						ssa(instr->regs[i-1]) : NULL;
+				struct ir3_instruction *right = (i < (n - 1)) ?
+						ssa(instr->regs[i+1]) : NULL;
+				set_neighbors(src_instr, left, right);
+				instr_find_neighbors(src_instr);
+			}
+		}
+	} else {
+		for (i = 1; i < instr->regs_count; i++) {
+			struct ir3_instruction *src_instr = ssa(instr->regs[i]);
+			if (src_instr)
+				instr_find_neighbors(src_instr);
+		}
+	}
+}
+
+static void block_find_neighbors(struct ir3_block *block)
+{
+	unsigned i;
+
+	for (i = 0; i < block->noutputs; i++) {
+		if (block->outputs[i]) {
+			struct ir3_instruction *instr = block->outputs[i];
+			instr_find_neighbors(instr);
+		}
+	}
+}
+
+static void instr_clear_neighbors(struct ir3_instruction *instr)
+{
+	unsigned i;
+
+	if (check_stop(instr))
+		return;
+
+	instr->cp.left_cnt = 0;
+	instr->cp.left = NULL;
+	instr->cp.right_cnt = 0;
+	instr->cp.right = NULL;
+
+	for (i = 1; i < instr->regs_count; i++) {
+		struct ir3_instruction *src_instr = ssa(instr->regs[i]);
+		if (src_instr)
+			instr_clear_neighbors(src_instr);
+	}
+}
+
+static void block_clear_neighbors(struct ir3_block *block)
+{
+	unsigned i;
+
+	for (i = 0; i < block->noutputs; i++) {
+		if (block->outputs[i]) {
+			struct ir3_instruction *instr = block->outputs[i];
+			instr_clear_neighbors(instr);
+		}
+	}
+}
+
 void ir3_block_cp(struct ir3_block *block)
 {
 	ir3_clear_mark(block->shader);
+	block_clear_neighbors(block);
+	ir3_clear_mark(block->shader);
+	block_find_neighbors(block);
+	ir3_clear_mark(block->shader);
 	block_cp(block);
 }
diff --git a/src/gallium/drivers/ilo/Makefile.sources b/src/gallium/drivers/ilo/Makefile.sources
index 52f4ff2..9e7977f 100644
--- a/src/gallium/drivers/ilo/Makefile.sources
+++ b/src/gallium/drivers/ilo/Makefile.sources
@@ -40,6 +40,7 @@ C_SOURCES := \
 	ilo_render_dynamic.c \
 	ilo_render_gen6.c \
 	ilo_render_gen7.c \
+	ilo_render_media.c \
 	ilo_render_surface.c \
 	ilo_screen.c \
 	ilo_screen.h \
@@ -82,6 +83,8 @@ GENHW_FILES := \
 	genhw/genhw.h \
 	genhw/gen_mi.xml.h \
 	genhw/gen_regs.xml.h \
+	genhw/gen_render.xml.h \
 	genhw/gen_render_3d.xml.h \
 	genhw/gen_render_dynamic.xml.h \
+	genhw/gen_render_media.xml.h \
 	genhw/gen_render_surface.xml.h
diff --git a/src/gallium/drivers/ilo/genhw/gen_eu_message.xml.h b/src/gallium/drivers/ilo/genhw/gen_eu_message.xml.h
index dd4dd85..c82fd34 100644
--- a/src/gallium/drivers/ilo/genhw/gen_eu_message.xml.h
+++ b/src/gallium/drivers/ilo/genhw/gen_eu_message.xml.h
@@ -177,9 +177,13 @@ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 #define GEN6_MSG_DP_SEND_WRITE_COMMIT				(0x1 << 17)
 #define GEN6_MSG_DP_OP__MASK					0x0001e000
 #define GEN6_MSG_DP_OP__SHIFT					13
+#define GEN6_MSG_DP_CTRL__MASK					0x00001f00
+#define GEN6_MSG_DP_CTRL__SHIFT					8
 #define GEN7_MSG_DP_CATEGORY					(0x1 << 18)
 #define GEN7_MSG_DP_OP__MASK					0x0003c000
 #define GEN7_MSG_DP_OP__SHIFT					14
+#define GEN7_MSG_DP_CTRL__MASK					0x00003f00
+#define GEN7_MSG_DP_CTRL__SHIFT					8
 #define GEN7_MSG_DP_OWORD_BLOCK_READ_INVALIDATE			(0x1 << 13)
 #define GEN6_MSG_DP_OWORD_BLOCK_SIZE__MASK			0x00000700
 #define GEN6_MSG_DP_OWORD_BLOCK_SIZE__SHIFT			8
@@ -214,7 +218,32 @@ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 #define GEN6_MSG_DP_RT_MODE_SIMD8_DUALSRC_HI			(0x3 << 8)
 #define GEN6_MSG_DP_RT_MODE_SIMD8_LO				(0x4 << 8)
 #define GEN6_MSG_DP_RT_MODE_SIMD8_IMAGE_WR			(0x5 << 8)
+#define GEN7_MSG_DP_UNTYPED_MODE__MASK				0x00003000
+#define GEN7_MSG_DP_UNTYPED_MODE__SHIFT				12
+#define GEN7_MSG_DP_UNTYPED_MODE_SIMD4X2			(0x0 << 12)
+#define GEN7_MSG_DP_UNTYPED_MODE_SIMD16				(0x1 << 12)
+#define GEN7_MSG_DP_UNTYPED_MODE_SIMD8				(0x2 << 12)
+#define GEN7_MSG_DP_UNTYPED_MASK__MASK				0x00000f00
+#define GEN7_MSG_DP_UNTYPED_MASK__SHIFT				8
+#define GEN7_MSG_DP_UNTYPED_MASK_R				(0x0 << 8)
+#define GEN7_MSG_DP_UNTYPED_MASK_G				(0x1 << 8)
+#define GEN7_MSG_DP_UNTYPED_MASK_B				(0x2 << 8)
+#define GEN7_MSG_DP_UNTYPED_MASK_A				(0x4 << 8)
 #define GEN6_MSG_DP_SURFACE__MASK				0x000000ff
 #define GEN6_MSG_DP_SURFACE__SHIFT				0
+#define GEN6_MSG_TS_RESOURCE_SELECT__MASK			0x00000010
+#define GEN6_MSG_TS_RESOURCE_SELECT__SHIFT			4
+#define GEN6_MSG_TS_RESOURCE_SELECT_CHILD			(0x0 << 4)
+#define GEN6_MSG_TS_RESOURCE_SELECT_ROOT			(0x1 << 4)
+#define GEN6_MSG_TS_RESOURCE_SELECT_DEREF			(0x0 << 4)
+#define GEN6_MSG_TS_RESOURCE_SELECT_NO_DEREF			(0x1 << 4)
+#define GEN6_MSG_TS_REQUESTER_TYPE__MASK			0x00000002
+#define GEN6_MSG_TS_REQUESTER_TYPE__SHIFT			1
+#define GEN6_MSG_TS_REQUESTER_TYPE_ROOT				(0x0 << 1)
+#define GEN6_MSG_TS_REQUESTER_TYPE_CHILD			(0x1 << 1)
+#define GEN6_MSG_TS_OPCODE__MASK				0x00000001
+#define GEN6_MSG_TS_OPCODE__SHIFT				0
+#define GEN6_MSG_TS_OPCODE_DEREF				0x0
+#define GEN6_MSG_TS_OPCODE_SPAWN				0x1
 
 #endif /* GEN_EU_MESSAGE_XML */
diff --git a/src/gallium/drivers/ilo/genhw/gen_regs.xml.h b/src/gallium/drivers/ilo/genhw/gen_regs.xml.h
index 30ac04e..6086760 100644
--- a/src/gallium/drivers/ilo/genhw/gen_regs.xml.h
+++ b/src/gallium/drivers/ilo/genhw/gen_regs.xml.h
@@ -95,6 +95,48 @@ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 #define GEN7_REG_SO_WRITE_OFFSET__ESIZE				0x8
 #define GEN7_REG_SO_WRITE_OFFSET__LEN				0x4
 
+
+#define GEN7_REG_L3SQCREG1					0xb010
+#define GEN7_REG_L3SQCREG1_CON4DCUNC				(0x1 << 24)
+#define GEN7_REG_L3SQCREG1_SQGHPCI__MASK			0x00ff0000
+#define GEN7_REG_L3SQCREG1_SQGHPCI__SHIFT			16
+#define GEN7_REG_L3SQCREG1_SQGHPCI_18_6				(0x73 << 16)
+#define GEN75_REG_L3SQCREG1_SQGPCI__MASK			0x00f80000
+#define GEN75_REG_L3SQCREG1_SQGPCI__SHIFT			19
+#define GEN75_REG_L3SQCREG1_SQGPCI_24				(0xc << 19)
+#define GEN75_REG_L3SQCREG1_SQHPCI__MASK			0x0007c000
+#define GEN75_REG_L3SQCREG1_SQHPCI__SHIFT			14
+#define GEN75_REG_L3SQCREG1_SQHPCI_8				(0x4 << 14)
+
+#define GEN7_REG_L3SQCREG2					0xb014
+
+#define GEN7_REG_L3SQCREG3					0xb018
+
+#define GEN7_REG_L3CNTLREG1					0xb01c
+
+#define GEN7_REG_L3CNTLREG2					0xb020
+#define GEN7_REG_L3CNTLREG2_DCWASLMB				(0x1 << 27)
+#define GEN7_REG_L3CNTLREG2_DCWASS__MASK			0x07e00000
+#define GEN7_REG_L3CNTLREG2_DCWASS__SHIFT			21
+#define GEN7_REG_L3CNTLREG2_ROCPSLMB				(0x1 << 20)
+#define GEN7_REG_L3CNTLREG2_RDOCPL__MASK			0x000fc000
+#define GEN7_REG_L3CNTLREG2_RDOCPL__SHIFT			14
+#define GEN7_REG_L3CNTLREG2_URBSLMB				(0x1 << 7)
+#define GEN7_REG_L3CNTLREG2_URBALL__MASK			0x0000007e
+#define GEN7_REG_L3CNTLREG2_URBALL__SHIFT			1
+#define GEN7_REG_L3CNTLREG2_SLMMENB				(0x1 << 0)
+
+#define GEN7_REG_L3CNTLREG3					0xb024
+#define GEN7_REG_L3CNTLREG3_TWALSLMB				(0x1 << 21)
+#define GEN7_REG_L3CNTLREG3_TXWYALL__MASK			0x001f8000
+#define GEN7_REG_L3CNTLREG3_TXWYALL__SHIFT			15
+#define GEN7_REG_L3CNTLREG3_CWASLMB				(0x1 << 14)
+#define GEN7_REG_L3CNTLREG3_CTWYALL__MASK			0x00003f00
+#define GEN7_REG_L3CNTLREG3_CTWYALL__SHIFT			8
+#define GEN7_REG_L3CNTLREG3_ISWYSLMB				(0x1 << 7)
+#define GEN7_REG_L3CNTLREG3_ISWYALL__MASK			0x0000007e
+#define GEN7_REG_L3CNTLREG3_ISWYALL__SHIFT			1
+
 #define GEN6_REG_BCS_SWCTRL					0x22200
 #define GEN6_REG_BCS_SWCTRL_DST_TILING_Y			(0x1 << 1)
 #define GEN6_REG_BCS_SWCTRL_SRC_TILING_Y			(0x1 << 0)
diff --git a/src/gallium/drivers/ilo/genhw/gen_render.xml.h b/src/gallium/drivers/ilo/genhw/gen_render.xml.h
new file mode 100644
index 0000000..9009437
--- /dev/null
+++ b/src/gallium/drivers/ilo/genhw/gen_render.xml.h
@@ -0,0 +1,182 @@
+#ifndef GEN_RENDER_XML
+#define GEN_RENDER_XML
+
+/* Autogenerated file, DO NOT EDIT manually!
+
+This file was generated by the rules-ng-ng headergen tool in this git repository:
+https://github.com/olvaffe/envytools/
+git clone https://github.com/olvaffe/envytools.git
+
+Copyright (C) 2014 by the following authors:
+- Chia-I Wu <olvaffe@gmail.com> (olv)
+
+Permission is hereby granted, free of charge, to any person obtaining
+a copy of this software and associated documentation files (the
+"Software"), to deal in the Software without restriction, including
+without limitation the rights to use, copy, modify, merge, publish,
+distribute, sublicense, and/or sell copies of the Software, and to
+permit persons to whom the Software is furnished to do so, subject to
+the following conditions:
+
+The above copyright notice and this permission notice (including the
+next paragraph) shall be included in all copies or substantial
+portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+*/
+
+
+#define GEN6_RENDER_TYPE__MASK					0xe0000000
+#define GEN6_RENDER_TYPE__SHIFT					29
+#define GEN6_RENDER_TYPE_RENDER					(0x3 << 29)
+#define GEN6_RENDER_SUBTYPE__MASK				0x18000000
+#define GEN6_RENDER_SUBTYPE__SHIFT				27
+#define GEN6_RENDER_SUBTYPE_COMMON				(0x0 << 27)
+#define GEN6_RENDER_SUBTYPE_SINGLE_DW				(0x1 << 27)
+#define GEN6_RENDER_SUBTYPE_MEDIA				(0x2 << 27)
+#define GEN6_RENDER_SUBTYPE_3D					(0x3 << 27)
+#define GEN6_RENDER_OPCODE__MASK				0x07ff0000
+#define GEN6_RENDER_OPCODE__SHIFT				16
+#define GEN6_RENDER_OPCODE_STATE_BASE_ADDRESS			(0x101 << 16)
+#define GEN6_RENDER_OPCODE_STATE_SIP				(0x102 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_VF_STATISTICS		(0xb << 16)
+#define GEN6_RENDER_OPCODE_PIPELINE_SELECT			(0x104 << 16)
+#define GEN6_RENDER_OPCODE_MEDIA_VFE_STATE			(0x0 << 16)
+#define GEN6_RENDER_OPCODE_MEDIA_CURBE_LOAD			(0x1 << 16)
+#define GEN6_RENDER_OPCODE_MEDIA_INTERFACE_DESCRIPTOR_LOAD	(0x2 << 16)
+#define GEN6_RENDER_OPCODE_MEDIA_STATE_FLUSH			(0x4 << 16)
+#define GEN7_RENDER_OPCODE_GPGPU_WALKER				(0x105 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS	(0x1 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS	(0x2 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_CLEAR_PARAMS			(0x4 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_URB				(0x5 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_DEPTH_BUFFER			(0x5 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_STENCIL_BUFFER		(0x6 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_HIER_DEPTH_BUFFER		(0x7 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_VERTEX_BUFFERS		(0x8 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_VERTEX_ELEMENTS		(0x9 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_INDEX_BUFFER			(0xa << 16)
+#define GEN75_RENDER_OPCODE_3DSTATE_VF				(0xc << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_VIEWPORT_STATE_POINTERS	(0xd << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_CC_STATE_POINTERS		(0xe << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_SCISSOR_STATE_POINTERS	(0xf << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_VS				(0x10 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_GS				(0x11 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_CLIP				(0x12 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_SF				(0x13 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_WM				(0x14 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_CONSTANT_VS			(0x15 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_CONSTANT_GS			(0x16 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_CONSTANT_PS			(0x17 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_SAMPLE_MASK			(0x18 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_CONSTANT_HS			(0x19 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_CONSTANT_DS			(0x1a << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_HS				(0x1b << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_TE				(0x1c << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_DS				(0x1d << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_STREAMOUT			(0x1e << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_SBE				(0x1f << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_PS				(0x20 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_VIEWPORT_STATE_POINTERS_SF_CLIP	(0x21 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_VIEWPORT_STATE_POINTERS_CC	(0x23 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_BLEND_STATE_POINTERS		(0x24 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_DEPTH_STENCIL_STATE_POINTERS	(0x25 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_VS	(0x26 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_HS	(0x27 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_DS	(0x28 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_GS	(0x29 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_PS	(0x2a << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_VS	(0x2b << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_HS	(0x2c << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_DS	(0x2d << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_GS	(0x2e << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_PS	(0x2f << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_URB_VS			(0x30 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_URB_HS			(0x31 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_URB_DS			(0x32 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_URB_GS			(0x33 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_DRAWING_RECTANGLE		(0x100 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_DEPTH_BUFFER			(0x105 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_POLY_STIPPLE_OFFSET		(0x106 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_POLY_STIPPLE_PATTERN		(0x107 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_LINE_STIPPLE			(0x108 << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_AA_LINE_PARAMETERS		(0x10a << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_GS_SVB_INDEX			(0x10b << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_MULTISAMPLE			(0x10d << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_STENCIL_BUFFER		(0x10e << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_HIER_DEPTH_BUFFER		(0x10f << 16)
+#define GEN6_RENDER_OPCODE_3DSTATE_CLEAR_PARAMS			(0x110 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_VS	(0x112 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_HS	(0x113 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_DS	(0x114 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_GS	(0x115 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_PS	(0x116 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_SO_DECL_LIST			(0x117 << 16)
+#define GEN7_RENDER_OPCODE_3DSTATE_SO_BUFFER			(0x118 << 16)
+#define GEN6_RENDER_OPCODE_PIPE_CONTROL				(0x200 << 16)
+#define GEN6_RENDER_OPCODE_3DPRIMITIVE				(0x300 << 16)
+#define GEN6_RENDER_LENGTH__MASK				0x000000ff
+#define GEN6_RENDER_LENGTH__SHIFT				0
+#define GEN6_MOCS_LLC__MASK					0x00000003
+#define GEN6_MOCS_LLC__SHIFT					0
+#define GEN6_MOCS_LLC_PTE					0x0
+#define GEN6_MOCS_LLC_UC					0x1
+#define GEN6_MOCS_LLC_ON					0x2
+#define GEN7_MOCS_LLC__MASK					0x00000002
+#define GEN7_MOCS_LLC__SHIFT					1
+#define GEN7_MOCS_LLC_PTE					(0x0 << 1)
+#define GEN7_MOCS_LLC_ON					(0x1 << 1)
+#define GEN75_MOCS_LLC__MASK					0x00000006
+#define GEN75_MOCS_LLC__SHIFT					1
+#define GEN75_MOCS_LLC_PTE					(0x0 << 1)
+#define GEN75_MOCS_LLC_UC					(0x1 << 1)
+#define GEN75_MOCS_LLC_ON					(0x2 << 1)
+#define GEN75_MOCS_LLC_ELLC					(0x3 << 1)
+#define GEN7_MOCS_L3__MASK					0x00000001
+#define GEN7_MOCS_L3__SHIFT					0
+#define GEN7_MOCS_L3_UC						0x0
+#define GEN7_MOCS_L3_ON						0x1
+#define GEN6_BASE_ADDR__MASK					0xfffff000
+#define GEN6_BASE_ADDR__SHIFT					12
+#define GEN6_BASE_ADDR__SHR					12
+#define GEN6_BASE_ADDR_MOCS__MASK				0x00000f00
+#define GEN6_BASE_ADDR_MOCS__SHIFT				8
+#define GEN6_BASE_ADDR_MODIFIED					(0x1 << 0)
+#define GEN6_STATE_BASE_ADDRESS__SIZE				10
+
+
+#define GEN6_BASE_ADDR_DW1_GENERAL_STATELESS_MOCS__MASK		0x000000f0
+#define GEN6_BASE_ADDR_DW1_GENERAL_STATELESS_MOCS__SHIFT	4
+#define GEN6_BASE_ADDR_DW1_GENERAL_STATELESS_FORCE_WRITE_THRU	(0x1 << 3)
+
+
+
+
+
+
+
+
+
+#define GEN6_STATE_SIP__SIZE					2
+
+
+#define GEN6_SIP_DW1_KERNEL_ADDR__MASK				0xfffffff0
+#define GEN6_SIP_DW1_KERNEL_ADDR__SHIFT				4
+#define GEN6_SIP_DW1_KERNEL_ADDR__SHR				4
+
+#define GEN6_PIPELINE_SELECT__SIZE				1
+
+#define GEN6_PIPELINE_SELECT_DW0_SELECT__MASK			0x00000003
+#define GEN6_PIPELINE_SELECT_DW0_SELECT__SHIFT			0
+#define GEN6_PIPELINE_SELECT_DW0_SELECT_3D			0x0
+#define GEN6_PIPELINE_SELECT_DW0_SELECT_MEDIA			0x1
+#define GEN7_PIPELINE_SELECT_DW0_SELECT_GPGPU			0x2
+
+
+#endif /* GEN_RENDER_XML */
diff --git a/src/gallium/drivers/ilo/genhw/gen_render_3d.xml.h b/src/gallium/drivers/ilo/genhw/gen_render_3d.xml.h
index ccca0db..2ddc0e5 100644
--- a/src/gallium/drivers/ilo/genhw/gen_render_3d.xml.h
+++ b/src/gallium/drivers/ilo/genhw/gen_render_3d.xml.h
@@ -109,99 +109,6 @@ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 #define GEN6_ZFORMAT_D24_UNORM_S8_UINT				0x2
 #define GEN6_ZFORMAT_D24_UNORM_X8_UINT				0x3
 #define GEN6_ZFORMAT_D16_UNORM					0x5
-#define GEN6_RENDER_TYPE__MASK					0xe0000000
-#define GEN6_RENDER_TYPE__SHIFT					29
-#define GEN6_RENDER_TYPE_RENDER					(0x3 << 29)
-#define GEN6_RENDER_SUBTYPE__MASK				0x18000000
-#define GEN6_RENDER_SUBTYPE__SHIFT				27
-#define GEN6_RENDER_SUBTYPE_COMMON				(0x0 << 27)
-#define GEN6_RENDER_SUBTYPE_SINGLE_DW				(0x1 << 27)
-#define GEN6_RENDER_SUBTYPE_MEDIA				(0x2 << 27)
-#define GEN6_RENDER_SUBTYPE_3D					(0x3 << 27)
-#define GEN6_RENDER_OPCODE__MASK				0x07ff0000
-#define GEN6_RENDER_OPCODE__SHIFT				16
-#define GEN6_RENDER_OPCODE_STATE_BASE_ADDRESS			(0x101 << 16)
-#define GEN6_RENDER_OPCODE_STATE_SIP				(0x102 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_VF_STATISTICS		(0xb << 16)
-#define GEN6_RENDER_OPCODE_PIPELINE_SELECT			(0x104 << 16)
-#define GEN6_RENDER_OPCODE_MEDIA_VFE_STATE			(0x0 << 16)
-#define GEN6_RENDER_OPCODE_MEDIA_CURBE_LOAD			(0x1 << 16)
-#define GEN6_RENDER_OPCODE_MEDIA_INTERFACE_DESCRIPTOR_LOAD	(0x2 << 16)
-#define GEN6_RENDER_OPCODE_MEDIA_GATEWAY_STATE			(0x3 << 16)
-#define GEN6_RENDER_OPCODE_MEDIA_STATE_FLUSH			(0x4 << 16)
-#define GEN6_RENDER_OPCODE_MEDIA_OBJECT_WALKER			(0x103 << 16)
-#define GEN7_RENDER_OPCODE_GPGPU_WALKER				(0x105 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS	(0x1 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS	(0x2 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_CLEAR_PARAMS			(0x4 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_URB				(0x5 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_DEPTH_BUFFER			(0x5 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_STENCIL_BUFFER		(0x6 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_HIER_DEPTH_BUFFER		(0x7 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_VERTEX_BUFFERS		(0x8 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_VERTEX_ELEMENTS		(0x9 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_INDEX_BUFFER			(0xa << 16)
-#define GEN75_RENDER_OPCODE_3DSTATE_VF				(0xc << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_VIEWPORT_STATE_POINTERS	(0xd << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_CC_STATE_POINTERS		(0xe << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_SCISSOR_STATE_POINTERS	(0xf << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_VS				(0x10 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_GS				(0x11 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_CLIP				(0x12 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_SF				(0x13 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_WM				(0x14 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_CONSTANT_VS			(0x15 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_CONSTANT_GS			(0x16 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_CONSTANT_PS			(0x17 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_SAMPLE_MASK			(0x18 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_CONSTANT_HS			(0x19 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_CONSTANT_DS			(0x1a << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_HS				(0x1b << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_TE				(0x1c << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_DS				(0x1d << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_STREAMOUT			(0x1e << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_SBE				(0x1f << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_PS				(0x20 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_VIEWPORT_STATE_POINTERS_SF_CLIP	(0x21 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_VIEWPORT_STATE_POINTERS_CC	(0x23 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_BLEND_STATE_POINTERS		(0x24 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_DEPTH_STENCIL_STATE_POINTERS	(0x25 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_VS	(0x26 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_HS	(0x27 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_DS	(0x28 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_GS	(0x29 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_BINDING_TABLE_POINTERS_PS	(0x2a << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_VS	(0x2b << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_HS	(0x2c << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_DS	(0x2d << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_GS	(0x2e << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_SAMPLER_STATE_POINTERS_PS	(0x2f << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_URB_VS			(0x30 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_URB_HS			(0x31 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_URB_DS			(0x32 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_URB_GS			(0x33 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_DRAWING_RECTANGLE		(0x100 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_DEPTH_BUFFER			(0x105 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_POLY_STIPPLE_OFFSET		(0x106 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_POLY_STIPPLE_PATTERN		(0x107 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_LINE_STIPPLE			(0x108 << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_AA_LINE_PARAMETERS		(0x10a << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_GS_SVB_INDEX			(0x10b << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_MULTISAMPLE			(0x10d << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_STENCIL_BUFFER		(0x10e << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_HIER_DEPTH_BUFFER		(0x10f << 16)
-#define GEN6_RENDER_OPCODE_3DSTATE_CLEAR_PARAMS			(0x110 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_VS	(0x112 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_HS	(0x113 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_DS	(0x114 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_GS	(0x115 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_PUSH_CONSTANT_ALLOC_PS	(0x116 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_SO_DECL_LIST			(0x117 << 16)
-#define GEN7_RENDER_OPCODE_3DSTATE_SO_BUFFER			(0x118 << 16)
-#define GEN6_RENDER_OPCODE_PIPE_CONTROL				(0x200 << 16)
-#define GEN6_RENDER_OPCODE_3DPRIMITIVE				(0x300 << 16)
-#define GEN6_RENDER_LENGTH__MASK				0x000000ff
-#define GEN6_RENDER_LENGTH__SHIFT				0
 #define GEN6_INTERP_NONPERSPECTIVE_SAMPLE			(0x1 << 5)
 #define GEN6_INTERP_NONPERSPECTIVE_CENTROID			(0x1 << 4)
 #define GEN6_INTERP_NONPERSPECTIVE_PIXEL			(0x1 << 3)
@@ -235,46 +142,10 @@ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 #define GEN6_THREADSCRATCH_ADDR__SHR				10
 #define GEN6_THREADSCRATCH_SPACE_PER_THREAD__MASK		0x0000000f
 #define GEN6_THREADSCRATCH_SPACE_PER_THREAD__SHIFT		0
-#define GEN6_BASE_ADDR__MASK					0xfffff000
-#define GEN6_BASE_ADDR__SHIFT					12
-#define GEN6_BASE_ADDR__SHR					12
-#define GEN6_BASE_ADDR_MOCS__MASK				0x00000f00
-#define GEN6_BASE_ADDR_MOCS__SHIFT				8
-#define GEN6_BASE_ADDR_MODIFIED					(0x1 << 0)
-#define GEN6_STATE_BASE_ADDRESS__SIZE				10
-
-
-#define GEN6_BASE_ADDR_DW1_GENERAL_STATELESS_MOCS__MASK		0x000000f0
-#define GEN6_BASE_ADDR_DW1_GENERAL_STATELESS_MOCS__SHIFT	4
-#define GEN6_BASE_ADDR_DW1_GENERAL_STATELESS_FORCE_WRITE_THRU	(0x1 << 3)
-
-
-
-
-
-
-
-
-
-#define GEN6_STATE_SIP__SIZE					2
-
-
-#define GEN6_SIP_DW1_KERNEL_ADDR__MASK				0xfffffff0
-#define GEN6_SIP_DW1_KERNEL_ADDR__SHIFT				4
-#define GEN6_SIP_DW1_KERNEL_ADDR__SHR				4
-
 #define GEN6_3DSTATE_VF_STATISTICS__SIZE			1
 
 #define GEN6_VF_STATS_DW0_ENABLE				(0x1 << 0)
 
-#define GEN6_PIPELINE_SELECT__SIZE				1
-
-#define GEN6_PIPELINE_SELECT_DW0_SELECT__MASK			0x00000003
-#define GEN6_PIPELINE_SELECT_DW0_SELECT__SHIFT			0
-#define GEN6_PIPELINE_SELECT_DW0_SELECT_3D			0x0
-#define GEN6_PIPELINE_SELECT_DW0_SELECT_MEDIA			0x1
-#define GEN75_PIPELINE_SELECT_DW0_SELECT_GPGPU			0x2
-
 #define GEN6_3DSTATE_BINDING_TABLE_POINTERS__SIZE		4
 
 #define GEN6_PTR_BINDING_TABLE_DW0_PS_CHANGED			(0x1 << 12)
diff --git a/src/gallium/drivers/ilo/genhw/gen_render_media.xml.h b/src/gallium/drivers/ilo/genhw/gen_render_media.xml.h
new file mode 100644
index 0000000..3590c79
--- /dev/null
+++ b/src/gallium/drivers/ilo/genhw/gen_render_media.xml.h
@@ -0,0 +1,224 @@
+#ifndef GEN_RENDER_MEDIA_XML
+#define GEN_RENDER_MEDIA_XML
+
+/* Autogenerated file, DO NOT EDIT manually!
+
+This file was generated by the rules-ng-ng headergen tool in this git repository:
+https://github.com/olvaffe/envytools/
+git clone https://github.com/olvaffe/envytools.git
+
+Copyright (C) 2014 by the following authors:
+- Chia-I Wu <olvaffe@gmail.com> (olv)
+
+Permission is hereby granted, free of charge, to any person obtaining
+a copy of this software and associated documentation files (the
+"Software"), to deal in the Software without restriction, including
+without limitation the rights to use, copy, modify, merge, publish,
+distribute, sublicense, and/or sell copies of the Software, and to
+permit persons to whom the Software is furnished to do so, subject to
+the following conditions:
+
+The above copyright notice and this permission notice (including the
+next paragraph) shall be included in all copies or substantial
+portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+*/
+
+
+#define GEN6_INTERFACE_DESCRIPTOR_DATA__SIZE			8
+
+#define GEN6_IDRT_DW0_KERNEL_ADDR__MASK				0xffffffc0
+#define GEN6_IDRT_DW0_KERNEL_ADDR__SHIFT			6
+#define GEN6_IDRT_DW0_KERNEL_ADDR__SHR				6
+
+#define GEN6_IDRT_DW1_SPF					(0x1 << 18)
+#define GEN6_IDRT_DW1_PRIORITY_HIGH				(0x1 << 17)
+#define GEN6_IDRT_DW1_FP_MODE_ALT				(0x1 << 16)
+#define GEN6_IDRT_DW1_ILLEGAL_CODE_EXCEPTION			(0x1 << 13)
+#define GEN6_IDRT_DW1_MASK_STACK_EXCEPTION			(0x1 << 11)
+#define GEN6_IDRT_DW1_SOFTWARE_EXCEPTION			(0x1 << 7)
+
+#define GEN6_IDRT_DW2_SAMPLER_ADDR__MASK			0xffffffe0
+#define GEN6_IDRT_DW2_SAMPLER_ADDR__SHIFT			5
+#define GEN6_IDRT_DW2_SAMPLER_ADDR__SHR				5
+#define GEN6_IDRT_DW2_SAMPLER_COUNT__MASK			0x0000001c
+#define GEN6_IDRT_DW2_SAMPLER_COUNT__SHIFT			2
+
+#define GEN6_IDRT_DW3_BINDING_TABLE_ADDR__MASK			0x0000ffe0
+#define GEN6_IDRT_DW3_BINDING_TABLE_ADDR__SHIFT			5
+#define GEN6_IDRT_DW3_BINDING_TABLE_ADDR__SHR			5
+#define GEN6_IDRT_DW3_BINDING_TABLE_SIZE__MASK			0x0000001f
+#define GEN6_IDRT_DW3_BINDING_TABLE_SIZE__SHIFT			0
+
+#define GEN6_IDRT_DW4_CURBE_READ_LEN__MASK			0xffff0000
+#define GEN6_IDRT_DW4_CURBE_READ_LEN__SHIFT			16
+#define GEN6_IDRT_DW4_CURBE_READ_OFFSET__MASK			0x0000ffff
+#define GEN6_IDRT_DW4_CURBE_READ_OFFSET__SHIFT			0
+
+#define GEN6_IDRT_DW5_BARRIER_ID__MASK				0x0000000f
+#define GEN6_IDRT_DW5_BARRIER_ID__SHIFT				0
+
+#define GEN7_IDRT_DW5_BARRIER_RETURN_GRF__MASK			0xff000000
+#define GEN7_IDRT_DW5_BARRIER_RETURN_GRF__SHIFT			24
+#define GEN7_IDRT_DW5_ROUNDING_MODE__MASK			0x00c00000
+#define GEN7_IDRT_DW5_ROUNDING_MODE__SHIFT			22
+#define GEN7_IDRT_DW5_ROUNDING_MODE_RTNE			(0x0 << 22)
+#define GEN7_IDRT_DW5_ROUNDING_MODE_RU				(0x1 << 22)
+#define GEN7_IDRT_DW5_ROUNDING_MODE_RD				(0x2 << 22)
+#define GEN7_IDRT_DW5_ROUNDING_MODE_RTZ				(0x3 << 22)
+#define GEN7_IDRT_DW5_BARRIER_ENABLE				(0x1 << 21)
+#define GEN7_IDRT_DW5_SLM_SIZE__MASK				0x001f0000
+#define GEN7_IDRT_DW5_SLM_SIZE__SHIFT				16
+#define GEN7_IDRT_DW5_BARRIER_RETURN_BYTE__MASK			0x0000ff00
+#define GEN7_IDRT_DW5_BARRIER_RETURN_BYTE__SHIFT		8
+#define GEN7_IDRT_DW5_THREAD_GROUP_SIZE__MASK			0x000000ff
+#define GEN7_IDRT_DW5_THREAD_GROUP_SIZE__SHIFT			0
+
+#define GEN75_IDRT_DW6_CROSS_THREAD_CURBE_READ_LEN__MASK	0x000000ff
+#define GEN75_IDRT_DW6_CROSS_THREAD_CURBE_READ_LEN__SHIFT	0
+
+
+#define GEN6_MEDIA_VFE_STATE__SIZE				8
+
+
+#define GEN6_VFE_DW1_SCRATCH_ADDR__MASK				0xfffffc00
+#define GEN6_VFE_DW1_SCRATCH_ADDR__SHIFT			10
+#define GEN6_VFE_DW1_SCRATCH_ADDR__SHR				10
+#define GEN6_VFE_DW1_SCRATCH_STACK_SIZE__MASK			0x000000f0
+#define GEN6_VFE_DW1_SCRATCH_STACK_SIZE__SHIFT			4
+#define GEN6_VFE_DW1_SCRATCH_SPACE_PER_THREAD__MASK		0x0000000f
+#define GEN6_VFE_DW1_SCRATCH_SPACE_PER_THREAD__SHIFT		0
+
+#define GEN6_VFE_DW2_MAX_THREADS__MASK				0xffff0000
+#define GEN6_VFE_DW2_MAX_THREADS__SHIFT				16
+#define GEN6_VFE_DW2_URB_ENTRY_COUNT__MASK			0x0000ff00
+#define GEN6_VFE_DW2_URB_ENTRY_COUNT__SHIFT			8
+#define GEN6_VFE_DW2_RESET_GATEWAY_TIMER			(0x1 << 7)
+#define GEN6_VFE_DW2_BYPASS_GATEWAY_CONTROL			(0x1 << 6)
+#define GEN6_VFE_DW2_FAST_PREEMPT				(0x1 << 5)
+#define GEN7_VFE_DW2_GATEWAY_MMIO__MASK				0x00000018
+#define GEN7_VFE_DW2_GATEWAY_MMIO__SHIFT			3
+#define GEN7_VFE_DW2_GATEWAY_MMIO_NONE				(0x0 << 3)
+#define GEN7_VFE_DW2_GATEWAY_MMIO_ANY				(0x2 << 3)
+#define GEN7_VFE_DW2_GPGPU_MODE					(0x1 << 2)
+
+#define GEN75_VFE_DW3_HALF_SLICE_DISABLE__MASK			0x00000003
+#define GEN75_VFE_DW3_HALF_SLICE_DISABLE__SHIFT			0
+#define GEN75_VFE_DW3_HALF_SLICE_DISABLE_NONE			0x0
+#define GEN75_VFE_DW3_HALF_SLICE_DISABLE_23			0x1
+#define GEN75_VFE_DW3_HALF_SLICE_DISABLE_123			0x3
+
+#define GEN6_VFE_DW4_URB_ENTRY_SIZE__MASK			0xffff0000
+#define GEN6_VFE_DW4_URB_ENTRY_SIZE__SHIFT			16
+#define GEN6_VFE_DW4_CURBE_SIZE__MASK				0x0000ffff
+#define GEN6_VFE_DW4_CURBE_SIZE__SHIFT				0
+
+#define GEN6_VFE_DW5_SCOREBOARD_ENABLE				(0x1 << 31)
+#define GEN6_VFE_DW5_SCOREBOARD_TYPE__MASK			0x40000000
+#define GEN6_VFE_DW5_SCOREBOARD_TYPE__SHIFT			30
+#define GEN6_VFE_DW5_SCOREBOARD_TYPE_STALLING			(0x0 << 30)
+#define GEN6_VFE_DW5_SCOREBOARD_TYPE_NON_STALLING		(0x1 << 30)
+#define GEN6_VFE_DW5_SCOREBOARD_MASK__MASK			0x000000ff
+#define GEN6_VFE_DW5_SCOREBOARD_MASK__SHIFT			0
+
+#define GEN6_VFE_DW6_SCOREBOARD_3_DELTA_Y__MASK			0xf0000000
+#define GEN6_VFE_DW6_SCOREBOARD_3_DELTA_Y__SHIFT		28
+#define GEN6_VFE_DW6_SCOREBOARD_3_DELTA_X__MASK			0x0f000000
+#define GEN6_VFE_DW6_SCOREBOARD_3_DELTA_X__SHIFT		24
+#define GEN6_VFE_DW6_SCOREBOARD_2_DELTA_Y__MASK			0x00f00000
+#define GEN6_VFE_DW6_SCOREBOARD_2_DELTA_Y__SHIFT		20
+#define GEN6_VFE_DW6_SCOREBOARD_2_DELTA_X__MASK			0x000f0000
+#define GEN6_VFE_DW6_SCOREBOARD_2_DELTA_X__SHIFT		16
+#define GEN6_VFE_DW6_SCOREBOARD_1_DELTA_Y__MASK			0x0000f000
+#define GEN6_VFE_DW6_SCOREBOARD_1_DELTA_Y__SHIFT		12
+#define GEN6_VFE_DW6_SCOREBOARD_1_DELTA_X__MASK			0x00000f00
+#define GEN6_VFE_DW6_SCOREBOARD_1_DELTA_X__SHIFT		8
+#define GEN6_VFE_DW6_SCOREBOARD_0_DELTA_Y__MASK			0x000000f0
+#define GEN6_VFE_DW6_SCOREBOARD_0_DELTA_Y__SHIFT		4
+#define GEN6_VFE_DW6_SCOREBOARD_0_DELTA_X__MASK			0x0000000f
+#define GEN6_VFE_DW6_SCOREBOARD_0_DELTA_X__SHIFT		0
+
+#define GEN6_VFE_DW7_SCOREBOARD_7_DELTA_Y__MASK			0xf0000000
+#define GEN6_VFE_DW7_SCOREBOARD_7_DELTA_Y__SHIFT		28
+#define GEN6_VFE_DW7_SCOREBOARD_7_DELTA_X__MASK			0x0f000000
+#define GEN6_VFE_DW7_SCOREBOARD_7_DELTA_X__SHIFT		24
+#define GEN6_VFE_DW7_SCOREBOARD_6_DELTA_Y__MASK			0x00f00000
+#define GEN6_VFE_DW7_SCOREBOARD_6_DELTA_Y__SHIFT		20
+#define GEN6_VFE_DW7_SCOREBOARD_6_DELTA_X__MASK			0x000f0000
+#define GEN6_VFE_DW7_SCOREBOARD_6_DELTA_X__SHIFT		16
+#define GEN6_VFE_DW7_SCOREBOARD_5_DELTA_Y__MASK			0x0000f000
+#define GEN6_VFE_DW7_SCOREBOARD_5_DELTA_Y__SHIFT		12
+#define GEN6_VFE_DW7_SCOREBOARD_5_DELTA_X__MASK			0x00000f00
+#define GEN6_VFE_DW7_SCOREBOARD_5_DELTA_X__SHIFT		8
+#define GEN6_VFE_DW7_SCOREBOARD_4_DELTA_Y__MASK			0x000000f0
+#define GEN6_VFE_DW7_SCOREBOARD_4_DELTA_Y__SHIFT		4
+#define GEN6_VFE_DW7_SCOREBOARD_4_DELTA_X__MASK			0x0000000f
+#define GEN6_VFE_DW7_SCOREBOARD_4_DELTA_X__SHIFT		0
+
+#define GEN6_MEDIA_CURBE_LOAD__SIZE				4
+
+
+
+#define GEN6_CURBE_LOAD_DW2_LEN__MASK				0x0001ffff
+#define GEN6_CURBE_LOAD_DW2_LEN__SHIFT				0
+
+
+#define GEN6_MEDIA_INTERFACE_DESCRIPTOR_LOAD__SIZE		4
+
+
+
+#define GEN6_IDRT_LOAD_DW2_LEN__MASK				0x0001ffff
+#define GEN6_IDRT_LOAD_DW2_LEN__SHIFT				0
+
+
+#define GEN6_MEDIA_STATE_FLUSH__SIZE				2
+
+
+#define GEN6_MEDIA_FLUSH_DW1_THREAD_COUNT_WATERMARK__MASK	0x00ff0000
+#define GEN6_MEDIA_FLUSH_DW1_THREAD_COUNT_WATERMARK__SHIFT	16
+#define GEN6_MEDIA_FLUSH_DW1_BARRIER_MASK__MASK			0x0000ffff
+#define GEN6_MEDIA_FLUSH_DW1_BARRIER_MASK__SHIFT		0
+
+#define GEN7_MEDIA_FLUSH_DW1_DISABLE_PREEMPTION			(0x1 << 8)
+#define GEN75_MEDIA_FLUSH_DW1_FLUSH_TO_GO			(0x1 << 7)
+#define GEN7_MEDIA_FLUSH_DW1_WATERMARK_REQUIRED			(0x1 << 6)
+#define GEN7_MEDIA_FLUSH_DW1_IDRT_OFFSET__MASK			0x0000003f
+#define GEN7_MEDIA_FLUSH_DW1_IDRT_OFFSET__SHIFT			0
+
+#define GEN7_GPGPU_WALKER__SIZE					11
+
+#define GEN7_GPGPU_DW0_INDIRECT_PARAM_ENABLE			(0x1 << 10)
+#define GEN7_GPGPU_DW0_PREDICATE_ENABLE				(0x1 << 8)
+
+#define GEN7_GPGPU_DW1_IDRT_OFFSET__MASK			0x0000003f
+#define GEN7_GPGPU_DW1_IDRT_OFFSET__SHIFT			0
+
+#define GEN7_GPGPU_DW2_SIMD_SIZE__MASK				0xc0000000
+#define GEN7_GPGPU_DW2_SIMD_SIZE__SHIFT				30
+#define GEN7_GPGPU_DW2_SIMD_SIZE_SIMD8				(0x0 << 30)
+#define GEN7_GPGPU_DW2_SIMD_SIZE_SIMD16				(0x1 << 30)
+#define GEN7_GPGPU_DW2_SIMD_SIZE_SIMD32				(0x2 << 30)
+#define GEN7_GPGPU_DW2_THREAD_MAX_Z__MASK			0x003f0000
+#define GEN7_GPGPU_DW2_THREAD_MAX_Z__SHIFT			16
+#define GEN7_GPGPU_DW2_THREAD_MAX_Y__MASK			0x00003f00
+#define GEN7_GPGPU_DW2_THREAD_MAX_Y__SHIFT			8
+#define GEN7_GPGPU_DW2_THREAD_MAX_X__MASK			0x0000003f
+#define GEN7_GPGPU_DW2_THREAD_MAX_X__SHIFT			0
+
+
+
+
+
+
+
+
+
+
+#endif /* GEN_RENDER_MEDIA_XML */
diff --git a/src/gallium/drivers/ilo/genhw/gen_render_surface.xml.h b/src/gallium/drivers/ilo/genhw/gen_render_surface.xml.h
index 2d2c07f..7d9dfdb 100644
--- a/src/gallium/drivers/ilo/genhw/gen_render_surface.xml.h
+++ b/src/gallium/drivers/ilo/genhw/gen_render_surface.xml.h
@@ -271,25 +271,6 @@ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 #define GEN75_SCS_GREEN						0x5
 #define GEN75_SCS_BLUE						0x6
 #define GEN75_SCS_ALPHA						0x7
-#define GEN6_MOCS_LLC__MASK					0x00000003
-#define GEN6_MOCS_LLC__SHIFT					0
-#define GEN6_MOCS_LLC_PTE					0x0
-#define GEN6_MOCS_LLC_UC					0x1
-#define GEN6_MOCS_LLC_ON					0x2
-#define GEN7_MOCS_LLC__MASK					0x00000002
-#define GEN7_MOCS_LLC__SHIFT					1
-#define GEN7_MOCS_LLC_PTE					(0x0 << 1)
-#define GEN7_MOCS_LLC_ON					(0x1 << 1)
-#define GEN75_MOCS_LLC__MASK					0x00000006
-#define GEN75_MOCS_LLC__SHIFT					1
-#define GEN75_MOCS_LLC_PTE					(0x0 << 1)
-#define GEN75_MOCS_LLC_UC					(0x1 << 1)
-#define GEN75_MOCS_LLC_ON					(0x2 << 1)
-#define GEN75_MOCS_LLC_ELLC					(0x3 << 1)
-#define GEN7_MOCS_L3__MASK					0x00000001
-#define GEN7_MOCS_L3__SHIFT					0
-#define GEN7_MOCS_L3_UC						0x0
-#define GEN7_MOCS_L3_ON						0x1
 #define GEN6_SURFACE_STATE__SIZE				8
 
 #define GEN6_SURFACE_DW0_TYPE__MASK				0xe0000000
diff --git a/src/gallium/drivers/ilo/genhw/genhw.h b/src/gallium/drivers/ilo/genhw/genhw.h
index 126a8b5..4c2cb57 100644
--- a/src/gallium/drivers/ilo/genhw/genhw.h
+++ b/src/gallium/drivers/ilo/genhw/genhw.h
@@ -31,9 +31,11 @@
 #include "gen_regs.xml.h"
 #include "gen_mi.xml.h"
 #include "gen_blitter.xml.h"
+#include "gen_render.xml.h"
 #include "gen_render_surface.xml.h"
 #include "gen_render_dynamic.xml.h"
 #include "gen_render_3d.xml.h"
+#include "gen_render_media.xml.h"
 #include "gen_eu_isa.xml.h"
 #include "gen_eu_message.xml.h"
 
diff --git a/src/gallium/drivers/ilo/ilo_builder_media.h b/src/gallium/drivers/ilo/ilo_builder_media.h
index 3a32631..bae329b 100644
--- a/src/gallium/drivers/ilo/ilo_builder_media.h
+++ b/src/gallium/drivers/ilo/ilo_builder_media.h
@@ -32,134 +32,169 @@
 #include "intel_winsys.h"
 
 #include "ilo_common.h"
+#include "ilo_shader.h"
 #include "ilo_builder.h"
 
+struct gen6_idrt_data {
+   const struct ilo_shader_state *cs;
+
+   uint32_t sampler_offset;
+   uint32_t binding_table_offset;
+
+   unsigned curbe_size;
+   unsigned thread_group_size;
+};
+
 static inline void
 gen6_MEDIA_VFE_STATE(struct ilo_builder *builder,
-                     int max_threads, int num_urb_entries,
-                     int urb_entry_size)
+                     unsigned curbe_alloc, bool use_slm)
 {
    const uint8_t cmd_len = 8;
-   uint32_t dw2, dw4, *dw;
+   const unsigned idrt_alloc =
+      ((ilo_dev_gen(builder->dev) >= ILO_GEN(7.5)) ? 64 : 32) * 32;
+   int max_threads;
+   uint32_t *dw;
 
-   ILO_DEV_ASSERT(builder->dev, 6, 6);
+   ILO_DEV_ASSERT(builder->dev, 7, 7.5);
 
-   dw2 = (max_threads - 1) << 16 |
-         num_urb_entries << 8 |
-         1 << 7 | /* Reset Gateway Timer */
-         1 << 6;  /* Bypass Gateway Control */
+   max_threads = builder->dev->thread_count;
 
-   dw4 = urb_entry_size << 16 |  /* URB Entry Allocation Size */
-         480;                    /* CURBE Allocation Size */
+   curbe_alloc = align(curbe_alloc, 32);
+   assert(idrt_alloc + curbe_alloc <= builder->dev->urb_size / (use_slm + 1));
 
    ilo_builder_batch_pointer(builder, cmd_len, &dw);
 
    dw[0] = GEN6_RENDER_CMD(MEDIA, MEDIA_VFE_STATE) | (cmd_len - 2);
    dw[1] = 0; /* scratch */
-   dw[2] = dw2;
-   dw[3] = 0; /* MBZ */
-   dw[4] = dw4;
-   dw[5] = 0; /* scoreboard */
+
+   dw[2] = (max_threads - 1) << GEN6_VFE_DW2_MAX_THREADS__SHIFT |
+           0 << GEN6_VFE_DW2_URB_ENTRY_COUNT__SHIFT |
+           GEN6_VFE_DW2_RESET_GATEWAY_TIMER |
+           GEN6_VFE_DW2_BYPASS_GATEWAY_CONTROL;
+   if (ilo_dev_gen(builder->dev) >= ILO_GEN(7))
+      dw[2] |= GEN7_VFE_DW2_GPGPU_MODE;
+
+   dw[3] = 0;
+
+   dw[4] = 0 << GEN6_VFE_DW4_URB_ENTRY_SIZE__SHIFT |
+           (curbe_alloc / 32);
+
+   dw[5] = 0;
    dw[6] = 0;
    dw[7] = 0;
 }
 
 static inline void
 gen6_MEDIA_CURBE_LOAD(struct ilo_builder *builder,
-                     uint32_t buf, int size)
+                      uint32_t offset, unsigned size)
 {
    const uint8_t cmd_len = 4;
    uint32_t *dw;
 
-   ILO_DEV_ASSERT(builder->dev, 6, 6);
+   ILO_DEV_ASSERT(builder->dev, 7, 7.5);
 
-   assert(buf % 32 == 0);
-   /* gen6_push_constant_buffer() allocates buffers in 256-bit units */
-   size = align(size, 32);
+   assert(offset % 32 == 0 && size % 32 == 0);
+   /* GPU hangs if size is zero */
+   assert(size);
 
    ilo_builder_batch_pointer(builder, cmd_len, &dw);
 
    dw[0] = GEN6_RENDER_CMD(MEDIA, MEDIA_CURBE_LOAD) | (cmd_len - 2);
-   dw[1] = 0; /* MBZ */
+   dw[1] = 0;
    dw[2] = size;
-   dw[3] = buf;
+   dw[3] = offset;
 }
 
 static inline void
 gen6_MEDIA_INTERFACE_DESCRIPTOR_LOAD(struct ilo_builder *builder,
-                                     uint32_t offset, int num_ids)
+                                     uint32_t offset, unsigned size)
 {
    const uint8_t cmd_len = 4;
+   const unsigned idrt_alloc =
+      ((ilo_dev_gen(builder->dev) >= ILO_GEN(7.5)) ? 64 : 32) * 32;
    uint32_t *dw;
 
-   ILO_DEV_ASSERT(builder->dev, 6, 6);
+   ILO_DEV_ASSERT(builder->dev, 7, 7.5);
 
-   assert(offset % 32 == 0);
+   assert(offset % 32 == 0 && size % 32 == 0);
+   assert(size && size <= idrt_alloc);
 
    ilo_builder_batch_pointer(builder, cmd_len, &dw);
 
    dw[0] = GEN6_RENDER_CMD(MEDIA, MEDIA_INTERFACE_DESCRIPTOR_LOAD) |
            (cmd_len - 2);
-   dw[1] = 0; /* MBZ */
-   /* every ID has 8 DWords */
-   dw[2] = num_ids * 8 * 4;
+   dw[1] = 0;
+   dw[2] = size;
    dw[3] = offset;
 }
 
 static inline void
-gen6_MEDIA_GATEWAY_STATE(struct ilo_builder *builder,
-                         int id, int byte, int thread_count)
+gen6_MEDIA_STATE_FLUSH(struct ilo_builder *builder)
 {
    const uint8_t cmd_len = 2;
    uint32_t *dw;
 
-   ILO_DEV_ASSERT(builder->dev, 6, 6);
+   ILO_DEV_ASSERT(builder->dev, 7, 7.5);
 
    ilo_builder_batch_pointer(builder, cmd_len, &dw);
 
-   dw[0] = GEN6_RENDER_CMD(MEDIA, MEDIA_GATEWAY_STATE) | (cmd_len - 2);
-   dw[1] = id << 16 |
-           byte << 8 |
-           thread_count;
+   dw[0] = GEN6_RENDER_CMD(MEDIA, MEDIA_STATE_FLUSH) | (cmd_len - 2);
+   dw[1] = 0;
 }
 
 static inline void
-gen6_MEDIA_STATE_FLUSH(struct ilo_builder *builder,
-                       int thread_count_water_mark,
-                       int barrier_mask)
+gen7_GPGPU_WALKER(struct ilo_builder *builder,
+                  const unsigned thread_group_offset[3],
+                  const unsigned thread_group_dim[3],
+                  unsigned thread_group_size,
+                  unsigned simd_size)
 {
-   const uint8_t cmd_len = 2;
+   const uint8_t cmd_len = 11;
+   uint32_t right_execmask, bottom_execmask;
+   unsigned thread_count;
    uint32_t *dw;
 
-   ILO_DEV_ASSERT(builder->dev, 6, 6);
+   ILO_DEV_ASSERT(builder->dev, 7, 7.5);
+
+   assert(simd_size == 16 || simd_size == 8);
+
+   thread_count = (thread_group_size + simd_size - 1) / simd_size;
+   assert(thread_count <= 64);
+
+   right_execmask = thread_group_size % simd_size;
+   if (right_execmask)
+      right_execmask = (1 << right_execmask) - 1;
+   else
+      right_execmask = (1 << simd_size) - 1;
+
+   bottom_execmask = 0xffffffff;
 
    ilo_builder_batch_pointer(builder, cmd_len, &dw);
 
-   dw[0] = GEN6_RENDER_CMD(MEDIA, MEDIA_STATE_FLUSH) | (cmd_len - 2);
-   dw[1] = thread_count_water_mark << 16 |
-           barrier_mask;
-}
+   dw[0] = GEN7_RENDER_CMD(MEDIA, GPGPU_WALKER) | (cmd_len - 2);
+   dw[1] = 0; /* always first IDRT */
 
-static inline void
-gen6_MEDIA_OBJECT_WALKER(struct ilo_builder *builder)
-{
-   assert(!"MEDIA_OBJECT_WALKER unsupported");
-}
+   dw[2] = (thread_count - 1) << GEN7_GPGPU_DW2_THREAD_MAX_X__SHIFT;
+   if (simd_size == 16)
+      dw[2] |= GEN7_GPGPU_DW2_SIMD_SIZE_SIMD16;
+   else
+      dw[2] |= GEN7_GPGPU_DW2_SIMD_SIZE_SIMD8;
 
-static inline void
-gen7_GPGPU_WALKER(struct ilo_builder *builder)
-{
-   assert(!"GPGPU_WALKER unsupported");
+   dw[3] = thread_group_offset[0];
+   dw[4] = thread_group_dim[0];
+   dw[5] = thread_group_offset[1];
+   dw[6] = thread_group_dim[1];
+   dw[7] = thread_group_offset[2];
+   dw[8] = thread_group_dim[2];
+
+   dw[9] = right_execmask;
+   dw[10] = bottom_execmask;
 }
 
 static inline uint32_t
 gen6_INTERFACE_DESCRIPTOR_DATA(struct ilo_builder *builder,
-                               const struct ilo_shader_state **cs,
-                               uint32_t *sampler_state,
-                               int *num_samplers,
-                               uint32_t *binding_table_state,
-                               int *num_surfaces,
-                               int num_ids)
+                               const struct gen6_idrt_data *data,
+                               int idrt_count)
 {
    /*
     * From the Sandy Bridge PRM, volume 2 part 2, page 34:
@@ -175,25 +210,60 @@ gen6_INTERFACE_DESCRIPTOR_DATA(struct ilo_builder *builder,
     *      aligned address of the Interface Descriptor data."
     */
    const int state_align = 32;
-   const int state_len = (32 / 4) * num_ids;
+   const int state_len = (32 / 4) * idrt_count;
    uint32_t state_offset, *dw;
    int i;
 
-   ILO_DEV_ASSERT(builder->dev, 6, 6);
+   ILO_DEV_ASSERT(builder->dev, 7, 7.5);
 
-   state_offset = ilo_builder_state_pointer(builder,
+   state_offset = ilo_builder_dynamic_pointer(builder,
          ILO_BUILDER_ITEM_BLOB, state_align, state_len, &dw);
 
-   for (i = 0; i < num_ids; i++) {
-      dw[0] = ilo_shader_get_kernel_offset(cs[i]);
-      dw[1] = 1 << 18; /* SPF */
-      dw[2] = sampler_state[i] |
-              (num_samplers[i] + 3) / 4 << 2;
-      dw[3] = binding_table_state[i] |
-              num_surfaces[i];
-      dw[4] = 0 << 16 |  /* CURBE Read Length */
-              0;         /* CURBE Read Offset */
-      dw[5] = 0; /* Barrier ID */
+   for (i = 0; i < idrt_count; i++) {
+      const struct gen6_idrt_data *idrt = &data[i];
+      const struct ilo_shader_state *cs = idrt->cs;
+      unsigned sampler_count, bt_size, slm_size;
+
+      sampler_count =
+         ilo_shader_get_kernel_param(cs, ILO_KERNEL_SAMPLER_COUNT);
+      assert(sampler_count <= 16);
+      sampler_count = (sampler_count + 3) / 4;
+
+      bt_size =
+         ilo_shader_get_kernel_param(cs, ILO_KERNEL_SURFACE_TOTAL_COUNT);
+      if (bt_size > 31)
+         bt_size = 31;
+
+      slm_size = ilo_shader_get_kernel_param(cs, ILO_KERNEL_CS_LOCAL_SIZE);
+
+      assert(idrt->curbe_size / 32 <= 63);
+
+      dw[0] = ilo_shader_get_kernel_offset(idrt->cs);
+      dw[1] = 0;
+      dw[2] = idrt->sampler_offset |
+              sampler_count << GEN6_IDRT_DW2_SAMPLER_COUNT__SHIFT;
+      dw[3] = idrt->binding_table_offset |
+              bt_size << GEN6_IDRT_DW3_BINDING_TABLE_SIZE__SHIFT;
+
+      dw[4] = (idrt->curbe_size / 32) << GEN6_IDRT_DW4_CURBE_READ_LEN__SHIFT |
+              0 << GEN6_IDRT_DW4_CURBE_READ_OFFSET__SHIFT;
+
+      if (ilo_dev_gen(builder->dev) >= ILO_GEN(7)) {
+         dw[5] = GEN7_IDRT_DW5_ROUNDING_MODE_RTNE;
+
+         if (slm_size) {
+            assert(slm_size <= 64 * 1024);
+            slm_size = util_next_power_of_two((slm_size + 4095) / 4096);
+
+            dw[5] |= GEN7_IDRT_DW5_BARRIER_ENABLE |
+                     slm_size << GEN7_IDRT_DW5_SLM_SIZE__SHIFT |
+                     idrt->thread_group_size <<
+                        GEN7_IDRT_DW5_THREAD_GROUP_SIZE__SHIFT;
+         }
+      } else {
+         dw[5] = 0;
+      }
+
       dw[6] = 0;
       dw[7] = 0;
 
diff --git a/src/gallium/drivers/ilo/ilo_builder_render.h b/src/gallium/drivers/ilo/ilo_builder_render.h
index f8a9838..aa09c87 100644
--- a/src/gallium/drivers/ilo/ilo_builder_render.h
+++ b/src/gallium/drivers/ilo/ilo_builder_render.h
@@ -57,8 +57,17 @@ gen6_PIPELINE_SELECT(struct ilo_builder *builder, int pipeline)
 
    ILO_DEV_ASSERT(builder->dev, 6, 7.5);
 
-   /* 3D or media */
-   assert(pipeline == 0x0 || pipeline == 0x1);
+   switch (pipeline) {
+   case GEN6_PIPELINE_SELECT_DW0_SELECT_3D:
+   case GEN6_PIPELINE_SELECT_DW0_SELECT_MEDIA:
+      break;
+   case GEN7_PIPELINE_SELECT_DW0_SELECT_GPGPU:
+      assert(ilo_dev_gen(builder->dev) >= ILO_GEN(7));
+      break;
+   default:
+      assert(!"unknown pipeline");
+      break;
+   }
 
    ilo_builder_batch_write(builder, cmd_len, &dw0);
 }
diff --git a/src/gallium/drivers/ilo/ilo_common.h b/src/gallium/drivers/ilo/ilo_common.h
index f83aa91..23a7080 100644
--- a/src/gallium/drivers/ilo/ilo_common.h
+++ b/src/gallium/drivers/ilo/ilo_common.h
@@ -86,6 +86,8 @@ struct ilo_dev_info {
    int gen_opaque;
 
    int gt;
+   int eu_count;
+   int thread_count;
    int urb_size;
 };
 
diff --git a/src/gallium/drivers/ilo/ilo_gpgpu.c b/src/gallium/drivers/ilo/ilo_gpgpu.c
index fd756a0..9a2ca00 100644
--- a/src/gallium/drivers/ilo/ilo_gpgpu.c
+++ b/src/gallium/drivers/ilo/ilo_gpgpu.c
@@ -25,18 +25,88 @@
  *    Chia-I Wu <olv@lunarg.com>
  */
 
+#include "util/u_upload_mgr.h"
 #include "ilo_context.h"
+#include "ilo_render.h"
+#include "ilo_shader.h"
 #include "ilo_gpgpu.h"
 
-/*
- * This is a placeholder.  We will need something similar to ilo_render.
- */
+static void
+launch_grid(struct ilo_context *ilo,
+            const uint *block_layout, const uint *grid_layout,
+            const struct pipe_constant_buffer *input, uint32_t pc)
+{
+   const unsigned grid_offset[3] = { 0, 0, 0 };
+   const unsigned thread_group_size =
+      block_layout[0] * block_layout[1] * block_layout[2];
+   int max_len, before_space;
+
+   ilo_cp_set_owner(ilo->cp, INTEL_RING_RENDER, NULL);
+
+   max_len = ilo_render_get_launch_grid_len(ilo->render, &ilo->state_vector);
+   max_len += ilo_render_get_flush_len(ilo->render) * 2;
+
+   if (max_len > ilo_cp_space(ilo->cp)) {
+      ilo_cp_submit(ilo->cp, "out of space");
+      assert(max_len <= ilo_cp_space(ilo->cp));
+   }
+
+   before_space = ilo_cp_space(ilo->cp);
+
+   while (true) {
+      struct ilo_builder_snapshot snapshot;
+
+      ilo_builder_batch_snapshot(&ilo->cp->builder, &snapshot);
+
+      ilo_render_emit_launch_grid(ilo->render, &ilo->state_vector,
+            grid_offset, grid_layout, thread_group_size, input, pc);
+
+      if (!ilo_builder_validate(&ilo->cp->builder, 0, NULL)) {
+         ilo_builder_batch_restore(&ilo->cp->builder, &snapshot);
+
+         /* flush and try again */
+         if (ilo_builder_batch_used(&ilo->cp->builder)) {
+            ilo_cp_submit(ilo->cp, "out of aperture");
+            continue;
+         }
+      }
+
+      break;
+   }
+
+   /* sanity check size estimation */
+   assert(before_space - ilo_cp_space(ilo->cp) <= max_len);
+}
 
 static void
 ilo_launch_grid(struct pipe_context *pipe,
                 const uint *block_layout, const uint *grid_layout,
                 uint32_t pc, const void *input)
 {
+   struct ilo_context *ilo = ilo_context(pipe);
+   struct ilo_shader_state *cs = ilo->state_vector.cs;
+   struct pipe_constant_buffer input_buf;
+
+   memset(&input_buf, 0, sizeof(input_buf));
+
+   input_buf.buffer_size =
+      ilo_shader_get_kernel_param(cs, ILO_KERNEL_CS_INPUT_SIZE);
+   if (input_buf.buffer_size) {
+      u_upload_data(ilo->uploader, 0, input_buf.buffer_size, input,
+            &input_buf.buffer_offset, &input_buf.buffer);
+   }
+
+   ilo_shader_cache_upload(ilo->shader_cache, &ilo->cp->builder);
+
+   launch_grid(ilo, block_layout, grid_layout, &input_buf, pc);
+
+   ilo_render_invalidate_hw(ilo->render);
+
+   if (ilo_debug & ILO_DEBUG_NOCACHE)
+      ilo_render_emit_flush(ilo->render);
+
+   if (input_buf.buffer_size)
+      pipe_resource_reference(&input_buf.buffer, NULL);
 }
 
 /**
diff --git a/src/gallium/drivers/ilo/ilo_render.c b/src/gallium/drivers/ilo/ilo_render.c
index 945d4cd..00b57b8 100644
--- a/src/gallium/drivers/ilo/ilo_render.c
+++ b/src/gallium/drivers/ilo/ilo_render.c
@@ -456,3 +456,42 @@ ilo_render_emit_draw(struct ilo_render *render,
 
    draw_session_end(render, vec, &session);
 }
+
+int
+ilo_render_get_launch_grid_len(const struct ilo_render *render,
+                               const struct ilo_state_vector *vec)
+{
+   ILO_DEV_ASSERT(render->dev, 7, 7.5);
+
+   return ilo_render_get_launch_grid_surface_states_len(render, vec) +
+          ilo_render_get_launch_grid_dynamic_states_len(render, vec) +
+          ilo_render_get_launch_grid_commands_len(render, vec);
+}
+
+void
+ilo_render_emit_launch_grid(struct ilo_render *render,
+                            const struct ilo_state_vector *vec,
+                            const unsigned thread_group_offset[3],
+                            const unsigned thread_group_dim[3],
+                            unsigned thread_group_size,
+                            const struct pipe_constant_buffer *input,
+                            uint32_t pc)
+{
+   struct ilo_render_launch_grid_session session;
+
+   ILO_DEV_ASSERT(render->dev, 7, 7.5);
+
+   assert(input->buffer);
+
+   memset(&session, 0, sizeof(session));
+
+   session.thread_group_offset = thread_group_offset;
+   session.thread_group_dim = thread_group_dim;
+   session.thread_group_size = thread_group_size;
+   session.input = input;
+   session.pc = pc;
+
+   ilo_render_emit_launch_grid_surface_states(render, vec, &session);
+   ilo_render_emit_launch_grid_dynamic_states(render, vec, &session);
+   ilo_render_emit_launch_grid_commands(render, vec, &session);
+}
diff --git a/src/gallium/drivers/ilo/ilo_render.h b/src/gallium/drivers/ilo/ilo_render.h
index 0cf1d03..a85b280 100644
--- a/src/gallium/drivers/ilo/ilo_render.h
+++ b/src/gallium/drivers/ilo/ilo_render.h
@@ -30,6 +30,7 @@
 
 #include "ilo_common.h"
 
+struct pipe_constant_buffer;
 struct ilo_blitter;
 struct ilo_builder;
 struct ilo_query;
@@ -87,4 +88,17 @@ void
 ilo_render_emit_draw(struct ilo_render *render,
                      const struct ilo_state_vector *vec);
 
+int
+ilo_render_get_launch_grid_len(const struct ilo_render *render,
+                               const struct ilo_state_vector *vec);
+
+void
+ilo_render_emit_launch_grid(struct ilo_render *render,
+                            const struct ilo_state_vector *vec,
+                            const unsigned thread_group_offset[3],
+                            const unsigned thread_group_dim[3],
+                            unsigned thread_group_size,
+                            const struct pipe_constant_buffer *input,
+                            uint32_t pc);
+
 #endif /* ILO_RENDER_H */
diff --git a/src/gallium/drivers/ilo/ilo_render_dynamic.c b/src/gallium/drivers/ilo/ilo_render_dynamic.c
index 5c36873..07d5664 100644
--- a/src/gallium/drivers/ilo/ilo_render_dynamic.c
+++ b/src/gallium/drivers/ilo/ilo_render_dynamic.c
@@ -28,6 +28,7 @@
 #include "ilo_common.h"
 #include "ilo_blitter.h"
 #include "ilo_builder_3d.h"
+#include "ilo_builder_media.h"
 #include "ilo_state.h"
 #include "ilo_render_gen.h"
 
@@ -440,3 +441,108 @@ ilo_render_emit_rectlist_dynamic_states(struct ilo_render *render,
    assert(ilo_builder_dynamic_used(render->builder) <= dynamic_used +
          ilo_render_get_rectlist_dynamic_states_len(render, blitter));
 }
+
+static void
+gen6_emit_launch_grid_dynamic_samplers(struct ilo_render *r,
+                                       const struct ilo_state_vector *vec,
+                                       struct ilo_render_launch_grid_session *session)
+{
+   const unsigned shader_type = PIPE_SHADER_COMPUTE;
+   const struct ilo_shader_state *cs = vec->cs;
+   const struct ilo_sampler_cso * const *samplers =
+      vec->sampler[shader_type].cso;
+   const struct pipe_sampler_view * const *views =
+      (const struct pipe_sampler_view **) vec->view[shader_type].states;
+   int sampler_count, i;
+
+   ILO_DEV_ASSERT(r->dev, 7, 7.5);
+
+   sampler_count = ilo_shader_get_kernel_param(cs, ILO_KERNEL_SAMPLER_COUNT);
+
+   assert(sampler_count <= Elements(vec->view[shader_type].states) &&
+          sampler_count <= Elements(vec->sampler[shader_type].cso));
+
+   for (i = 0; i < sampler_count; i++) {
+      r->state.cs.SAMPLER_BORDER_COLOR_STATE[i] = (samplers[i]) ?
+         gen6_SAMPLER_BORDER_COLOR_STATE(r->builder, samplers[i]) : 0;
+   }
+
+   r->state.cs.SAMPLER_STATE = gen6_SAMPLER_STATE(r->builder, samplers, views,
+         r->state.cs.SAMPLER_BORDER_COLOR_STATE, sampler_count);
+}
+
+static void
+gen6_emit_launch_grid_dynamic_pcb(struct ilo_render *r,
+                                  const struct ilo_state_vector *vec,
+                                  struct ilo_render_launch_grid_session *session)
+{
+   r->state.cs.PUSH_CONSTANT_BUFFER = 0;
+   r->state.cs.PUSH_CONSTANT_BUFFER_size = 0;
+}
+
+static void
+gen6_emit_launch_grid_dynamic_idrt(struct ilo_render *r,
+                                   const struct ilo_state_vector *vec,
+                                   struct ilo_render_launch_grid_session *session)
+{
+   const struct ilo_shader_state *cs = vec->cs;
+   struct gen6_idrt_data data;
+
+   ILO_DEV_ASSERT(r->dev, 7, 7.5);
+
+   memset(&data, 0, sizeof(data));
+
+   data.cs = cs;
+   data.sampler_offset = r->state.cs.SAMPLER_STATE;
+   data.binding_table_offset = r->state.cs.BINDING_TABLE_STATE;
+
+   data.curbe_size = r->state.cs.PUSH_CONSTANT_BUFFER_size;
+   data.thread_group_size = session->thread_group_size;
+
+   session->idrt = gen6_INTERFACE_DESCRIPTOR_DATA(r->builder, &data, 1);
+   session->idrt_size = 32;
+}
+
+int
+ilo_render_get_launch_grid_dynamic_states_len(const struct ilo_render *render,
+                                              const struct ilo_state_vector *vec)
+{
+   const int alignment = 32 / 4;
+   int num_samplers;
+   int len = 0;
+
+   ILO_DEV_ASSERT(render->dev, 7, 7.5);
+
+   num_samplers = ilo_shader_get_kernel_param(vec->cs,
+         ILO_KERNEL_SAMPLER_COUNT);
+
+   /* SAMPLER_STATE array and SAMPLER_BORDER_COLORs */
+   if (num_samplers) {
+      /* prefetches are done in multiples of 4 */
+      num_samplers = align(num_samplers, 4);
+
+      len += align(GEN6_SAMPLER_STATE__SIZE * num_samplers, alignment) +
+         align(GEN6_SAMPLER_BORDER_COLOR__SIZE, alignment) * num_samplers;
+   }
+
+   len += GEN6_INTERFACE_DESCRIPTOR_DATA__SIZE;
+
+   return len;
+}
+
+void
+ilo_render_emit_launch_grid_dynamic_states(struct ilo_render *render,
+                                           const struct ilo_state_vector *vec,
+                                           struct ilo_render_launch_grid_session *session)
+{
+   const unsigned dynamic_used = ilo_builder_dynamic_used(render->builder);
+
+   ILO_DEV_ASSERT(render->dev, 7, 7.5);
+
+   gen6_emit_launch_grid_dynamic_samplers(render, vec, session);
+   gen6_emit_launch_grid_dynamic_pcb(render, vec, session);
+   gen6_emit_launch_grid_dynamic_idrt(render, vec, session);
+
+   assert(ilo_builder_dynamic_used(render->builder) <= dynamic_used +
+         ilo_render_get_launch_grid_dynamic_states_len(render, vec));
+}
diff --git a/src/gallium/drivers/ilo/ilo_render_gen.h b/src/gallium/drivers/ilo/ilo_render_gen.h
index 32d1237..28d5030 100644
--- a/src/gallium/drivers/ilo/ilo_render_gen.h
+++ b/src/gallium/drivers/ilo/ilo_render_gen.h
@@ -118,6 +118,15 @@ struct ilo_render {
          uint32_t PUSH_CONSTANT_BUFFER;
          int PUSH_CONSTANT_BUFFER_size;
       } wm;
+
+      struct {
+         uint32_t BINDING_TABLE_STATE;
+         uint32_t SURFACE_STATE[ILO_MAX_SURFACES];
+         uint32_t SAMPLER_STATE;
+         uint32_t SAMPLER_BORDER_COLOR_STATE[ILO_MAX_SAMPLERS];
+         uint32_t PUSH_CONSTANT_BUFFER;
+         int PUSH_CONSTANT_BUFFER_size;
+      } cs;
    } state;
 };
 
@@ -157,6 +166,17 @@ struct ilo_render_rectlist_session {
    uint32_t vb_end;
 };
 
+struct ilo_render_launch_grid_session {
+   const unsigned *thread_group_offset;
+   const unsigned *thread_group_dim;
+   unsigned thread_group_size;
+   const struct pipe_constant_buffer *input;
+   uint32_t pc;
+
+   uint32_t idrt;
+   int idrt_size;
+};
+
 int
 ilo_render_get_draw_commands_len_gen6(const struct ilo_render *render,
                                       const struct ilo_state_vector *vec);
@@ -239,6 +259,15 @@ ilo_render_emit_rectlist_commands(struct ilo_render *render,
 }
 
 int
+ilo_render_get_launch_grid_commands_len(const struct ilo_render *render,
+                                        const struct ilo_state_vector *vec);
+
+void
+ilo_render_emit_launch_grid_commands(struct ilo_render *render,
+                                     const struct ilo_state_vector *vec,
+                                     const struct ilo_render_launch_grid_session *session);
+
+int
 ilo_render_get_draw_dynamic_states_len(const struct ilo_render *render,
                                        const struct ilo_state_vector *vec);
 
@@ -257,6 +286,15 @@ ilo_render_emit_rectlist_dynamic_states(struct ilo_render *render,
                                         struct ilo_render_rectlist_session *session);
 
 int
+ilo_render_get_launch_grid_dynamic_states_len(const struct ilo_render *render,
+                                              const struct ilo_state_vector *vec);
+
+void
+ilo_render_emit_launch_grid_dynamic_states(struct ilo_render *render,
+                                           const struct ilo_state_vector *vec,
+                                           struct ilo_render_launch_grid_session *session);
+
+int
 ilo_render_get_draw_surface_states_len(const struct ilo_render *render,
                                        const struct ilo_state_vector *vec);
 
@@ -265,6 +303,15 @@ ilo_render_emit_draw_surface_states(struct ilo_render *render,
                                     const struct ilo_state_vector *vec,
                                     struct ilo_render_draw_session *session);
 
+int
+ilo_render_get_launch_grid_surface_states_len(const struct ilo_render *render,
+                                              const struct ilo_state_vector *vec);
+
+void
+ilo_render_emit_launch_grid_surface_states(struct ilo_render *render,
+                                           const struct ilo_state_vector *vec,
+                                           struct ilo_render_launch_grid_session *session);
+
 void
 gen6_wa_pre_pipe_control(struct ilo_render *r, uint32_t dw1);
 
diff --git a/src/gallium/drivers/ilo/ilo_render_media.c b/src/gallium/drivers/ilo/ilo_render_media.c
new file mode 100644
index 0000000..f6b466c
--- /dev/null
+++ b/src/gallium/drivers/ilo/ilo_render_media.c
@@ -0,0 +1,229 @@
+/*
+ * Mesa 3-D graphics library
+ *
+ * Copyright (C) 2014 LunarG, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included
+ * in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Chia-I Wu <olv@lunarg.com>
+ */
+
+#include "genhw/genhw.h"
+
+#include "ilo_builder_media.h"
+#include "ilo_builder_mi.h"
+#include "ilo_builder_render.h"
+#include "ilo_state.h"
+#include "ilo_render_gen.h"
+
+struct gen7_l3_config {
+   int slm;
+   int urb;
+   int rest;
+   int dc;
+   int ro;
+   int is;
+   int c;
+   int t;
+};
+
+/*
+ * From the Ivy Bridge PRM, volume 1 part 7, page 10:
+ *
+ *     "Normal L3/URB mode (non-SLM mode), uses all 4 banks of L3 equally to
+ *      distribute cycles. The following allocation is a suggested programming
+ *      model. Note all numbers below are given in KBytes."
+ *
+ * From the Haswell PRM, volume 7, page 662:
+ *
+ *     "The configuration for {SLM = 0,URB = 224,DC = 32,RO = 256,IS = 0,C =
+ *      0,T =0, SUM 512} was validated as a later supported configuration and
+ *      can be utilized if desired."
+ */
+static const struct gen7_l3_config gen7_l3_non_slm_configs[] = {
+   /*       SLM   URB  Rest    DC    RO   I/S     C     T */
+   [0] = {    0,  256,    0,    0,  256,    0,    0,    0, },
+   [1] = {    0,  256,    0,  128,  128,    0,    0,    0, },
+   [2] = {    0,  256,    0,   32,    0,   64,   32,  128, },
+   [3] = {    0,  224,    0,   64,    0,   64,   32,  128, },
+   [4] = {    0,  224,    0,  128,    0,   64,   32,   64, },
+   [5] = {    0,  224,    0,   64,    0,  128,   32,   64, },
+   [6] = {    0,  224,    0,    0,    0,  128,   32,  128, },
+   [7] = {    0,  256,    0,    0,    0,  128,    0,  128, },
+
+   [8] = {    0,  224,    0,   32,  256,    0,    0,    0, },
+};
+
+/*
+ * From the Ivy Bridge PRM, volume 1 part 7, page 11:
+ *
+ *     "With the existence of Shared Local Memory, a 64KB chunk from each of
+ *      the 2 L3 banks will be reserved for SLM usage. The remaining cache
+ *      space is divided between the remaining clients. SLM allocation is done
+ *      via reducing the number of ways on the two banks from 64 to 32."
+ *
+ * From the Haswell PRM, volume 7, page 662:
+ *
+ *     "The configuration for {SLM = 128,URB = 128,DC = 0,RO = 256,IS = 0,C =
+ *      0,T =0, SUM 512} was validated as a later supported configuration and
+ *      can be utilized if desired. For this configuration, global atomics
+ *      must be programmed to be in GTI."
+ */
+static const struct gen7_l3_config gen7_l3_slm_configs[] = {
+   /*       SLM   URB  Rest    DC    RO   I/S     C     T */
+   [0] = {  128,  128,    0,  128,  128,    0,    0,    0, },
+   [1] = {  128,  128,    0,   64,    0,   64,   64,   64, },
+   [2] = {  128,  128,    0,   32,    0,   64,   32,  128, },
+   [3] = {  128,  128,    0,   32,    0,  128,   32,   64, },
+
+   [4] = {  128,  128,    0,    0,  256,    0,    0,    0, },
+};
+
+static void
+gen7_launch_grid_l3(struct ilo_render *r, bool use_slm)
+{
+   uint32_t l3sqcreg1, l3cntlreg2, l3cntlreg3;
+   const struct gen7_l3_config *conf;
+
+   /*
+    * This function mostly follows what beignet does.  I do not know why, for
+    * example, CON4DCUNC should be reset.  I do not know if it should be set
+    * again after launch_grid().
+    */
+
+   ILO_DEV_ASSERT(r->dev, 7, 7.5);
+
+   if (use_slm)
+      conf = &gen7_l3_slm_configs[1];
+   else
+      conf = &gen7_l3_non_slm_configs[4];
+
+   /* unset GEN7_REG_L3SQCREG1_CON4DCUNC (without readback first) */
+   if (ilo_dev_gen(r->dev) >= ILO_GEN(7.5)) {
+      l3sqcreg1 = GEN75_REG_L3SQCREG1_SQGPCI_24 |
+                  GEN75_REG_L3SQCREG1_SQHPCI_8;
+   } else {
+      l3sqcreg1 = GEN7_REG_L3SQCREG1_SQGHPCI_18_6;
+   }
+
+   l3cntlreg2 = (conf->dc / 8) << GEN7_REG_L3CNTLREG2_DCWASS__SHIFT |
+                (conf->ro / 8) << GEN7_REG_L3CNTLREG2_RDOCPL__SHIFT |
+                (conf->urb / 8) << GEN7_REG_L3CNTLREG2_URBALL__SHIFT;
+
+   l3cntlreg3 = (conf->t / 8) << GEN7_REG_L3CNTLREG3_TXWYALL__SHIFT |
+                (conf->c / 8) << GEN7_REG_L3CNTLREG3_CTWYALL__SHIFT |
+                (conf->is / 8) << GEN7_REG_L3CNTLREG3_ISWYALL__SHIFT;
+
+   if (conf->slm) {
+      /*
+       * From the Ivy Bridge PRM, volume 1 part 7, page 11:
+       *
+       *     "Note that URB needs to be set as low b/w client in SLM mode,
+       *      else the hash will fail. This is a required s/w model."
+       */
+      l3cntlreg2 |= GEN7_REG_L3CNTLREG2_URBSLMB |
+                    GEN7_REG_L3CNTLREG2_SLMMENB;
+   }
+
+   gen6_MI_LOAD_REGISTER_IMM(r->builder, GEN7_REG_L3SQCREG1, l3sqcreg1);
+   gen6_MI_LOAD_REGISTER_IMM(r->builder, GEN7_REG_L3CNTLREG2, l3cntlreg2);
+   gen6_MI_LOAD_REGISTER_IMM(r->builder, GEN7_REG_L3CNTLREG3, l3cntlreg3);
+}
+
+int
+ilo_render_get_launch_grid_commands_len(const struct ilo_render *render,
+                                        const struct ilo_state_vector *vec)
+{
+   static int len;
+
+   ILO_DEV_ASSERT(render->dev, 7, 7.5);
+
+   if (!len) {
+      len +=
+         GEN6_PIPELINE_SELECT__SIZE +
+         GEN6_STATE_BASE_ADDRESS__SIZE +
+         GEN6_MEDIA_VFE_STATE__SIZE +
+         GEN6_MEDIA_CURBE_LOAD__SIZE +
+         GEN6_MEDIA_INTERFACE_DESCRIPTOR_LOAD__SIZE +
+         GEN6_MEDIA_STATE_FLUSH__SIZE;
+
+      len += ilo_render_get_flush_len(render) * 3;
+
+      if (ilo_dev_gen(render->dev) >= ILO_GEN(7)) {
+         len += GEN6_MI_LOAD_REGISTER_IMM__SIZE * 3 * 2;
+         len += GEN7_GPGPU_WALKER__SIZE;
+      }
+   }
+
+   return len;
+}
+
+void
+ilo_render_emit_launch_grid_commands(struct ilo_render *render,
+                                     const struct ilo_state_vector *vec,
+                                     const struct ilo_render_launch_grid_session *session)
+{
+   const unsigned batch_used = ilo_builder_batch_used(render->builder);
+   const uint32_t pcb = render->state.cs.PUSH_CONSTANT_BUFFER;
+   const int pcb_size = render->state.cs.PUSH_CONSTANT_BUFFER_size;
+   int simd_size;
+   bool use_slm;
+
+   ILO_DEV_ASSERT(render->dev, 7, 7.5);
+
+   simd_size = ilo_shader_get_kernel_param(vec->cs, ILO_KERNEL_CS_SIMD_SIZE);
+   use_slm = ilo_shader_get_kernel_param(vec->cs, ILO_KERNEL_CS_LOCAL_SIZE);
+
+   ilo_render_emit_flush(render);
+
+   if (ilo_dev_gen(render->dev) >= ILO_GEN(7)) {
+      gen7_launch_grid_l3(render, use_slm);
+      ilo_render_emit_flush(render);
+
+      gen6_PIPELINE_SELECT(render->builder,
+            GEN7_PIPELINE_SELECT_DW0_SELECT_GPGPU);
+   } else {
+      gen6_PIPELINE_SELECT(render->builder,
+            GEN6_PIPELINE_SELECT_DW0_SELECT_MEDIA);
+   }
+
+   gen6_state_base_address(render->builder, true);
+
+   gen6_MEDIA_VFE_STATE(render->builder, pcb_size, use_slm);
+
+   if (pcb_size)
+      gen6_MEDIA_CURBE_LOAD(render->builder, pcb, pcb_size);
+
+   gen6_MEDIA_INTERFACE_DESCRIPTOR_LOAD(render->builder,
+         session->idrt, session->idrt_size);
+
+   gen7_GPGPU_WALKER(render->builder, session->thread_group_offset,
+         session->thread_group_dim, session->thread_group_size, simd_size);
+
+   gen6_MEDIA_STATE_FLUSH(render->builder);
+
+   if (ilo_dev_gen(render->dev) >= ILO_GEN(7) && use_slm) {
+      ilo_render_emit_flush(render);
+      gen7_launch_grid_l3(render, false);
+   }
+
+   assert(ilo_builder_batch_used(render->builder) <= batch_used +
+         ilo_render_get_launch_grid_commands_len(render, vec));
+}
diff --git a/src/gallium/drivers/ilo/ilo_render_surface.c b/src/gallium/drivers/ilo/ilo_render_surface.c
index 22a7e48..657fbfd 100644
--- a/src/gallium/drivers/ilo/ilo_render_surface.c
+++ b/src/gallium/drivers/ilo/ilo_render_surface.c
@@ -381,3 +381,177 @@ ilo_render_emit_draw_surface_states(struct ilo_render *render,
    assert(ilo_builder_surface_used(render->builder) <= surface_used +
          ilo_render_get_draw_surface_states_len(render, vec));
 }
+
+static void
+gen6_emit_launch_grid_surface_view(struct ilo_render *r,
+                                   const struct ilo_state_vector *vec,
+                                   struct ilo_render_launch_grid_session *session)
+{
+   const struct ilo_shader_state *cs = vec->cs;
+   const struct ilo_view_state *view = &vec->view[PIPE_SHADER_COMPUTE];
+   uint32_t *surface_state = r->state.cs.SURFACE_STATE;
+   int base, count, i;
+
+   ILO_DEV_ASSERT(r->dev, 7, 7.5);
+
+   base = ilo_shader_get_kernel_param(cs, ILO_KERNEL_SURFACE_TEX_BASE);
+   count = ilo_shader_get_kernel_param(cs, ILO_KERNEL_SURFACE_TEX_COUNT);
+
+   /* SURFACE_STATEs for sampler views */
+   surface_state += base;
+   for (i = 0; i < count; i++) {
+      if (i < view->count && view->states[i]) {
+         const struct ilo_view_cso *cso =
+            (const struct ilo_view_cso *) view->states[i];
+
+         surface_state[i] =
+            gen6_SURFACE_STATE(r->builder, &cso->surface, false);
+      } else {
+         surface_state[i] = 0;
+      }
+   }
+}
+
+static void
+gen6_emit_launch_grid_surface_const(struct ilo_render *r,
+                                    const struct ilo_state_vector *vec,
+                                    struct ilo_render_launch_grid_session *session)
+{
+   const struct ilo_shader_state *cs = vec->cs;
+   uint32_t *surface_state = r->state.cs.SURFACE_STATE;
+   struct ilo_view_surface view;
+   int base, count;
+
+   ILO_DEV_ASSERT(r->dev, 7, 7.5);
+
+   base = ilo_shader_get_kernel_param(cs, ILO_KERNEL_SURFACE_CONST_BASE);
+   count = ilo_shader_get_kernel_param(cs, ILO_KERNEL_SURFACE_CONST_COUNT);
+
+   if (!count)
+      return;
+
+   ilo_gpe_init_view_surface_for_buffer(r->dev,
+         ilo_buffer(session->input->buffer),
+         session->input->buffer_offset,
+         session->input->buffer_size,
+         1, PIPE_FORMAT_NONE,
+         false, false, &view);
+
+   assert(count == 1 && session->input->buffer);
+   surface_state[base] = gen6_SURFACE_STATE(r->builder, &view, false);
+}
+
+static void
+gen6_emit_launch_grid_surface_cs_resource(struct ilo_render *r,
+                                          const struct ilo_state_vector *vec,
+                                          struct ilo_render_launch_grid_session *session)
+{
+   ILO_DEV_ASSERT(r->dev, 7, 7.5);
+
+   /* TODO */
+   assert(!vec->cs_resource.count);
+}
+
+static void
+gen6_emit_launch_grid_surface_global(struct ilo_render *r,
+                                          const struct ilo_state_vector *vec,
+                                          struct ilo_render_launch_grid_session *session)
+{
+   const struct ilo_shader_state *cs = vec->cs;
+   const struct ilo_global_binding_cso *bindings =
+      util_dynarray_begin(&vec->global_binding.bindings);
+   uint32_t *surface_state = r->state.cs.SURFACE_STATE;
+   int base, count, i;
+
+   ILO_DEV_ASSERT(r->dev, 7, 7.5);
+
+   base = ilo_shader_get_kernel_param(cs, ILO_KERNEL_CS_SURFACE_GLOBAL_BASE);
+   count = ilo_shader_get_kernel_param(cs, ILO_KERNEL_CS_SURFACE_GLOBAL_COUNT);
+
+   if (!count)
+      return;
+
+   if (base + count > Elements(r->state.cs.SURFACE_STATE)) {
+      ilo_warn("too many global bindings\n");
+      count = Elements(r->state.cs.SURFACE_STATE) - base;
+   }
+
+   /* SURFACE_STATEs for global bindings */
+   surface_state += base;
+   for (i = 0; i < count; i++) {
+      if (i < vec->global_binding.count && bindings[i].resource) {
+         const struct ilo_buffer *buf = ilo_buffer(bindings[i].resource);
+         struct ilo_view_surface view;
+
+         assert(bindings[i].resource->target == PIPE_BUFFER);
+
+         ilo_gpe_init_view_surface_for_buffer(r->dev, buf, 0, buf->bo_size,
+               1, PIPE_FORMAT_NONE, true, true, &view);
+         surface_state[i] =
+            gen6_SURFACE_STATE(r->builder, &view, true);
+      } else {
+         surface_state[i] = 0;
+      }
+   }
+}
+
+static void
+gen6_emit_launch_grid_surface_binding_table(struct ilo_render *r,
+                                            const struct ilo_state_vector *vec,
+                                            struct ilo_render_launch_grid_session *session)
+{
+   const struct ilo_shader_state *cs = vec->cs;
+   int count;
+
+   ILO_DEV_ASSERT(r->dev, 7, 7.5);
+
+   count = ilo_shader_get_kernel_param(cs, ILO_KERNEL_SURFACE_TOTAL_COUNT);
+   if (count) {
+      r->state.cs.BINDING_TABLE_STATE = gen6_BINDING_TABLE_STATE(r->builder,
+            r->state.cs.SURFACE_STATE, count);
+   }
+}
+
+int
+ilo_render_get_launch_grid_surface_states_len(const struct ilo_render *render,
+                                              const struct ilo_state_vector *vec)
+{
+   const int alignment = 32 / 4;
+   int num_surfaces;
+   int len = 0;
+
+   ILO_DEV_ASSERT(render->dev, 7, 7.5);
+
+   num_surfaces = ilo_shader_get_kernel_param(vec->cs,
+         ILO_KERNEL_SURFACE_TOTAL_COUNT);
+
+   /* BINDING_TABLE_STATE and SURFACE_STATEs */
+   if (num_surfaces) {
+      len += align(num_surfaces, alignment) +
+         align(GEN6_SURFACE_STATE__SIZE, alignment) * num_surfaces;
+   }
+
+   return len;
+}
+
+void
+ilo_render_emit_launch_grid_surface_states(struct ilo_render *render,
+                                           const struct ilo_state_vector *vec,
+                                           struct ilo_render_launch_grid_session *session)
+{
+   const unsigned surface_used = ilo_builder_surface_used(render->builder);
+
+   ILO_DEV_ASSERT(render->dev, 7, 7.5);
+
+   /* idrt depends on the binding table */
+   assert(!session->idrt_size);
+
+   gen6_emit_launch_grid_surface_view(render, vec, session);
+   gen6_emit_launch_grid_surface_const(render, vec, session);
+   gen6_emit_launch_grid_surface_cs_resource(render, vec, session);
+   gen6_emit_launch_grid_surface_global(render, vec, session);
+   gen6_emit_launch_grid_surface_binding_table(render, vec, session);
+
+   assert(ilo_builder_surface_used(render->builder) <= surface_used +
+         ilo_render_get_launch_grid_surface_states_len(render, vec));
+}
diff --git a/src/gallium/drivers/ilo/ilo_screen.c b/src/gallium/drivers/ilo/ilo_screen.c
index da6cf76..06aa973 100644
--- a/src/gallium/drivers/ilo/ilo_screen.c
+++ b/src/gallium/drivers/ilo/ilo_screen.c
@@ -194,6 +194,7 @@ ilo_get_compute_param(struct pipe_screen *screen,
                       enum pipe_compute_cap param,
                       void *ret)
 {
+   struct ilo_screen *is = ilo_screen(screen);
    union {
       const char *ir_target;
       uint64_t grid_dimension;
@@ -205,11 +206,13 @@ ilo_get_compute_param(struct pipe_screen *screen,
       uint64_t max_private_size;
       uint64_t max_input_size;
       uint64_t max_mem_alloc_size;
+      uint32_t max_clock_frequency;
+      uint32_t max_compute_units;
+      uint32_t images_supported;
    } val;
    const void *ptr;
    int size;
 
-   /* XXX some randomly chosen values */
    switch (param) {
    case PIPE_COMPUTE_CAP_IR_TARGET:
       val.ir_target = "ilog";
@@ -224,58 +227,79 @@ ilo_get_compute_param(struct pipe_screen *screen,
       size = sizeof(val.grid_dimension);
       break;
    case PIPE_COMPUTE_CAP_MAX_GRID_SIZE:
-      val.max_grid_size[0] = 65535;
-      val.max_grid_size[1] = 65535;
-      val.max_grid_size[2] = 1;
+      val.max_grid_size[0] = 0xffffffffu;
+      val.max_grid_size[1] = 0xffffffffu;
+      val.max_grid_size[2] = 0xffffffffu;
 
       ptr = &val.max_grid_size;
       size = sizeof(val.max_grid_size);
       break;
    case PIPE_COMPUTE_CAP_MAX_BLOCK_SIZE:
-      val.max_block_size[0] = 512;
-      val.max_block_size[1] = 512;
-      val.max_block_size[2] = 512;
+      val.max_block_size[0] = 1024;
+      val.max_block_size[1] = 1024;
+      val.max_block_size[2] = 1024;
 
       ptr = &val.max_block_size;
       size = sizeof(val.max_block_size);
       break;
 
    case PIPE_COMPUTE_CAP_MAX_THREADS_PER_BLOCK:
-      val.max_threads_per_block = 512;
+      val.max_threads_per_block = 1024;
 
       ptr = &val.max_threads_per_block;
       size = sizeof(val.max_threads_per_block);
       break;
    case PIPE_COMPUTE_CAP_MAX_GLOBAL_SIZE:
-      val.max_global_size = 4;
+      /* \see ilo_max_resource_size */
+      val.max_global_size = 1u << 31;
 
       ptr = &val.max_global_size;
       size = sizeof(val.max_global_size);
       break;
    case PIPE_COMPUTE_CAP_MAX_LOCAL_SIZE:
+      /* Shared Local Memory Size of INTERFACE_DESCRIPTOR_DATA */
       val.max_local_size = 64 * 1024;
 
       ptr = &val.max_local_size;
       size = sizeof(val.max_local_size);
       break;
    case PIPE_COMPUTE_CAP_MAX_PRIVATE_SIZE:
-      val.max_private_size = 32768;
+      /* scratch size */
+      val.max_private_size = 12 * 1024;
 
       ptr = &val.max_private_size;
       size = sizeof(val.max_private_size);
       break;
    case PIPE_COMPUTE_CAP_MAX_INPUT_SIZE:
-      val.max_input_size = 256;
+      val.max_input_size = 1024;
 
       ptr = &val.max_input_size;
       size = sizeof(val.max_input_size);
       break;
    case PIPE_COMPUTE_CAP_MAX_MEM_ALLOC_SIZE:
-      val.max_mem_alloc_size = 128 * 1024 * 1024;
+      val.max_mem_alloc_size = 1u << 31;
 
       ptr = &val.max_mem_alloc_size;
       size = sizeof(val.max_mem_alloc_size);
       break;
+   case PIPE_COMPUTE_CAP_MAX_CLOCK_FREQUENCY:
+      val.max_clock_frequency = 1000;
+
+      ptr = &val.max_clock_frequency;
+      size = sizeof(val.max_clock_frequency);
+      break;
+   case PIPE_COMPUTE_CAP_MAX_COMPUTE_UNITS:
+      val.max_compute_units = is->dev.eu_count;
+
+      ptr = &val.max_compute_units;
+      size = sizeof(val.max_compute_units);
+      break;
+   case PIPE_COMPUTE_CAP_IMAGES_SUPPORTED:
+      val.images_supported = 1;
+
+      ptr = &val.images_supported;
+      size = sizeof(val.images_supported);
+      break;
    default:
       ptr = NULL;
       size = 0;
@@ -682,39 +706,85 @@ init_dev(struct ilo_dev_info *dev, const struct intel_winsys_info *info)
       ilo_warn("PPGTT disabled\n");
    }
 
-   /*
-    * From the Sandy Bridge PRM, volume 4 part 2, page 18:
-    *
-    *     "[DevSNB]: The GT1 product's URB provides 32KB of storage, arranged
-    *      as 1024 256-bit rows. The GT2 product's URB provides 64KB of
-    *      storage, arranged as 2048 256-bit rows. A row corresponds in size
-    *      to an EU GRF register. Read/write access to the URB is generally
-    *      supported on a row-granular basis."
-    *
-    * From the Ivy Bridge PRM, volume 4 part 2, page 17:
-    *
-    *     "URB Size    URB Rows    URB Rows when SLM Enabled
-    *      128k        4096        2048
-    *      256k        8096        4096"
-    */
-
    if (gen_is_hsw(info->devid)) {
+      /*
+       * From the Haswell PRM, volume 4, page 8:
+       *
+       *     "Description                    GT3      GT2      GT1.5    GT1
+       *      (...)
+       *      EUs (Total)                    40       20       12       10
+       *      Threads (Total)                280      140      84       70
+       *      (...)
+       *      URB Size (max, within L3$)     512KB    256KB    256KB    128KB
+       */
       dev->gen_opaque = ILO_GEN(7.5);
       dev->gt = gen_get_hsw_gt(info->devid);
-      dev->urb_size = ((dev->gt == 3) ? 512 :
-                       (dev->gt == 2) ? 256 : 128) * 1024;
-   }
-   else if (gen_is_ivb(info->devid) || gen_is_vlv(info->devid)) {
+      if (dev->gt == 3) {
+         dev->eu_count = 40;
+         dev->thread_count = 280;
+         dev->urb_size = 512 * 1024;
+      } else if (dev->gt == 2) {
+         dev->eu_count = 20;
+         dev->thread_count = 140;
+         dev->urb_size = 256 * 1024;
+      } else {
+         dev->eu_count = 10;
+         dev->thread_count = 70;
+         dev->urb_size = 128 * 1024;
+      }
+   } else if (gen_is_ivb(info->devid) || gen_is_vlv(info->devid)) {
+      /*
+       * From the Ivy Bridge PRM, volume 1 part 1, page 18:
+       *
+       *     "Device             # of EUs        #Threads/EU
+       *      Ivy Bridge (GT2)   16              8
+       *      Ivy Bridge (GT1)   6               6"
+       *
+       * From the Ivy Bridge PRM, volume 4 part 2, page 17:
+       *
+       *     "URB Size    URB Rows    URB Rows when SLM Enabled
+       *      128k        4096        2048
+       *      256k        8096        4096"
+       */
       dev->gen_opaque = ILO_GEN(7);
       dev->gt = (gen_is_ivb(info->devid)) ? gen_get_ivb_gt(info->devid) : 1;
-      dev->urb_size = ((dev->gt == 2) ? 256 : 128) * 1024;
-   }
-   else if (gen_is_snb(info->devid)) {
+      if (dev->gt == 2) {
+         dev->eu_count = 16;
+         dev->thread_count = 128;
+         dev->urb_size = 256 * 1024;
+      } else {
+         dev->eu_count = 6;
+         dev->thread_count = 36;
+         dev->urb_size = 128 * 1024;
+      }
+   } else if (gen_is_snb(info->devid)) {
+      /*
+       * From the Sandy Bridge PRM, volume 1 part 1, page 22:
+       *
+       *     "Device             # of EUs        #Threads/EU
+       *      SNB GT2            12              5
+       *      SNB GT1            6               4"
+       *
+       * From the Sandy Bridge PRM, volume 4 part 2, page 18:
+       *
+       *     "[DevSNB]: The GT1 product's URB provides 32KB of storage,
+       *      arranged as 1024 256-bit rows. The GT2 product's URB provides
+       *      64KB of storage, arranged as 2048 256-bit rows. A row
+       *      corresponds in size to an EU GRF register. Read/write access to
+       *      the URB is generally supported on a row-granular basis."
+       */
       dev->gen_opaque = ILO_GEN(6);
       dev->gt = gen_get_snb_gt(info->devid);
-      dev->urb_size = ((dev->gt == 2) ? 64 : 32) * 1024;
-   }
-   else {
+      if (dev->gt == 2) {
+         dev->eu_count = 12;
+         dev->thread_count = 60;
+         dev->urb_size = 64 * 1024;
+      } else {
+         dev->eu_count = 6;
+         dev->thread_count = 24;
+         dev->urb_size = 32 * 1024;
+      }
+   } else {
       ilo_err("unknown GPU generation\n");
       return false;
    }
diff --git a/src/gallium/drivers/ilo/ilo_shader.c b/src/gallium/drivers/ilo/ilo_shader.c
index f4203aa..626bc1b 100644
--- a/src/gallium/drivers/ilo/ilo_shader.c
+++ b/src/gallium/drivers/ilo/ilo_shader.c
@@ -1036,6 +1036,12 @@ ilo_shader_get_kernel_param(const struct ilo_shader_state *shader,
    case ILO_KERNEL_SURFACE_CONST_COUNT:
       val = kernel->bt.const_count;
       break;
+   case ILO_KERNEL_SURFACE_RES_BASE:
+      val = kernel->bt.res_base;
+      break;
+   case ILO_KERNEL_SURFACE_RES_COUNT:
+      val = kernel->bt.res_count;
+      break;
 
    case ILO_KERNEL_VS_INPUT_INSTANCEID:
       val = shader->info.has_instanceid;
@@ -1111,6 +1117,25 @@ ilo_shader_get_kernel_param(const struct ilo_shader_state *shader,
       val = kernel->bt.rt_count;
       break;
 
+   case ILO_KERNEL_CS_LOCAL_SIZE:
+      val = shader->info.compute.req_local_mem;
+      break;
+   case ILO_KERNEL_CS_PRIVATE_SIZE:
+      val = shader->info.compute.req_private_mem;
+      break;
+   case ILO_KERNEL_CS_INPUT_SIZE:
+      val = shader->info.compute.req_input_mem;
+      break;
+   case ILO_KERNEL_CS_SIMD_SIZE:
+      val = 16;
+      break;
+   case ILO_KERNEL_CS_SURFACE_GLOBAL_BASE:
+      val = kernel->bt.global_base;
+      break;
+   case ILO_KERNEL_CS_SURFACE_GLOBAL_COUNT:
+      val = kernel->bt.global_count;
+      break;
+
    default:
       assert(!"unknown kernel parameter");
       val = 0;
diff --git a/src/gallium/drivers/ilo/ilo_shader.h b/src/gallium/drivers/ilo/ilo_shader.h
index c66513e..ea500e3 100644
--- a/src/gallium/drivers/ilo/ilo_shader.h
+++ b/src/gallium/drivers/ilo/ilo_shader.h
@@ -43,6 +43,8 @@ enum ilo_kernel_param {
    ILO_KERNEL_SURFACE_TEX_COUNT,
    ILO_KERNEL_SURFACE_CONST_BASE,
    ILO_KERNEL_SURFACE_CONST_COUNT,
+   ILO_KERNEL_SURFACE_RES_BASE,
+   ILO_KERNEL_SURFACE_RES_COUNT,
 
    ILO_KERNEL_VS_INPUT_INSTANCEID,
    ILO_KERNEL_VS_INPUT_VERTEXID,
@@ -69,6 +71,13 @@ enum ilo_kernel_param {
    ILO_KERNEL_FS_SURFACE_RT_BASE,
    ILO_KERNEL_FS_SURFACE_RT_COUNT,
 
+   ILO_KERNEL_CS_LOCAL_SIZE,
+   ILO_KERNEL_CS_PRIVATE_SIZE,
+   ILO_KERNEL_CS_INPUT_SIZE,
+   ILO_KERNEL_CS_SIMD_SIZE,
+   ILO_KERNEL_CS_SURFACE_GLOBAL_BASE,
+   ILO_KERNEL_CS_SURFACE_GLOBAL_COUNT,
+
    ILO_KERNEL_PARAM_COUNT,
 };
 
diff --git a/src/gallium/drivers/ilo/ilo_state.c b/src/gallium/drivers/ilo/ilo_state.c
index 18c1566..c68062a 100644
--- a/src/gallium/drivers/ilo/ilo_state.c
+++ b/src/gallium/drivers/ilo/ilo_state.c
@@ -25,6 +25,7 @@
  *    Chia-I Wu <olv@lunarg.com>
  */
 
+#include "util/u_dynarray.h"
 #include "util/u_helpers.h"
 #include "util/u_upload_mgr.h"
 
@@ -261,6 +262,40 @@ ilo_finalize_3d_states(struct ilo_context *ilo,
    u_upload_unmap(ilo->uploader);
 }
 
+static void
+finalize_global_binding(struct ilo_state_vector *vec)
+{
+   struct ilo_shader_state *cs = vec->cs;
+   int base, count, shift;
+   int i;
+
+   count = ilo_shader_get_kernel_param(cs,
+         ILO_KERNEL_CS_SURFACE_GLOBAL_COUNT);
+   if (!count)
+      return;
+
+   base = ilo_shader_get_kernel_param(cs, ILO_KERNEL_CS_SURFACE_GLOBAL_BASE);
+   shift = 32 - util_last_bit(base + count - 1);
+
+   if (count > vec->global_binding.count)
+      count = vec->global_binding.count;
+
+   for (i = 0; i < count; i++) {
+      struct ilo_global_binding_cso *cso =
+         util_dynarray_element(&vec->global_binding.bindings,
+               struct ilo_global_binding_cso, i);
+      const uint32_t offset = *cso->handle & ((1 << shift) - 1);
+
+      *cso->handle = ((base + i) << shift) | offset;
+   }
+}
+
+void
+ilo_finalize_compute_states(struct ilo_context *ilo)
+{
+   finalize_global_binding(&ilo->state_vector);
+}
+
 static void *
 ilo_create_blend_state(struct pipe_context *pipe,
                        const struct pipe_blend_state *state)
@@ -1138,30 +1173,52 @@ ilo_set_global_binding(struct pipe_context *pipe,
                        uint32_t **handles)
 {
    struct ilo_state_vector *vec = &ilo_context(pipe)->state_vector;
-   struct ilo_global_binding *dst = &vec->global_binding;
+   struct ilo_global_binding_cso *dst;
    unsigned i;
 
-   assert(start + count <= Elements(dst->resources));
+   /* make room */
+   if (vec->global_binding.count < start + count) {
+      if (resources) {
+         const unsigned old_size = vec->global_binding.bindings.size;
+         const unsigned new_size = sizeof(*dst) * (start + count);
 
-   if (resources) {
-      for (i = 0; i < count; i++)
-         pipe_resource_reference(&dst->resources[start + i], resources[i]);
+         if (old_size < new_size) {
+            util_dynarray_resize(&vec->global_binding.bindings, new_size);
+            memset(vec->global_binding.bindings.data + old_size, 0,
+                  new_size - old_size);
+         }
+      } else {
+         count = vec->global_binding.count - start;
+      }
    }
-   else {
-      for (i = 0; i < count; i++)
-         pipe_resource_reference(&dst->resources[start + i], NULL);
+
+   dst = util_dynarray_element(&vec->global_binding.bindings,
+         struct ilo_global_binding_cso, start);
+
+   if (resources) {
+      for (i = 0; i < count; i++) {
+         pipe_resource_reference(&dst[i].resource, resources[i]);
+         dst[i].handle = handles[i];
+      }
+   } else {
+      for (i = 0; i < count; i++) {
+         pipe_resource_reference(&dst[i].resource, NULL);
+         dst[i].handle = NULL;
+      }
    }
 
-   if (dst->count <= start + count) {
+   if (vec->global_binding.count <= start + count) {
+      dst = util_dynarray_begin(&vec->global_binding.bindings);
+
       if (resources)
          count += start;
       else
          count = start;
 
-      while (count > 0 && !dst->resources[count - 1])
+      while (count > 0 && !dst[count - 1].resource)
          count--;
 
-      dst->count = count;
+      vec->global_binding.count = count;
    }
 
    vec->dirty |= ILO_DIRTY_GLOBAL_BINDING;
@@ -1240,6 +1297,8 @@ ilo_state_vector_init(const struct ilo_dev_info *dev,
    ilo_gpe_init_zs_surface(dev, NULL, PIPE_FORMAT_NONE,
          0, 0, 1, &vec->fb.null_zs);
 
+   util_dynarray_init(&vec->global_binding.bindings);
+
    vec->dirty = ILO_DIRTY_ALL;
 }
 
@@ -1283,8 +1342,14 @@ ilo_state_vector_cleanup(struct ilo_state_vector *vec)
    for (i = 0; i < vec->cs_resource.count; i++)
       pipe_surface_reference(&vec->cs_resource.states[i], NULL);
 
-   for (i = 0; i < vec->global_binding.count; i++)
-      pipe_resource_reference(&vec->global_binding.resources[i], NULL);
+   for (i = 0; i < vec->global_binding.count; i++) {
+      struct ilo_global_binding_cso *cso =
+         util_dynarray_element(&vec->global_binding.bindings,
+               struct ilo_global_binding_cso, i);
+      pipe_resource_reference(&cso->resource, NULL);
+   }
+
+   util_dynarray_fini(&vec->global_binding.bindings);
 }
 
 /**
@@ -1405,7 +1470,11 @@ ilo_state_vector_resource_renamed(struct ilo_state_vector *vec,
    }
 
    for (i = 0; i < vec->global_binding.count; i++) {
-      if (vec->global_binding.resources[i] == res) {
+      struct ilo_global_binding_cso *cso =
+         util_dynarray_element(&vec->global_binding.bindings,
+               struct ilo_global_binding_cso, i);
+
+      if (cso->resource == res) {
          states |= ILO_DIRTY_GLOBAL_BINDING;
          break;
       }
diff --git a/src/gallium/drivers/ilo/ilo_state.h b/src/gallium/drivers/ilo/ilo_state.h
index a1d4b7b..6f544e1 100644
--- a/src/gallium/drivers/ilo/ilo_state.h
+++ b/src/gallium/drivers/ilo/ilo_state.h
@@ -29,6 +29,7 @@
 #define ILO_STATE_H
 
 #include "pipe/p_state.h"
+#include "util/u_dynarray.h"
 
 #include "ilo_common.h"
 
@@ -349,25 +350,27 @@ struct ilo_fb_state {
    unsigned num_samples;
 };
 
+struct ilo_global_binding_cso {
+   struct pipe_resource *resource;
+   uint32_t *handle;
+};
+
+/*
+ * In theory, we would like a "virtual" bo that serves as the global memory
+ * region.  The virtual bo would reserve a region in the GTT aperture, but the
+ * pages of it would come from those of the global bindings.
+ *
+ * The virtual bo would be created in launch_grid().  The global bindings
+ * would be added to the virtual bo.  A SURFACE_STATE for the virtual bo would
+ * be created.  The handles returned by set_global_binding() would be offsets
+ * into the virtual bo.
+ *
+ * But for now, we will create a SURFACE_STATE for each of the bindings.  The
+ * handle of a global binding consists of the offset and the binding table
+ * index.
+ */
 struct ilo_global_binding {
-   /*
-    * XXX These should not be treated as real resources (and there could be
-    * thousands of them).  They should be treated as regions in GLOBAL
-    * resource, which is the only real resource.
-    *
-    * That is, a resource here should instead be
-    *
-    *   struct ilo_global_region {
-    *     struct pipe_resource base;
-    *     int offset;
-    *     int size;
-    *   };
-    *
-    * and it describes the region [offset, offset + size) in GLOBAL
-    * resource.
-    */
-   struct pipe_resource *resources[PIPE_MAX_SHADER_RESOURCES];
-   uint32_t *handles[PIPE_MAX_SHADER_RESOURCES];
+   struct util_dynarray bindings;
    unsigned count;
 };
 
@@ -425,6 +428,9 @@ ilo_finalize_3d_states(struct ilo_context *ilo,
                        const struct pipe_draw_info *draw);
 
 void
+ilo_finalize_compute_states(struct ilo_context *ilo);
+
+void
 ilo_state_vector_init(const struct ilo_dev_info *dev,
                       struct ilo_state_vector *vec);
 
diff --git a/src/gallium/drivers/ilo/ilo_state_gen6.c b/src/gallium/drivers/ilo/ilo_state_gen6.c
index 6f0c92d..bc80aeb 100644
--- a/src/gallium/drivers/ilo/ilo_state_gen6.c
+++ b/src/gallium/drivers/ilo/ilo_state_gen6.c
@@ -434,35 +434,9 @@ ilo_gpe_init_vs_cso(const struct ilo_dev_info *dev,
    if (!vue_read_len)
       vue_read_len = 1;
 
-   switch (ilo_dev_gen(dev)) {
-   case ILO_GEN(6):
-      /*
-       * From the Sandy Bridge PRM, volume 1 part 1, page 22:
-       *
-       *     "Device             # of EUs        #Threads/EU
-       *      SNB GT2            12              5
-       *      SNB GT1            6               4"
-       */
-      max_threads = (dev->gt == 2) ? 60 : 24;
-      break;
-   case ILO_GEN(7):
-      /*
-       * From the Ivy Bridge PRM, volume 1 part 1, page 18:
-       *
-       *     "Device             # of EUs        #Threads/EU
-       *      Ivy Bridge (GT2)   16              8
-       *      Ivy Bridge (GT1)   6               6"
-       */
-      max_threads = (dev->gt == 2) ? 128 : 36;
-      break;
-   case ILO_GEN(7.5):
-      /* see brwCreateContext() */
-      max_threads = (dev->gt >= 2) ? 280 : 70;
-      break;
-   default:
-      max_threads = 1;
-      break;
-   }
+   max_threads = dev->thread_count;
+   if (ilo_dev_gen(dev) == ILO_GEN(7.5) && dev->gt == 2)
+      max_threads *= 2;
 
    dw2 = (true) ? 0 : GEN6_THREADDISP_FP_MODE_ALT;
    dw2 |= ((sampler_count + 3) / 4) << GEN6_THREADDISP_SAMPLER_COUNT__SHIFT;
diff --git a/src/gallium/drivers/ilo/shader/ilo_shader_cs.c b/src/gallium/drivers/ilo/shader/ilo_shader_cs.c
index 880ec57..fd86070 100644
--- a/src/gallium/drivers/ilo/shader/ilo_shader_cs.c
+++ b/src/gallium/drivers/ilo/shader/ilo_shader_cs.c
@@ -25,8 +25,176 @@
  *    Chia-I Wu <olv@lunarg.com>
  */
 
+#include "toy_compiler.h"
+#include "toy_helpers.h"
+#include "toy_legalize.h"
+#include "toy_optimize.h"
 #include "ilo_shader_internal.h"
 
+struct cs_compile_context {
+   struct ilo_shader *shader;
+   const struct ilo_shader_variant *variant;
+
+   struct toy_compiler tc;
+
+   int first_free_grf;
+   int last_free_grf;
+
+   int num_grf_per_vrf;
+
+   int first_free_mrf;
+   int last_free_mrf;
+};
+
+/**
+ * Compile the shader.
+ */
+static bool
+cs_compile(struct cs_compile_context *ccc)
+{
+   struct toy_compiler *tc = &ccc->tc;
+   struct ilo_shader *sh = ccc->shader;
+
+   toy_compiler_legalize_for_ra(tc);
+   toy_compiler_optimize(tc);
+   toy_compiler_allocate_registers(tc,
+         ccc->first_free_grf,
+         ccc->last_free_grf,
+         ccc->num_grf_per_vrf);
+   toy_compiler_legalize_for_asm(tc);
+
+   if (tc->fail) {
+      ilo_err("failed to legalize FS instructions: %s\n", tc->reason);
+      return false;
+   }
+
+   if (ilo_debug & ILO_DEBUG_CS) {
+      ilo_printf("legalized instructions:\n");
+      toy_compiler_dump(tc);
+      ilo_printf("\n");
+   }
+
+   if (true) {
+      sh->kernel = toy_compiler_assemble(tc, &sh->kernel_size);
+   } else {
+      static const uint32_t microcode[] = {
+         /* fill in the microcode here */
+         0x0, 0x0, 0x0, 0x0,
+      };
+      const bool swap = true;
+
+      sh->kernel_size = sizeof(microcode);
+      sh->kernel = MALLOC(sh->kernel_size);
+
+      if (sh->kernel) {
+         const int num_dwords = sizeof(microcode) / 4;
+         const uint32_t *src = microcode;
+         uint32_t *dst = (uint32_t *) sh->kernel;
+         int i;
+
+         for (i = 0; i < num_dwords; i += 4) {
+            if (swap) {
+               dst[i + 0] = src[i + 3];
+               dst[i + 1] = src[i + 2];
+               dst[i + 2] = src[i + 1];
+               dst[i + 3] = src[i + 0];
+            }
+            else {
+               memcpy(dst, src, 16);
+            }
+         }
+      }
+   }
+
+   if (!sh->kernel) {
+      ilo_err("failed to compile CS: %s\n", tc->reason);
+      return false;
+   }
+
+   if (ilo_debug & ILO_DEBUG_CS) {
+      ilo_printf("disassembly:\n");
+      toy_compiler_disassemble(tc->dev, sh->kernel, sh->kernel_size, false);
+      ilo_printf("\n");
+   }
+
+   return true;
+}
+
+static void
+cs_dummy(struct cs_compile_context *ccc)
+{
+   struct toy_compiler *tc = &ccc->tc;
+   struct toy_dst header;
+   struct toy_src r0, desc;
+   struct toy_inst *inst;
+
+   header = tdst_ud(tdst(TOY_FILE_MRF, ccc->first_free_mrf, 0));
+   r0 = tsrc_ud(tsrc(TOY_FILE_GRF, 0, 0));
+
+   inst = tc_MOV(tc, header, r0);
+   inst->exec_size = GEN6_EXECSIZE_8;
+   inst->mask_ctrl = GEN6_MASKCTRL_NOMASK;
+
+   desc = tsrc_imm_mdesc(tc, true, 1, 0, true,
+         GEN6_MSG_TS_RESOURCE_SELECT_NO_DEREF |
+         GEN6_MSG_TS_REQUESTER_TYPE_ROOT |
+         GEN6_MSG_TS_OPCODE_DEREF);
+
+   tc_SEND(tc, tdst_null(), tsrc_from(header), desc, GEN6_SFID_SPAWNER);
+}
+
+static bool
+cs_setup(struct cs_compile_context *ccc,
+         const struct ilo_shader_state *state,
+         const struct ilo_shader_variant *variant)
+{
+   memset(ccc, 0, sizeof(*ccc));
+
+   ccc->shader = CALLOC_STRUCT(ilo_shader);
+   if (!ccc->shader)
+      return false;
+
+   ccc->variant = variant;
+
+   toy_compiler_init(&ccc->tc, state->info.dev);
+
+   ccc->tc.templ.access_mode = GEN6_ALIGN_1;
+   ccc->tc.templ.qtr_ctrl = GEN6_QTRCTRL_1H;
+   ccc->tc.templ.exec_size = GEN6_EXECSIZE_16;
+   ccc->tc.rect_linear_width = 8;
+
+   ccc->first_free_grf = 1;
+   ccc->last_free_grf = 127;
+
+   /* m0 is reserved for system routines */
+   ccc->first_free_mrf = 1;
+   ccc->last_free_mrf = 15;
+
+   /* instructions are compressed with GEN6_EXECSIZE_16 */
+   ccc->num_grf_per_vrf = 2;
+
+   if (ilo_dev_gen(ccc->tc.dev) >= ILO_GEN(7)) {
+      ccc->last_free_grf -= 15;
+      ccc->first_free_mrf = ccc->last_free_grf + 1;
+      ccc->last_free_mrf = ccc->first_free_mrf + 14;
+   }
+
+   ccc->shader->in.start_grf = 1;
+   ccc->shader->dispatch_16 = true;
+
+   /* INPUT */
+   ccc->shader->bt.const_base = 0;
+   ccc->shader->bt.const_count = 1;
+
+   /* a GLOBAL */
+   ccc->shader->bt.global_base = 1;
+   ccc->shader->bt.global_count = 1;
+
+   ccc->shader->bt.total_count = 2;
+
+   return true;
+}
+
 /**
  * Compile the compute shader.
  */
@@ -34,5 +202,21 @@ struct ilo_shader *
 ilo_shader_compile_cs(const struct ilo_shader_state *state,
                       const struct ilo_shader_variant *variant)
 {
-   return NULL;
+   struct cs_compile_context ccc;
+
+   ILO_DEV_ASSERT(state->info.dev, 7, 7.5);
+
+   if (!cs_setup(&ccc, state, variant))
+      return NULL;
+
+   cs_dummy(&ccc);
+
+   if (!cs_compile(&ccc)) {
+      FREE(ccc.shader);
+      ccc.shader = NULL;
+   }
+
+   toy_compiler_cleanup(&ccc.tc);
+
+   return ccc.shader;
 }
diff --git a/src/gallium/drivers/ilo/shader/ilo_shader_internal.h b/src/gallium/drivers/ilo/shader/ilo_shader_internal.h
index 98ec8dd..c55fde7 100644
--- a/src/gallium/drivers/ilo/shader/ilo_shader_internal.h
+++ b/src/gallium/drivers/ilo/shader/ilo_shader_internal.h
@@ -138,9 +138,12 @@ struct ilo_shader {
       int rt_base, rt_count;
       int tex_base, tex_count;
       int const_base, const_count;
+      int res_base, res_count;
 
       int gen6_so_base, gen6_so_count;
 
+      int global_base, global_count;
+
       int total_count;
    } bt;
 
diff --git a/src/gallium/drivers/ilo/shader/toy_compiler_disasm.c b/src/gallium/drivers/ilo/shader/toy_compiler_disasm.c
index 94321af..f45ac56 100644
--- a/src/gallium/drivers/ilo/shader/toy_compiler_disasm.c
+++ b/src/gallium/drivers/ilo/shader/toy_compiler_disasm.c
@@ -1219,6 +1219,38 @@ disasm_printer_add_mdesc_urb(struct disasm_printer *printer,
 }
 
 static void
+disasm_printer_add_mdesc_spawner(struct disasm_printer *printer,
+                                 const struct disasm_inst *inst,
+                                 uint32_t mdesc)
+{
+   const char *from;
+
+   switch (mdesc & GEN6_MSG_TS_REQUESTER_TYPE__MASK) {
+   case GEN6_MSG_TS_REQUESTER_TYPE_ROOT:  from = "root";    break;
+   case GEN6_MSG_TS_REQUESTER_TYPE_CHILD: from = "child";   break;
+   default:                               from = "BAD";     break;
+   }
+
+   disasm_printer_add(printer, "(%s thread ", from);
+
+   switch (mdesc & GEN6_MSG_TS_OPCODE__MASK) {
+   case GEN6_MSG_TS_OPCODE_DEREF:
+      disasm_printer_add(printer, "%sderef",
+            (mdesc & GEN6_MSG_TS_RESOURCE_SELECT_NO_DEREF) ? "no " : "");
+      break;
+   case GEN6_MSG_TS_OPCODE_SPAWN:
+      disasm_printer_add(printer, "spawn %s)",
+            (mdesc & GEN6_MSG_TS_RESOURCE_SELECT_ROOT) ? "root" : "child");
+      break;
+   default:
+      disasm_printer_add(printer, "BAD");
+      break;
+   }
+
+   disasm_printer_add(printer, ")");
+}
+
+static void
 disasm_printer_add_mdesc_dp_sampler(struct disasm_printer *printer,
                                     const struct disasm_inst *inst,
                                     uint32_t mdesc)
@@ -1235,6 +1267,140 @@ disasm_printer_add_mdesc_dp_sampler(struct disasm_printer *printer,
 }
 
 static void
+disasm_printer_add_mdesc_dp_dc0(struct disasm_printer *printer,
+                                const struct disasm_inst *inst,
+                                uint32_t mdesc)
+{
+   const int op = GEN_EXTRACT(mdesc, GEN7_MSG_DP_OP);
+   const char *str;
+
+   ILO_DEV_ASSERT(inst->dev, 7, 7.5);
+
+   if (ilo_dev_gen(inst->dev) >= ILO_GEN(7.5)) {
+      switch (op) {
+      case GEN75_MSG_DP_DC0_OWORD_BLOCK_READ:             str = "OWORD block read";           break;
+      case GEN75_MSG_DP_DC0_UNALIGNED_OWORD_BLOCK_READ:   str = "unaligned OWORD block read"; break;
+      case GEN75_MSG_DP_DC0_OWORD_DUAL_BLOCK_READ:        str = "OWORD dual block read";      break;
+      case GEN75_MSG_DP_DC0_DWORD_SCATTERED_READ:         str = "DWORD scattered read";       break;
+      case GEN75_MSG_DP_DC0_BYTE_SCATTERED_READ:          str = "BYTE scattered read";        break;
+      case GEN75_MSG_DP_DC0_MEMORY_FENCE:                 str = "memory fence";               break;
+      case GEN75_MSG_DP_DC0_OWORD_BLOCK_WRITE:            str = "OWORD block write";          break;
+      case GEN75_MSG_DP_DC0_OWORD_DUAL_BLOCK_WRITE:       str = "OWORD dual block write";     break;
+      case GEN75_MSG_DP_DC0_DWORD_SCATTERED_WRITE:        str = "OWORD scattered write";      break;
+      case GEN75_MSG_DP_DC0_BYTE_SCATTERED_WRITE:         str = "BYTE scattered write";       break;
+      default:                                            str = "BAD";                        break;
+      }
+   } else {
+      switch (op) {
+      case GEN7_MSG_DP_DC0_OWORD_BLOCK_READ:             str = "OWORD block read";           break;
+      case GEN7_MSG_DP_DC0_UNALIGNED_OWORD_BLOCK_READ:   str = "unaligned OWORD block read"; break;
+      case GEN7_MSG_DP_DC0_OWORD_DUAL_BLOCK_READ:        str = "OWORD dual block read";      break;
+      case GEN7_MSG_DP_DC0_DWORD_SCATTERED_READ:         str = "DWORD scattered read";       break;
+      case GEN7_MSG_DP_DC0_BYTE_SCATTERED_READ:          str = "BYTE scattered read";        break;
+      case GEN7_MSG_DP_DC0_UNTYPED_SURFACE_READ:         str = "untyped surface read";       break;
+      case GEN7_MSG_DP_DC0_UNTYPED_ATOMIC_OP:            str = "untyped atomic op";          break;
+      case GEN7_MSG_DP_DC0_MEMORY_FENCE:                 str = "memory fence";               break;
+      case GEN7_MSG_DP_DC0_OWORD_BLOCK_WRITE:            str = "OWORD block write";          break;
+      case GEN7_MSG_DP_DC0_OWORD_DUAL_BLOCK_WRITE:       str = "OWORD dual block write";     break;
+      case GEN7_MSG_DP_DC0_DWORD_SCATTERED_WRITE:        str = "OWORD scattered write";      break;
+      case GEN7_MSG_DP_DC0_BYTE_SCATTERED_WRITE:         str = "BYTE scattered write";       break;
+      case GEN7_MSG_DP_DC0_UNTYPED_SURFACE_WRITE:        str = "untyped surface write";      break;
+      default:                                           str = "BAD";                        break;
+      }
+   }
+
+   disasm_printer_add(printer, "(%s, Surface = %d, ",
+         str, GEN_EXTRACT(mdesc, GEN6_MSG_DP_SURFACE));
+
+   if (ilo_dev_gen(inst->dev) >= ILO_GEN(7.5)) {
+      disasm_printer_add(printer, "0x%x",
+            GEN_EXTRACT(mdesc, GEN6_MSG_DP_CTRL));
+   } else {
+      switch (op) {
+      case GEN7_MSG_DP_DC0_UNTYPED_SURFACE_READ:
+      case GEN7_MSG_DP_DC0_UNTYPED_SURFACE_WRITE:
+         switch (mdesc & GEN7_MSG_DP_UNTYPED_MODE__MASK) {
+         case GEN7_MSG_DP_UNTYPED_MODE_SIMD4X2: str = "4x2";   break;
+         case GEN7_MSG_DP_UNTYPED_MODE_SIMD16:  str = "16";    break;
+         case GEN7_MSG_DP_UNTYPED_MODE_SIMD8:   str = "8";     break;
+         default:                               str = "BAD";   break;
+         }
+
+         disasm_printer_add(printer, "SIMD%s, Mask = 0x%x",
+               str, GEN_EXTRACT(mdesc, GEN7_MSG_DP_UNTYPED_MASK));
+         break;
+      default:
+         disasm_printer_add(printer, "0x%x",
+               GEN_EXTRACT(mdesc, GEN6_MSG_DP_CTRL));
+         break;
+      }
+   }
+
+   disasm_printer_add(printer, ")");
+}
+
+static void
+disasm_printer_add_mdesc_dp_dc1(struct disasm_printer *printer,
+                                const struct disasm_inst *inst,
+                                uint32_t mdesc)
+{
+   const int op = GEN_EXTRACT(mdesc, GEN7_MSG_DP_OP);
+   const char *str;
+
+   ILO_DEV_ASSERT(inst->dev, 7.5, 7.5);
+
+   switch (op) {
+   case GEN75_MSG_DP_DC1_UNTYPED_SURFACE_READ:        str = "untyped surface read";       break;
+   case GEN75_MSG_DP_DC1_UNTYPED_ATOMIC_OP:           str = "DC untyped atomic op";       break;
+   case GEN75_MSG_DP_DC1_UNTYPED_ATOMIC_OP_SIMD4X2:   str = "DC untyped 4x2 atomic op";   break;
+   case GEN75_MSG_DP_DC1_MEDIA_BLOCK_READ:            str = "DC media block read";        break;
+   case GEN75_MSG_DP_DC1_TYPED_SURFACE_READ:          str = "DC typed surface read";      break;
+   case GEN75_MSG_DP_DC1_TYPED_ATOMIC_OP:             str = "DC typed atomic";            break;
+   case GEN75_MSG_DP_DC1_TYPED_ATOMIC_OP_SIMD4X2:     str = "DC typed 4x2 atomic op";     break;
+   case GEN75_MSG_DP_DC1_UNTYPED_SURFACE_WRITE:       str = "DC untyped surface write";   break;
+   case GEN75_MSG_DP_DC1_MEDIA_BLOCK_WRITE:           str = "DC media block write";       break;
+   case GEN75_MSG_DP_DC1_ATOMIC_COUNTER_OP:           str = "DC atomic counter op";       break;
+   case GEN75_MSG_DP_DC1_ATOMIC_COUNTER_OP_SIMD4X2:   str = "DC 4x2 atomic counter op";   break;
+   case GEN75_MSG_DP_DC1_TYPED_SURFACE_WRITE:         str = "DC typed surface write";     break;
+   default:                                           str = "BAD";                        break;
+   }
+
+   disasm_printer_add(printer, "(%s, Surface = %d, ",
+         str, GEN_EXTRACT(mdesc, GEN6_MSG_DP_SURFACE));
+
+   switch (op) {
+   case GEN75_MSG_DP_DC1_UNTYPED_SURFACE_READ:
+   case GEN75_MSG_DP_DC1_UNTYPED_SURFACE_WRITE:
+      switch (mdesc & GEN7_MSG_DP_UNTYPED_MODE__MASK) {
+      case GEN7_MSG_DP_UNTYPED_MODE_SIMD4X2: str = "4x2";   break;
+      case GEN7_MSG_DP_UNTYPED_MODE_SIMD16:  str = "16";    break;
+      case GEN7_MSG_DP_UNTYPED_MODE_SIMD8:   str = "8";     break;
+      default:                               str = "BAD";   break;
+      }
+
+      disasm_printer_add(printer, "SIMD%s, Mask = 0x%x",
+            str, GEN_EXTRACT(mdesc, GEN7_MSG_DP_UNTYPED_MASK));
+      break;
+   case GEN75_MSG_DP_DC1_UNTYPED_ATOMIC_OP:
+   case GEN75_MSG_DP_DC1_UNTYPED_ATOMIC_OP_SIMD4X2:
+   case GEN75_MSG_DP_DC1_MEDIA_BLOCK_READ:
+   case GEN75_MSG_DP_DC1_TYPED_SURFACE_READ:
+   case GEN75_MSG_DP_DC1_TYPED_ATOMIC_OP:
+   case GEN75_MSG_DP_DC1_TYPED_ATOMIC_OP_SIMD4X2:
+   case GEN75_MSG_DP_DC1_MEDIA_BLOCK_WRITE:
+   case GEN75_MSG_DP_DC1_ATOMIC_COUNTER_OP:
+   case GEN75_MSG_DP_DC1_ATOMIC_COUNTER_OP_SIMD4X2:
+   case GEN75_MSG_DP_DC1_TYPED_SURFACE_WRITE:
+   default:
+      disasm_printer_add(printer, "0x%x",
+            GEN_EXTRACT(mdesc, GEN6_MSG_DP_CTRL));
+      break;
+   }
+
+   disasm_printer_add(printer, ")");
+}
+
+static void
 disasm_printer_add_mdesc_dp_rc(struct disasm_printer *printer,
                                const struct disasm_inst *inst,
                                uint32_t mdesc)
@@ -1338,10 +1504,17 @@ disasm_printer_add_mdesc(struct disasm_printer *printer,
    case GEN6_SFID_URB:
       disasm_printer_add_mdesc_urb(printer, inst, mdesc);
       break;
-   case GEN6_SFID_DP_CC:
+   case GEN6_SFID_SPAWNER:
+      disasm_printer_add_mdesc_spawner(printer, inst, mdesc);
+      break;
    case GEN7_SFID_DP_DC0:
-   case GEN7_SFID_PI:
+      disasm_printer_add_mdesc_dp_dc0(printer, inst, mdesc);
+      break;
    case GEN75_SFID_DP_DC1:
+      disasm_printer_add_mdesc_dp_dc1(printer, inst, mdesc);
+      break;
+   case GEN6_SFID_DP_CC:
+   case GEN7_SFID_PI:
    default:
       break;
    }
diff --git a/src/gallium/drivers/nouveau/nv50/nv50_context.h b/src/gallium/drivers/nouveau/nv50/nv50_context.h
index 9557317..45eb554 100644
--- a/src/gallium/drivers/nouveau/nv50/nv50_context.h
+++ b/src/gallium/drivers/nouveau/nv50/nv50_context.h
@@ -178,8 +178,9 @@ struct nv50_context {
    uint32_t rt_array_mode;
 
    struct pipe_query *cond_query;
-   boolean cond_cond;
+   boolean cond_cond; /* inverted rendering condition */
    uint cond_mode;
+   uint32_t cond_condmode; /* the calculated condition */
 
    struct nv50_blitctx *blit;
 };
diff --git a/src/gallium/drivers/nouveau/nv50/nv50_query.c b/src/gallium/drivers/nouveau/nv50/nv50_query.c
index a373dc6..e0671ce 100644
--- a/src/gallium/drivers/nouveau/nv50/nv50_query.c
+++ b/src/gallium/drivers/nouveau/nv50/nv50_query.c
@@ -158,7 +158,10 @@ nv50_query_begin(struct pipe_context *pipe, struct pipe_query *pq)
       /* XXX: can we do this with the GPU, and sync with respect to a previous
        *  query ?
        */
+      q->data[0] = q->sequence; /* initialize sequence */
       q->data[1] = 1; /* initial render condition = TRUE */
+      q->data[4] = q->sequence + 1; /* for comparison COND_MODE */
+      q->data[5] = 0;
    }
    if (!q->is64bit)
       q->data[0] = q->sequence++; /* the previously used one */
@@ -327,30 +330,67 @@ nv50_render_condition(struct pipe_context *pipe,
    struct nv50_context *nv50 = nv50_context(pipe);
    struct nouveau_pushbuf *push = nv50->base.pushbuf;
    struct nv50_query *q;
+   uint32_t cond;
+   boolean wait =
+      mode != PIPE_RENDER_COND_NO_WAIT &&
+      mode != PIPE_RENDER_COND_BY_REGION_NO_WAIT;
+
+   if (!pq) {
+      cond = NV50_3D_COND_MODE_ALWAYS;
+   }
+   else {
+      q = nv50_query(pq);
+      /* NOTE: comparison of 2 queries only works if both have completed */
+      switch (q->type) {
+      case PIPE_QUERY_SO_OVERFLOW_PREDICATE:
+         cond = condition ? NV50_3D_COND_MODE_EQUAL :
+                            NV50_3D_COND_MODE_NOT_EQUAL;
+         wait = TRUE;
+         break;
+      case PIPE_QUERY_OCCLUSION_COUNTER:
+      case PIPE_QUERY_OCCLUSION_PREDICATE:
+         if (likely(!condition)) {
+            /* XXX: Placeholder, handle nesting here if available */
+            if (unlikely(false))
+               cond = wait ? NV50_3D_COND_MODE_NOT_EQUAL :
+                             NV50_3D_COND_MODE_ALWAYS;
+            else
+               cond = NV50_3D_COND_MODE_RES_NON_ZERO;
+         } else {
+            cond = wait ? NV50_3D_COND_MODE_EQUAL : NV50_3D_COND_MODE_ALWAYS;
+         }
+         break;
+      default:
+         assert(!"render condition query not a predicate");
+         cond = NV50_3D_COND_MODE_ALWAYS;
+         break;
+      }
+   }
 
    nv50->cond_query = pq;
    nv50->cond_cond = condition;
+   nv50->cond_condmode = cond;
    nv50->cond_mode = mode;
 
-   PUSH_SPACE(push, 9);
-
    if (!pq) {
+      PUSH_SPACE(push, 2);
       BEGIN_NV04(push, NV50_3D(COND_MODE), 1);
-      PUSH_DATA (push, NV50_3D_COND_MODE_ALWAYS);
+      PUSH_DATA (push, cond);
       return;
    }
-   q = nv50_query(pq);
 
-   if (mode == PIPE_RENDER_COND_WAIT ||
-       mode == PIPE_RENDER_COND_BY_REGION_WAIT) {
+   PUSH_SPACE(push, 9);
+
+   if (wait) {
       BEGIN_NV04(push, SUBC_3D(NV50_GRAPH_SERIALIZE), 1);
       PUSH_DATA (push, 0);
    }
 
+   PUSH_REFN (push, q->bo, NOUVEAU_BO_GART | NOUVEAU_BO_RD);
    BEGIN_NV04(push, NV50_3D(COND_ADDRESS_HIGH), 3);
    PUSH_DATAh(push, q->bo->offset + q->offset);
    PUSH_DATA (push, q->bo->offset + q->offset);
-   PUSH_DATA (push, NV50_3D_COND_MODE_RES_NON_ZERO);
+   PUSH_DATA (push, cond);
 
    BEGIN_NV04(push, NV50_2D(COND_ADDRESS_HIGH), 2);
    PUSH_DATAh(push, q->bo->offset + q->offset);
diff --git a/src/gallium/drivers/nouveau/nv50/nv50_screen.c b/src/gallium/drivers/nouveau/nv50/nv50_screen.c
index 4ee5980..825e0ba 100644
--- a/src/gallium/drivers/nouveau/nv50/nv50_screen.c
+++ b/src/gallium/drivers/nouveau/nv50/nv50_screen.c
@@ -172,6 +172,7 @@ nv50_screen_get_param(struct pipe_screen *pscreen, enum pipe_cap param)
    case PIPE_CAP_PREFER_BLIT_BASED_TEXTURE_TRANSFER:
    case PIPE_CAP_TGSI_FS_FINE_DERIVATIVE:
    case PIPE_CAP_SAMPLER_VIEW_TARGET:
+   case PIPE_CAP_CONDITIONAL_RENDER_INVERTED:
       return 1;
    case PIPE_CAP_SEAMLESS_CUBE_MAP:
       return 1; /* class_3d >= NVA0_3D_CLASS; */
@@ -203,7 +204,6 @@ nv50_screen_get_param(struct pipe_screen *pscreen, enum pipe_cap param)
    case PIPE_CAP_TGSI_VS_WINDOW_SPACE_POSITION:
    case PIPE_CAP_COMPUTE:
    case PIPE_CAP_DRAW_INDIRECT:
-   case PIPE_CAP_CONDITIONAL_RENDER_INVERTED:
    case PIPE_CAP_CLIP_HALFZ:
       return 0;
 
diff --git a/src/gallium/drivers/nouveau/nv50/nv50_surface.c b/src/gallium/drivers/nouveau/nv50/nv50_surface.c
index e1dd6e0..e1d2b26 100644
--- a/src/gallium/drivers/nouveau/nv50/nv50_surface.c
+++ b/src/gallium/drivers/nouveau/nv50/nv50_surface.c
@@ -1297,7 +1297,7 @@ nv50_blit_eng2d(struct nv50_context *nv50, const struct pipe_blit_info *info)
 
    if (nv50->cond_query && info->render_condition_enable) {
       BEGIN_NV04(push, NV50_2D(COND_MODE), 1);
-      PUSH_DATA (push, NV50_2D_COND_MODE_RES_NON_ZERO);
+      PUSH_DATA (push, nv50->cond_condmode);
    }
 
    if (mask != 0xffffffff) {
diff --git a/src/gallium/drivers/r300/r300_state.c b/src/gallium/drivers/r300/r300_state.c
index cfcc19d..6ce0329 100644
--- a/src/gallium/drivers/r300/r300_state.c
+++ b/src/gallium/drivers/r300/r300_state.c
@@ -1432,7 +1432,7 @@ static void r300_bind_rs_state(struct pipe_context* pipe, void* state)
         }
     }
 
-    if (last_clip_halfz != r300->clip_halfz) {
+    if (r300->screen->caps.has_tcl && last_clip_halfz != r300->clip_halfz) {
         r300_mark_atom_dirty(r300, &r300->vs_state);
     }
 }
diff --git a/src/gallium/drivers/r600/eg_asm.c b/src/gallium/drivers/r600/eg_asm.c
index acb3040..295cb4d 100644
--- a/src/gallium/drivers/r600/eg_asm.c
+++ b/src/gallium/drivers/r600/eg_asm.c
@@ -43,10 +43,10 @@ int eg_bytecode_cf_build(struct r600_bytecode *bc, struct r600_bytecode_cf *cf)
 			/* prepend ALU_EXTENDED if we need more than 2 kcache sets */
 			if (cf->eg_alu_extended) {
 				bc->bytecode[id++] =
-						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK_INDEX_MODE0(V_SQ_CF_INDEX_NONE) |
-						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK_INDEX_MODE1(V_SQ_CF_INDEX_NONE) |
-						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK_INDEX_MODE2(V_SQ_CF_INDEX_NONE) |
-						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK_INDEX_MODE3(V_SQ_CF_INDEX_NONE) |
+						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK_INDEX_MODE0(cf->kcache[0].index_mode) |
+						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK_INDEX_MODE1(cf->kcache[1].index_mode) |
+						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK_INDEX_MODE2(cf->kcache[2].index_mode) |
+						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK_INDEX_MODE3(cf->kcache[3].index_mode) |
 						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK2(cf->kcache[2].bank) |
 						S_SQ_CF_ALU_WORD0_EXT_KCACHE_BANK3(cf->kcache[3].bank) |
 						S_SQ_CF_ALU_WORD0_EXT_KCACHE_MODE2(cf->kcache[2].mode);
@@ -143,3 +143,47 @@ void eg_bytecode_export_read(struct r600_bytecode *bc,
 	output->comp_mask = G_SQ_CF_ALLOC_EXPORT_WORD1_BUF_COMP_MASK(word1);
 }
 #endif
+
+int egcm_load_index_reg(struct r600_bytecode *bc, unsigned id, bool inside_alu_clause)
+{
+	struct r600_bytecode_alu alu;
+	int r;
+	unsigned type;
+
+	assert(id < 2);
+	assert(bc->chip_class >= EVERGREEN);
+
+	if (bc->index_loaded[id])
+		return 0;
+
+	memset(&alu, 0, sizeof(alu));
+	alu.op = ALU_OP1_MOVA_INT;
+	alu.src[0].sel = bc->index_reg[id];
+	alu.src[0].chan = 0;
+	alu.last = 1;
+	r = r600_bytecode_add_alu(bc, &alu);
+	if (r)
+		return r;
+
+	bc->ar_loaded = 0; /* clobbered */
+
+	memset(&alu, 0, sizeof(alu));
+	alu.op = id == 0 ? ALU_OP0_SET_CF_IDX0 : ALU_OP0_SET_CF_IDX1;
+	alu.last = 1;
+	r = r600_bytecode_add_alu(bc, &alu);
+	if (r)
+		return r;
+
+	/* Must split ALU group as index only applies to following group */
+	if (inside_alu_clause) {
+		type = bc->cf_last->op;
+		if ((r = r600_bytecode_add_cf(bc))) {
+			return r;
+		}
+		bc->cf_last->op = type;
+	}
+
+	bc->index_loaded[id] = 1;
+
+	return 0;
+}
diff --git a/src/gallium/drivers/r600/evergreen_compute.c b/src/gallium/drivers/r600/evergreen_compute.c
index 38b78c7..90fdd79 100644
--- a/src/gallium/drivers/r600/evergreen_compute.c
+++ b/src/gallium/drivers/r600/evergreen_compute.c
@@ -47,8 +47,9 @@
 #include "compute_memory_pool.h"
 #include "sb/sb_public.h"
 #ifdef HAVE_OPENCL
-#include "radeon_llvm_util.h"
+#include "radeon/radeon_llvm_util.h"
 #endif
+#include "radeon/radeon_elf_util.h"
 #include <inttypes.h>
 
 /**
@@ -198,18 +199,42 @@ void *evergreen_create_compute_state(
 {
 	struct r600_context *ctx = (struct r600_context *)ctx_;
 	struct r600_pipe_compute *shader = CALLOC_STRUCT(r600_pipe_compute);
-
 #ifdef HAVE_OPENCL
 	const struct pipe_llvm_program_header * header;
-	const unsigned char * code;
-	unsigned i;
-
-	shader->llvm_ctx = LLVMContextCreate();
+	const char *code;
+	void *p;
+	boolean use_kill;
 
 	COMPUTE_DBG(ctx->screen, "*** evergreen_create_compute_state\n");
-
 	header = cso->prog;
 	code = cso->prog + sizeof(struct pipe_llvm_program_header);
+#if HAVE_LLVM < 0x0306
+        (void)use_kill;
+	(void)p;
+	shader->llvm_ctx = LLVMContextCreate();
+	shader->num_kernels = radeon_llvm_get_num_kernels(shader->llvm_ctx,
+				code, header->num_bytes);
+	shader->kernels = CALLOC(sizeof(struct r600_kernel),
+				shader->num_kernels);
+	{
+		unsigned i;
+		for (i = 0; i < shader->num_kernels; i++) {
+			struct r600_kernel *kernel = &shader->kernels[i];
+			kernel->llvm_module = radeon_llvm_get_kernel_module(
+				shader->llvm_ctx, i, code, header->num_bytes);
+		}
+	}
+#else
+	memset(&shader->binary, 0, sizeof(shader->binary));
+	radeon_elf_read(code, header->num_bytes, &shader->binary, true);
+	r600_create_shader(&shader->bc, &shader->binary, &use_kill);
+
+	shader->code_bo = r600_compute_buffer_alloc_vram(ctx->screen,
+							shader->bc.ndw * 4);
+	p = r600_buffer_map_sync_with_rings(&ctx->b, shader->code_bo, PIPE_TRANSFER_WRITE);
+	memcpy(p, shader->bc.bytecode, shader->bc.ndw * 4);
+	ctx->b.ws->buffer_unmap(shader->code_bo->cs_buf);
+#endif
 #endif
 
 	shader->ctx = (struct r600_context*)ctx;
@@ -217,17 +242,6 @@ void *evergreen_create_compute_state(
 	shader->private_size = cso->req_private_mem;
 	shader->input_size = cso->req_input_mem;
 
-#ifdef HAVE_OPENCL 
-	shader->num_kernels = radeon_llvm_get_num_kernels(shader->llvm_ctx, code,
-							header->num_bytes);
-	shader->kernels = CALLOC(sizeof(struct r600_kernel), shader->num_kernels);
-
-	for (i = 0; i < shader->num_kernels; i++) {
-		struct r600_kernel *kernel = &shader->kernels[i];
-		kernel->llvm_module = radeon_llvm_get_kernel_module(shader->llvm_ctx, i,
-							code, header->num_bytes);
-	}
-#endif
 	return shader;
 }
 
@@ -238,14 +252,6 @@ void evergreen_delete_compute_state(struct pipe_context *ctx, void* state)
 	if (!shader)
 		return;
 
-	FREE(shader->kernels);
-
-#ifdef HAVE_OPENCL
-	if (shader->llvm_ctx){
-		LLVMContextDispose(shader->llvm_ctx);
-	}
-#endif
-
 	FREE(shader);
 }
 
@@ -347,7 +353,13 @@ static void evergreen_emit_direct_dispatch(
 	unsigned wave_divisor = (16 * num_pipes);
 	int group_size = 1;
 	int grid_size = 1;
-	unsigned lds_size = shader->local_size / 4 + shader->active_kernel->bc.nlds_dw;
+	unsigned lds_size = shader->local_size / 4 +
+#if HAVE_LLVM < 0x0306
+		shader->active_kernel->bc.nlds_dw;
+#else
+		shader->bc.nlds_dw;
+#endif
+
 
 	/* Calculate group_size/grid_size */
 	for (i = 0; i < 3; i++) {
@@ -520,19 +532,34 @@ void evergreen_emit_cs_shader(
 	struct r600_cs_shader_state *state =
 					(struct r600_cs_shader_state*)atom;
 	struct r600_pipe_compute *shader = state->shader;
-	struct r600_kernel *kernel = &shader->kernels[state->kernel_index];
 	struct radeon_winsys_cs *cs = rctx->b.rings.gfx.cs;
+	uint64_t va;
+	struct r600_resource *code_bo;
+	unsigned ngpr, nstack;
+
+#if HAVE_LLVM < 0x0306
+	struct r600_kernel *kernel = &shader->kernels[state->kernel_index];
+	code_bo = kernel->code_bo;
+	va = kernel->code_bo->gpu_address;
+	ngpr = kernel->bc.ngpr;
+	nstack = kernel->bc.nstack;
+#else
+	code_bo = shader->code_bo;
+	va = shader->code_bo->gpu_address + state->pc;
+	ngpr = shader->bc.ngpr;
+	nstack = shader->bc.nstack;
+#endif
 
 	r600_write_compute_context_reg_seq(cs, R_0288D0_SQ_PGM_START_LS, 3);
-	radeon_emit(cs, kernel->code_bo->gpu_address >> 8); /* R_0288D0_SQ_PGM_START_LS */
+	radeon_emit(cs, va >> 8); /* R_0288D0_SQ_PGM_START_LS */
 	radeon_emit(cs,           /* R_0288D4_SQ_PGM_RESOURCES_LS */
-			S_0288D4_NUM_GPRS(kernel->bc.ngpr)
-			| S_0288D4_STACK_SIZE(kernel->bc.nstack));
+			S_0288D4_NUM_GPRS(ngpr)
+			| S_0288D4_STACK_SIZE(nstack));
 	radeon_emit(cs, 0);	/* R_0288D8_SQ_PGM_RESOURCES_LS_2 */
 
 	radeon_emit(cs, PKT3C(PKT3_NOP, 0, 0));
 	radeon_emit(cs, r600_context_bo_reloc(&rctx->b, &rctx->b.rings.gfx,
-					      kernel->code_bo, RADEON_USAGE_READ,
+					      code_bo, RADEON_USAGE_READ,
 					      RADEON_PRIO_SHADER_DATA));
 }
 
@@ -542,46 +569,54 @@ static void evergreen_launch_grid(
 		uint32_t pc, const void *input)
 {
 	struct r600_context *ctx = (struct r600_context *)ctx_;
-
+#ifdef HAVE_OPENCL
 	struct r600_pipe_compute *shader = ctx->cs_shader_state.shader;
+	boolean use_kill;
+
+#if HAVE_LLVM < 0x0306
 	struct r600_kernel *kernel = &shader->kernels[pc];
+	(void)use_kill;
+        if (!kernel->code_bo) {
+                void *p;
+                struct r600_bytecode *bc = &kernel->bc;
+                LLVMModuleRef mod = kernel->llvm_module;
+                boolean use_kill = false;
+                bool dump = (ctx->screen->b.debug_flags & DBG_CS) != 0;
+                unsigned use_sb = ctx->screen->b.debug_flags & DBG_SB_CS;
+                unsigned sb_disasm = use_sb ||
+                        (ctx->screen->b.debug_flags & DBG_SB_DISASM);
+
+                r600_bytecode_init(bc, ctx->b.chip_class, ctx->b.family,
+                           ctx->screen->has_compressed_msaa_texturing);
+                bc->type = TGSI_PROCESSOR_COMPUTE;
+                bc->isa = ctx->isa;
+                r600_llvm_compile(mod, ctx->b.family, bc, &use_kill, dump);
+
+                if (dump && !sb_disasm) {
+                        r600_bytecode_disasm(bc);
+                } else if ((dump && sb_disasm) || use_sb) {
+                        if (r600_sb_bytecode_process(ctx, bc, NULL, dump, use_sb))
+                                R600_ERR("r600_sb_bytecode_process failed!\n");
+                }
+
+                kernel->code_bo = r600_compute_buffer_alloc_vram(ctx->screen,
+                                                        kernel->bc.ndw * 4);
+                p = r600_buffer_map_sync_with_rings(&ctx->b, kernel->code_bo, PIPE_TRANSFER_WRITE);
+                memcpy(p, kernel->bc.bytecode, kernel->bc.ndw * 4);
+                ctx->b.ws->buffer_unmap(kernel->code_bo->cs_buf);
+        }
+	shader->active_kernel = kernel;
+	ctx->cs_shader_state.kernel_index = pc;
+#else
+	ctx->cs_shader_state.pc = pc;
+	/* Get the config information for this kernel. */
+	r600_shader_binary_read_config(&shader->binary, &shader->bc, pc, &use_kill);
+#endif
+#endif
 
 	COMPUTE_DBG(ctx->screen, "*** evergreen_launch_grid: pc = %u\n", pc);
 
-#ifdef HAVE_OPENCL
-
-	if (!kernel->code_bo) {
-		void *p;
-		struct r600_bytecode *bc = &kernel->bc;
-		LLVMModuleRef mod = kernel->llvm_module;
-		boolean use_kill = false;
-		bool dump = (ctx->screen->b.debug_flags & DBG_CS) != 0;
-		unsigned use_sb = ctx->screen->b.debug_flags & DBG_SB_CS;
-		unsigned sb_disasm = use_sb ||
-			(ctx->screen->b.debug_flags & DBG_SB_DISASM);
-
-		r600_bytecode_init(bc, ctx->b.chip_class, ctx->b.family,
-			   ctx->screen->has_compressed_msaa_texturing);
-		bc->type = TGSI_PROCESSOR_COMPUTE;
-		bc->isa = ctx->isa;
-		r600_llvm_compile(mod, ctx->b.family, bc, &use_kill, dump);
-
-		if (dump && !sb_disasm) {
-			r600_bytecode_disasm(bc);
-		} else if ((dump && sb_disasm) || use_sb) {
-			if (r600_sb_bytecode_process(ctx, bc, NULL, dump, use_sb))
-				R600_ERR("r600_sb_bytecode_process failed!\n");
-		}
 
-		kernel->code_bo = r600_compute_buffer_alloc_vram(ctx->screen,
-							kernel->bc.ndw * 4);
-		p = r600_buffer_map_sync_with_rings(&ctx->b, kernel->code_bo, PIPE_TRANSFER_WRITE);
-		memcpy(p, kernel->bc.bytecode, kernel->bc.ndw * 4);
-		ctx->b.ws->buffer_unmap(kernel->code_bo->cs_buf);
-	}
-#endif
-	shader->active_kernel = kernel;
-	ctx->cs_shader_state.kernel_index = pc;
 	evergreen_compute_upload_input(ctx_, block_layout, grid_layout, input);
 	compute_emit_cs(ctx, block_layout, grid_layout);
 }
diff --git a/src/gallium/drivers/r600/evergreen_compute_internal.h b/src/gallium/drivers/r600/evergreen_compute_internal.h
index 0929d8d..95593dd 100644
--- a/src/gallium/drivers/r600/evergreen_compute_internal.h
+++ b/src/gallium/drivers/r600/evergreen_compute_internal.h
@@ -27,6 +27,8 @@
 
 #include "r600_asm.h"
 
+#if HAVE_LLVM < 0x0306
+
 struct r600_kernel {
 	unsigned count;
 #ifdef HAVE_OPENCL
@@ -36,13 +38,21 @@ struct r600_kernel {
 	struct r600_bytecode bc;
 };
 
+#endif
+
 struct r600_pipe_compute {
 	struct r600_context *ctx;
 
+#if HAVE_LLVM < 0x0306
 	unsigned num_kernels;
 	struct r600_kernel *kernels;
-
 	struct r600_kernel *active_kernel;
+#endif
+
+	struct radeon_shader_binary binary;
+	struct r600_resource *code_bo;
+	struct r600_bytecode bc;
+
 	unsigned local_size;
 	unsigned private_size;
 	unsigned input_size;
diff --git a/src/gallium/drivers/r600/evergreen_state.c b/src/gallium/drivers/r600/evergreen_state.c
index f74dd91..36b86aa 100644
--- a/src/gallium/drivers/r600/evergreen_state.c
+++ b/src/gallium/drivers/r600/evergreen_state.c
@@ -542,9 +542,9 @@ static void *evergreen_create_rs_state(struct pipe_context *ctx,
 			       S_028814_CULL_FRONT((state->cull_face & PIPE_FACE_FRONT) ? 1 : 0) |
 			       S_028814_CULL_BACK((state->cull_face & PIPE_FACE_BACK) ? 1 : 0) |
 			       S_028814_FACE(!state->front_ccw) |
-			       S_028814_POLY_OFFSET_FRONT_ENABLE(state->offset_tri) |
-			       S_028814_POLY_OFFSET_BACK_ENABLE(state->offset_tri) |
-			       S_028814_POLY_OFFSET_PARA_ENABLE(state->offset_tri) |
+			       S_028814_POLY_OFFSET_FRONT_ENABLE(util_get_offset(state, state->fill_front)) |
+			       S_028814_POLY_OFFSET_BACK_ENABLE(util_get_offset(state, state->fill_back)) |
+			       S_028814_POLY_OFFSET_PARA_ENABLE(state->offset_point || state->offset_line) |
 			       S_028814_POLY_MODE(state->fill_front != PIPE_POLYGON_MODE_FILL ||
 						  state->fill_back != PIPE_POLYGON_MODE_FILL) |
 			       S_028814_POLYMODE_FRONT_PTYPE(r600_translate_fill(state->fill_front)) |
diff --git a/src/gallium/drivers/r600/r600_asm.c b/src/gallium/drivers/r600/r600_asm.c
index 8aa69b5..ce3c2d1 100644
--- a/src/gallium/drivers/r600/r600_asm.c
+++ b/src/gallium/drivers/r600/r600_asm.c
@@ -819,6 +819,10 @@ static int merge_inst_groups(struct r600_bytecode *bc, struct r600_bytecode_alu
 			have_rel = 1;
 		}
 
+		if (alu->op == ALU_OP0_SET_CF_IDX0 ||
+			alu->op == ALU_OP0_SET_CF_IDX1)
+			return 0; /* data hazard with MOVA */
+
 		/* Let's check source gprs */
 		num_src = r600_bytecode_get_num_operands(bc, alu);
 		for (src = 0; src < num_src; ++src) {
@@ -884,7 +888,7 @@ static int merge_inst_groups(struct r600_bytecode *bc, struct r600_bytecode_alu
 /* we'll keep kcache sets sorted by bank & addr */
 static int r600_bytecode_alloc_kcache_line(struct r600_bytecode *bc,
 		struct r600_bytecode_kcache *kcache,
-		unsigned bank, unsigned line)
+		unsigned bank, unsigned line, unsigned index_mode)
 {
 	int i, kcache_banks = bc->chip_class >= EVERGREEN ? 4 : 2;
 
@@ -907,6 +911,7 @@ static int r600_bytecode_alloc_kcache_line(struct r600_bytecode *bc,
 				kcache[i].mode = V_SQ_CF_KCACHE_LOCK_1;
 				kcache[i].bank = bank;
 				kcache[i].addr = line;
+				kcache[i].index_mode = index_mode;
 				return 0;
 			}
 
@@ -936,6 +941,7 @@ static int r600_bytecode_alloc_kcache_line(struct r600_bytecode *bc,
 			kcache[i].mode = V_SQ_CF_KCACHE_LOCK_1;
 			kcache[i].bank = bank;
 			kcache[i].addr = line;
+			kcache[i].index_mode = index_mode;
 			return 0;
 		}
 	}
@@ -949,15 +955,16 @@ static int r600_bytecode_alloc_inst_kcache_lines(struct r600_bytecode *bc,
 	int i, r;
 
 	for (i = 0; i < 3; i++) {
-		unsigned bank, line, sel = alu->src[i].sel;
+		unsigned bank, line, sel = alu->src[i].sel, index_mode;
 
 		if (sel < 512)
 			continue;
 
 		bank = alu->src[i].kc_bank;
 		line = (sel-512)>>4;
+		index_mode = alu->src[i].kc_rel ? 1 : 0; // V_SQ_CF_INDEX_0 / V_SQ_CF_INDEX_NONE
 
-		if ((r = r600_bytecode_alloc_kcache_line(bc, kcache, bank, line)))
+		if ((r = r600_bytecode_alloc_kcache_line(bc, kcache, bank, line, index_mode)))
 			return r;
 	}
 	return 0;
@@ -1028,8 +1035,9 @@ static int r600_bytecode_alloc_kcache_lines(struct r600_bytecode *bc,
 		memcpy(bc->cf_last->kcache, kcache, 4 * sizeof(struct r600_bytecode_kcache));
 	}
 
-	/* if we actually used more than 2 kcache sets - use ALU_EXTENDED on eg+ */
-	if (kcache[2].mode != V_SQ_CF_KCACHE_NOP) {
+	/* if we actually used more than 2 kcache sets, or have relative indexing - use ALU_EXTENDED on eg+ */
+	if (kcache[2].mode != V_SQ_CF_KCACHE_NOP ||
+		kcache[0].index_mode || kcache[1].index_mode || kcache[2].index_mode || kcache[3].index_mode) {
 		if (bc->chip_class < EVERGREEN)
 			return -ENOMEM;
 		bc->cf_last->eg_alu_extended = 1;
@@ -1149,6 +1157,13 @@ int r600_bytecode_add_alu_type(struct r600_bytecode *bc,
 	}
 	bc->cf_last->op = type;
 
+	/* Load index register if required */
+	if (bc->chip_class >= EVERGREEN) {
+		for (i = 0; i < 3; i++)
+			if (nalu->src[i].kc_bank && nalu->src[i].kc_rel)
+				egcm_load_index_reg(bc, 0, true);
+	}
+
 	/* Check AR usage and load it if required */
 	for (i = 0; i < 3; i++)
 		if (nalu->src[i].rel && !bc->ar_loaded)
@@ -1274,6 +1289,12 @@ int r600_bytecode_add_vtx(struct r600_bytecode *bc, const struct r600_bytecode_v
 		return -ENOMEM;
 	memcpy(nvtx, vtx, sizeof(struct r600_bytecode_vtx));
 
+	/* Load index register if required */
+	if (bc->chip_class >= EVERGREEN) {
+		if (vtx->buffer_index_mode)
+			egcm_load_index_reg(bc, 0, false);
+	}
+
 	/* cf can contains only alu or only vtx or only tex */
 	if (bc->cf_last == NULL ||
 	    last_inst_was_not_vtx_fetch(bc) ||
@@ -1320,6 +1341,12 @@ int r600_bytecode_add_tex(struct r600_bytecode *bc, const struct r600_bytecode_t
 		return -ENOMEM;
 	memcpy(ntex, tex, sizeof(struct r600_bytecode_tex));
 
+	/* Load index register if required */
+	if (bc->chip_class >= EVERGREEN) {
+		if (tex->sampler_index_mode || tex->resource_index_mode)
+			egcm_load_index_reg(bc, 1, false);
+	}
+
 	/* we can't fetch data und use it as texture lookup address in the same TEX clause */
 	if (bc->cf_last != NULL &&
 		bc->cf_last->op == CF_OP_TEX) {
@@ -1400,6 +1427,8 @@ static int r600_bytecode_vtx_build(struct r600_bytecode *bc, struct r600_bytecod
 				S_SQ_VTX_WORD1_GPR_DST_GPR(vtx->dst_gpr);
 	bc->bytecode[id] = S_SQ_VTX_WORD2_OFFSET(vtx->offset)|
 				S_SQ_VTX_WORD2_ENDIAN_SWAP(vtx->endian);
+	if (bc->chip_class >= EVERGREEN)
+		bc->bytecode[id] |= ((vtx->buffer_index_mode & 0x3) << 21); // S_SQ_VTX_WORD2_BIM(vtx->buffer_index_mode);
 	if (bc->chip_class < CAYMAN)
 		bc->bytecode[id] |= S_SQ_VTX_WORD2_MEGA_FETCH(1);
 	id++;
@@ -1410,12 +1439,16 @@ static int r600_bytecode_vtx_build(struct r600_bytecode *bc, struct r600_bytecod
 /* common to all 3 families */
 static int r600_bytecode_tex_build(struct r600_bytecode *bc, struct r600_bytecode_tex *tex, unsigned id)
 {
-	bc->bytecode[id++] = S_SQ_TEX_WORD0_TEX_INST(
+	bc->bytecode[id] = S_SQ_TEX_WORD0_TEX_INST(
 					r600_isa_fetch_opcode(bc->isa->hw_class, tex->op)) |
 			    EG_S_SQ_TEX_WORD0_INST_MOD(tex->inst_mod) |
 				S_SQ_TEX_WORD0_RESOURCE_ID(tex->resource_id) |
 				S_SQ_TEX_WORD0_SRC_GPR(tex->src_gpr) |
 				S_SQ_TEX_WORD0_SRC_REL(tex->src_rel);
+	if (bc->chip_class >= EVERGREEN)
+		bc->bytecode[id] |= ((tex->sampler_index_mode & 0x3) << 27) | // S_SQ_TEX_WORD0_SIM(tex->sampler_index_mode);
+				((tex->resource_index_mode & 0x3) << 25); // S_SQ_TEX_WORD0_RIM(tex->resource_index_mode)
+	id++;
 	bc->bytecode[id++] = S_SQ_TEX_WORD1_DST_GPR(tex->dst_gpr) |
 				S_SQ_TEX_WORD1_DST_REL(tex->dst_rel) |
 				S_SQ_TEX_WORD1_DST_SEL_X(tex->dst_sel_x) |
@@ -1847,6 +1880,7 @@ static int print_indent(int p, int c)
 
 void r600_bytecode_disasm(struct r600_bytecode *bc)
 {
+	const char *index_mode[] = {"CF_INDEX_NONE", "CF_INDEX_0", "CF_INDEX_1"};
 	static int index = 0;
 	struct r600_bytecode_cf *cf = NULL;
 	struct r600_bytecode_alu *alu = NULL;
@@ -1897,8 +1931,10 @@ void r600_bytecode_disasm(struct r600_bytecode *bc)
 					if (cf->kcache[i].mode) {
 						int c_start = (cf->kcache[i].addr << 4);
 						int c_end = c_start + (cf->kcache[i].mode << 4);
-						fprintf(stderr, "KC%d[CB%d:%d-%d] ",
-						        i, cf->kcache[i].bank, c_start, c_end);
+						fprintf(stderr, "KC%d[CB%d:%d-%d%s%s] ",
+						        i, cf->kcache[i].bank, c_start, c_end,
+						        cf->kcache[i].index_mode ? " " : "",
+						        cf->kcache[i].index_mode ? index_mode[cf->kcache[i].index_mode] : "");
 					}
 				}
 				fprintf(stderr, "\n");
@@ -2064,6 +2100,9 @@ void r600_bytecode_disasm(struct r600_bytecode *bc)
 			o += fprintf(stderr, ",  RID:%d", tex->resource_id);
 			o += fprintf(stderr, ", SID:%d  ", tex->sampler_id);
 
+			if (tex->sampler_index_mode)
+				fprintf(stderr, "SQ_%s ", index_mode[tex->sampler_index_mode]);
+
 			if (tex->lod_bias)
 				fprintf(stderr, "LB:%d ", tex->lod_bias);
 
@@ -2115,6 +2154,9 @@ void r600_bytecode_disasm(struct r600_bytecode *bc)
 			if (bc->chip_class < CAYMAN && vtx->mega_fetch_count)
 				fprintf(stderr, "MFC:%d ", vtx->mega_fetch_count);
 
+			if (bc->chip_class >= EVERGREEN && vtx->buffer_index_mode)
+				fprintf(stderr, "SQ_%s ", index_mode[vtx->buffer_index_mode]);
+
 			fprintf(stderr, "UCF:%d ", vtx->use_const_fields);
 			fprintf(stderr, "FMT(DTA:%d ", vtx->data_format);
 			fprintf(stderr, "NUM:%d ", vtx->num_format_all);
diff --git a/src/gallium/drivers/r600/r600_asm.h b/src/gallium/drivers/r600/r600_asm.h
index 48ea3c4..e37d926 100644
--- a/src/gallium/drivers/r600/r600_asm.h
+++ b/src/gallium/drivers/r600/r600_asm.h
@@ -33,6 +33,7 @@ struct r600_bytecode_alu_src {
 	unsigned			abs;
 	unsigned			rel;
 	unsigned			kc_bank;
+	unsigned			kc_rel;
 	uint32_t			value;
 };
 
@@ -86,6 +87,9 @@ struct r600_bytecode_tex {
 	unsigned			src_sel_y;
 	unsigned			src_sel_z;
 	unsigned			src_sel_w;
+	/* indexed samplers/resources only on evergreen/cayman */
+	unsigned			sampler_index_mode;
+	unsigned			resource_index_mode;
 };
 
 struct r600_bytecode_vtx {
@@ -108,6 +112,7 @@ struct r600_bytecode_vtx {
 	unsigned			srf_mode_all;
 	unsigned			offset;
 	unsigned			endian;
+	unsigned			buffer_index_mode;
 };
 
 struct r600_bytecode_output {
@@ -132,6 +137,7 @@ struct r600_bytecode_kcache {
 	unsigned			bank;
 	unsigned			mode;
 	unsigned			addr;
+	unsigned			index_mode;
 };
 
 struct r600_bytecode_cf {
@@ -217,12 +223,15 @@ struct r600_bytecode {
 	unsigned	ar_chan;
 	unsigned        ar_handling;
 	unsigned        r6xx_nop_after_rel_dst;
+	bool		index_loaded[2];
+	unsigned 	index_reg[2]; /* indexing register CF_INDEX_[01] */
 	unsigned        debug_id;
 	struct r600_isa* isa;
 };
 
 /* eg_asm.c */
 int eg_bytecode_cf_build(struct r600_bytecode *bc, struct r600_bytecode_cf *cf);
+int egcm_load_index_reg(struct r600_bytecode *bc, unsigned id, bool inside_alu_clause);
 
 /* r600_asm.c */
 void r600_bytecode_init(struct r600_bytecode *bc,
diff --git a/src/gallium/drivers/r600/r600_llvm.c b/src/gallium/drivers/r600/r600_llvm.c
index 7661419..c19693a 100644
--- a/src/gallium/drivers/r600/r600_llvm.c
+++ b/src/gallium/drivers/r600/r600_llvm.c
@@ -13,8 +13,9 @@
 #include "r600_opcodes.h"
 #include "r600_shader.h"
 #include "r600_pipe.h"
-#include "radeon/radeon_llvm.h"
-#include "radeon/radeon_llvm_emit.h"
+#include "radeon_llvm.h"
+#include "radeon_llvm_emit.h"
+#include "radeon_elf_util.h"
 
 #include <stdio.h>
 
@@ -818,31 +819,20 @@ LLVMModuleRef r600_tgsi_llvm(
 #define R_028868_SQ_PGM_RESOURCES_VS                 0x028868
 #define R_028850_SQ_PGM_RESOURCES_PS                 0x028850
 
-unsigned r600_llvm_compile(
-	LLVMModuleRef mod,
-	enum radeon_family family,
-	struct r600_bytecode *bc,
-	boolean *use_kill,
-	unsigned dump)
+void r600_shader_binary_read_config(const struct radeon_shader_binary *binary,
+					struct r600_bytecode *bc,
+					uint64_t symbol_offset,
+					boolean *use_kill)
 {
-	unsigned r;
-	struct radeon_shader_binary binary;
-	const char * gpu_family = r600_get_llvm_processor_name(family);
 	unsigned i;
+	const unsigned char *config =
+		radeon_shader_binary_config_start(binary, symbol_offset);
 
-	memset(&binary, 0, sizeof(struct radeon_shader_binary));
-	r = radeon_llvm_compile(mod, &binary, gpu_family, dump);
-
-	assert(binary.code_size % 4 == 0);
-	bc->bytecode = CALLOC(1, binary.code_size);
-	memcpy(bc->bytecode, binary.code, binary.code_size);
-	bc->ndw = binary.code_size / 4;
-
-	for (i = 0; i < binary.config_size; i+= 8) {
+	for (i = 0; i < binary->config_size_per_symbol; i+= 8) {
 		unsigned reg =
-			util_le32_to_cpu(*(uint32_t*)(binary.config + i));
+			util_le32_to_cpu(*(uint32_t*)(config + i));
 		unsigned value =
-			util_le32_to_cpu(*(uint32_t*)(binary.config + i + 4));
+			util_le32_to_cpu(*(uint32_t*)(config + i + 4));
 		switch (reg) {
 		/* R600 / R700 */
 		case R_028850_SQ_PGM_RESOURCES_PS:
@@ -851,8 +841,8 @@ unsigned r600_llvm_compile(
 		case R_028844_SQ_PGM_RESOURCES_PS:
 		case R_028860_SQ_PGM_RESOURCES_VS:
 		case R_0288D4_SQ_PGM_RESOURCES_LS:
-			bc->ngpr = G_028844_NUM_GPRS(value);
-			bc->nstack = G_028844_STACK_SIZE(value);
+			bc->ngpr = MAX2(bc->ngpr, G_028844_NUM_GPRS(value));
+			bc->nstack = MAX2(bc->nstack, G_028844_STACK_SIZE(value));
 			break;
 		case R_02880C_DB_SHADER_CONTROL:
 			*use_kill = G_02880C_KILL_ENABLE(value);
@@ -863,6 +853,39 @@ unsigned r600_llvm_compile(
 		}
 	}
 
+}
+
+unsigned r600_create_shader(struct r600_bytecode *bc,
+		const struct radeon_shader_binary *binary,
+		boolean *use_kill)
+
+{
+	assert(binary->code_size % 4 == 0);
+	bc->bytecode = CALLOC(1, binary->code_size);
+	memcpy(bc->bytecode, binary->code, binary->code_size);
+	bc->ndw = binary->code_size / 4;
+
+	r600_shader_binary_read_config(binary, bc, 0, use_kill);
+
+	return 0;
+}
+
+unsigned r600_llvm_compile(
+	LLVMModuleRef mod,
+	enum radeon_family family,
+	struct r600_bytecode *bc,
+	boolean *use_kill,
+	unsigned dump)
+{
+	unsigned r;
+	struct radeon_shader_binary binary;
+	const char * gpu_family = r600_get_llvm_processor_name(family);
+
+	memset(&binary, 0, sizeof(struct radeon_shader_binary));
+	r = radeon_llvm_compile(mod, &binary, gpu_family, dump);
+
+	r = r600_create_shader(bc, &binary, use_kill);
+
 	FREE(binary.code);
 	FREE(binary.config);
 
diff --git a/src/gallium/drivers/r600/r600_llvm.h b/src/gallium/drivers/r600/r600_llvm.h
index 3840a5a..9b5304d 100644
--- a/src/gallium/drivers/r600/r600_llvm.h
+++ b/src/gallium/drivers/r600/r600_llvm.h
@@ -10,6 +10,7 @@
 struct r600_bytecode;
 struct r600_shader_ctx;
 struct radeon_llvm_context;
+struct radeon_shader_binary;
 enum radeon_family;
 
 LLVMModuleRef r600_tgsi_llvm(
@@ -23,6 +24,15 @@ unsigned r600_llvm_compile(
 	boolean *use_kill,
 	unsigned dump);
 
+unsigned r600_create_shader(struct r600_bytecode *bc,
+		const struct radeon_shader_binary *binary,
+		boolean *use_kill);
+
+void r600_shader_binary_read_config(const struct radeon_shader_binary *binary,
+		struct r600_bytecode *bc,
+		uint64_t symbol_offset,
+		boolean *use_kill);
+
 #endif /* defined R600_USE_LLVM || defined HAVE_OPENCL */
 
 #endif /* R600_LLVM_H */
diff --git a/src/gallium/drivers/r600/r600_pipe.c b/src/gallium/drivers/r600/r600_pipe.c
index c86daa6..0b571e4 100644
--- a/src/gallium/drivers/r600/r600_pipe.c
+++ b/src/gallium/drivers/r600/r600_pipe.c
@@ -472,7 +472,11 @@ static int r600_get_shader_param(struct pipe_screen* pscreen, unsigned shader, e
 		return 16;
         case PIPE_SHADER_CAP_PREFERRED_IR:
 		if (shader == PIPE_SHADER_COMPUTE) {
+#if HAVE_LLVM < 0x0306
 			return PIPE_SHADER_IR_LLVM;
+#else
+			return PIPE_SHADER_IR_NATIVE;
+#endif
 		} else {
 			return PIPE_SHADER_IR_TGSI;
 		}
diff --git a/src/gallium/drivers/r600/r600_pipe.h b/src/gallium/drivers/r600/r600_pipe.h
index fa9d34b..40b0328 100644
--- a/src/gallium/drivers/r600/r600_pipe.h
+++ b/src/gallium/drivers/r600/r600_pipe.h
@@ -146,6 +146,7 @@ struct r600_clip_state {
 struct r600_cs_shader_state {
 	struct r600_atom atom;
 	unsigned kernel_index;
+	unsigned pc;
 	struct r600_pipe_compute *shader;
 };
 
diff --git a/src/gallium/drivers/r600/r600_shader.c b/src/gallium/drivers/r600/r600_shader.c
index 9e9a557..aab4215 100644
--- a/src/gallium/drivers/r600/r600_shader.c
+++ b/src/gallium/drivers/r600/r600_shader.c
@@ -161,6 +161,8 @@ int r600_pipe_shader_create(struct pipe_context *ctx,
 
 	/* disable SB for geom shaders - it can't handle the CF_EMIT instructions */
 	use_sb &= (shader->shader.processor_type != TGSI_PROCESSOR_GEOMETRY);
+	/* disable SB for shaders using CF_INDEX_0/1 (sampler/ubo array indexing) as it doesn't handle those currently */
+	use_sb &= !shader->shader.uses_index_registers;
 
 	/* Check if the bytecode has already been built.  When using the llvm
 	 * backend, r600_shader_from_tgsi() will take care of building the
@@ -265,6 +267,7 @@ struct r600_shader_src {
 	unsigned				abs;
 	unsigned				rel;
 	unsigned				kc_bank;
+	boolean					kc_rel; /* true if cache bank is indexed */
 	uint32_t				value[4];
 };
 
@@ -325,7 +328,7 @@ static int tgsi_bgnloop(struct r600_shader_ctx *ctx);
 static int tgsi_endloop(struct r600_shader_ctx *ctx);
 static int tgsi_loop_brk_cont(struct r600_shader_ctx *ctx);
 static int tgsi_fetch_rel_const(struct r600_shader_ctx *ctx,
-                                unsigned int cb_idx, unsigned int offset, unsigned ar_chan,
+                                unsigned int cb_idx, unsigned cb_rel, unsigned int offset, unsigned ar_chan,
                                 unsigned int dst_reg);
 static void r600_bytecode_src(struct r600_bytecode_alu_src *bc_src,
 			const struct r600_shader_src *shader_src,
@@ -761,10 +764,33 @@ static int allocate_system_value_inputs(struct r600_shader_ctx *ctx, int gpr_off
 		return 0;
 	}
 
+	/* need to scan shader for system values and interpolateAtSample/Offset/Centroid */
 	while (!tgsi_parse_end_of_tokens(&parse)) {
 		tgsi_parse_token(&parse);
 
-		if (parse.FullToken.Token.Type == TGSI_TOKEN_TYPE_DECLARATION) {
+		if (parse.FullToken.Token.Type == TGSI_TOKEN_TYPE_INSTRUCTION) {
+			const struct tgsi_full_instruction *inst = &parse.FullToken.FullInstruction;
+			if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE ||
+				inst->Instruction.Opcode == TGSI_OPCODE_INTERP_OFFSET ||
+				inst->Instruction.Opcode == TGSI_OPCODE_INTERP_CENTROID)
+			{
+				int interpolate, location, k;
+
+				if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE) {
+					location = TGSI_INTERPOLATE_LOC_CENTER;
+					inputs[1].enabled = true; /* needs SAMPLEID */
+				} else if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_OFFSET) {
+					location = TGSI_INTERPOLATE_LOC_CENTER;
+					/* Needs sample positions, currently those are always available */
+				} else {
+					location = TGSI_INTERPOLATE_LOC_CENTROID;
+				}
+
+				interpolate = ctx->info.input_interpolate[inst->Src[0].Register.Index];
+				k = eg_get_interpolator_index(interpolate, location);
+				ctx->eg_interpolators[k].enabled = true;
+			}
+		} else if (parse.FullToken.Token.Type == TGSI_TOKEN_TYPE_DECLARATION) {
 			struct tgsi_full_declaration *d = &parse.FullToken.FullDeclaration;
 			if (d->Declaration.File == TGSI_FILE_SYSTEM_VALUE) {
 				for (k = 0; k < Elements(inputs); k++) {
@@ -812,6 +838,7 @@ static int evergreen_gpr_count(struct r600_shader_ctx *ctx)
 {
 	int i;
 	int num_baryc;
+	struct tgsi_parse_context parse;
 
 	memset(&ctx->eg_interpolators, 0, sizeof(ctx->eg_interpolators));
 
@@ -831,6 +858,39 @@ static int evergreen_gpr_count(struct r600_shader_ctx *ctx)
 			ctx->eg_interpolators[k].enabled = TRUE;
 	}
 
+	if (tgsi_parse_init(&parse, ctx->tokens) != TGSI_PARSE_OK) {
+		return 0;
+	}
+
+	/* need to scan shader for system values and interpolateAtSample/Offset/Centroid */
+	while (!tgsi_parse_end_of_tokens(&parse)) {
+		tgsi_parse_token(&parse);
+
+		if (parse.FullToken.Token.Type == TGSI_TOKEN_TYPE_INSTRUCTION) {
+			const struct tgsi_full_instruction *inst = &parse.FullToken.FullInstruction;
+			if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE ||
+				inst->Instruction.Opcode == TGSI_OPCODE_INTERP_OFFSET ||
+				inst->Instruction.Opcode == TGSI_OPCODE_INTERP_CENTROID)
+			{
+				int interpolate, location, k;
+
+				if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE) {
+					location = TGSI_INTERPOLATE_LOC_CENTER;
+				} else if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_OFFSET) {
+					location = TGSI_INTERPOLATE_LOC_CENTER;
+				} else {
+					location = TGSI_INTERPOLATE_LOC_CENTROID;
+				}
+
+				interpolate = ctx->info.input_interpolate[inst->Src[0].Register.Index];
+				k = eg_get_interpolator_index(interpolate, location);
+				ctx->eg_interpolators[k].enabled = true;
+			}
+		}
+	}
+
+	tgsi_parse_free(&parse);
+
 	/* assign gpr to each interpolator according to priority */
 	num_baryc = 0;
 	for (i = 0; i < Elements(ctx->eg_interpolators); i++) {
@@ -884,8 +944,8 @@ static int load_sample_position(struct r600_shader_ctx *ctx, struct r600_shader_
 	vtx.dst_gpr = t1;
 	vtx.dst_sel_x = 0;
 	vtx.dst_sel_y = 1;
-	vtx.dst_sel_z = 7;
-	vtx.dst_sel_w = 7;
+	vtx.dst_sel_z = 2;
+	vtx.dst_sel_w = 3;
 	vtx.data_format = FMT_32_32_32_32_FLOAT;
 	vtx.num_format_all = 2;
 	vtx.format_comp_all = 1;
@@ -974,12 +1034,15 @@ static void tgsi_src(struct r600_shader_ctx *ctx,
 	if (tgsi_src->Register.File == TGSI_FILE_CONSTANT) {
 		if (tgsi_src->Register.Dimension) {
 			r600_src->kc_bank = tgsi_src->Dimension.Index;
+			if (tgsi_src->Dimension.Indirect) {
+				r600_src->kc_rel = 1;
+			}
 		}
 	}
 }
 
 static int tgsi_fetch_rel_const(struct r600_shader_ctx *ctx,
-                                unsigned int cb_idx, unsigned int offset, unsigned ar_chan,
+                                unsigned int cb_idx, unsigned cb_rel, unsigned int offset, unsigned ar_chan,
                                 unsigned int dst_reg)
 {
 	struct r600_bytecode_vtx vtx;
@@ -1026,6 +1089,7 @@ static int tgsi_fetch_rel_const(struct r600_shader_ctx *ctx,
 	vtx.num_format_all = 2;		/* NUM_FORMAT_SCALED */
 	vtx.format_comp_all = 1;	/* FORMAT_COMP_SIGNED */
 	vtx.endian = r600_endian_swap(32);
+	vtx.buffer_index_mode = cb_rel; // cb_rel ? V_SQ_CF_INDEX_0 : V_SQ_CF_INDEX_NONE;
 
 	if ((r = r600_bytecode_add_vtx(ctx->bc, &vtx)))
 		return r;
@@ -1154,13 +1218,17 @@ static int tgsi_split_constant(struct r600_shader_ctx *ctx)
 			continue;
 		}
 
+		if (ctx->src[i].kc_rel)
+			ctx->shader->uses_index_registers = true;
+
 		if (ctx->src[i].rel) {
 			int chan = inst->Src[i].Indirect.Swizzle;
 			int treg = r600_get_temp(ctx);
-			if ((r = tgsi_fetch_rel_const(ctx, ctx->src[i].kc_bank, ctx->src[i].sel - 512, chan, treg)))
+			if ((r = tgsi_fetch_rel_const(ctx, ctx->src[i].kc_bank, ctx->src[i].kc_rel, ctx->src[i].sel - 512, chan, treg)))
 				return r;
 
 			ctx->src[i].kc_bank = 0;
+			ctx->src[i].kc_rel = 0;
 			ctx->src[i].sel = treg;
 			ctx->src[i].rel = 0;
 			j--;
@@ -1173,6 +1241,7 @@ static int tgsi_split_constant(struct r600_shader_ctx *ctx)
 				alu.src[0].chan = k;
 				alu.src[0].rel = ctx->src[i].rel;
 				alu.src[0].kc_bank = ctx->src[i].kc_bank;
+				alu.src[0].kc_rel = ctx->src[i].kc_rel;
 				alu.dst.sel = treg;
 				alu.dst.chan = k;
 				alu.dst.write = 1;
@@ -1756,6 +1825,7 @@ static int r600_shader_from_tgsi(struct r600_context *rctx,
 	ctx.gs_out_ring_offset = 0;
 	ctx.gs_next_vertex = 0;
 
+	shader->uses_index_registers = false;
 	ctx.face_gpr = -1;
 	ctx.fixed_pt_position_gpr = -1;
 	ctx.fragcoord_input = -1;
@@ -1839,8 +1909,13 @@ static int r600_shader_from_tgsi(struct r600_context *rctx,
 	if (ctx.type == TGSI_PROCESSOR_GEOMETRY) {
 		ctx.gs_export_gpr_treg = ctx.bc->ar_reg + 1;
 		ctx.temp_reg = ctx.bc->ar_reg + 2;
-	} else
+		ctx.bc->index_reg[0] = ctx.bc->ar_reg + 3;
+		ctx.bc->index_reg[1] = ctx.bc->ar_reg + 4;
+	} else {
 		ctx.temp_reg = ctx.bc->ar_reg + 1;
+		ctx.bc->index_reg[0] = ctx.bc->ar_reg + 2;
+		ctx.bc->index_reg[1] = ctx.bc->ar_reg + 3;
+	}
 
 	if (indirect_gprs) {
 		shader->max_arrays = 0;
@@ -2458,6 +2533,7 @@ static void r600_bytecode_src(struct r600_bytecode_alu_src *bc_src,
 	bc_src->rel = shader_src->rel;
 	bc_src->value = shader_src->value[bc_src->chan];
 	bc_src->kc_bank = shader_src->kc_bank;
+	bc_src->kc_rel = shader_src->kc_rel;
 }
 
 static void r600_bytecode_src_set_abs(struct r600_bytecode_alu_src *bc_src)
@@ -4544,6 +4620,171 @@ static int tgsi_msb(struct r600_shader_ctx *ctx)
 	return 0;
 }
 
+static int tgsi_interp_egcm(struct r600_shader_ctx *ctx)
+{
+	struct tgsi_full_instruction *inst = &ctx->parse.FullToken.FullInstruction;
+	struct r600_bytecode_alu alu;
+	int r, i = 0, k, interp_gpr, interp_base_chan, tmp, lasti;
+	unsigned location;
+	int input;
+
+	assert(inst->Src[0].Register.File == TGSI_FILE_INPUT);
+
+	input = inst->Src[0].Register.Index;
+
+	/* Interpolators have been marked for use already by allocate_system_value_inputs */
+	if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_OFFSET ||
+		inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE) {
+		location = TGSI_INTERPOLATE_LOC_CENTER; /* sample offset will be added explicitly */
+	}
+	else {
+		location = TGSI_INTERPOLATE_LOC_CENTROID;
+	}
+
+	k = eg_get_interpolator_index(ctx->shader->input[input].interpolate, location);
+	if (k < 0)
+		k = 0;
+	interp_gpr = ctx->eg_interpolators[k].ij_index / 2;
+	interp_base_chan = 2 * (ctx->eg_interpolators[k].ij_index % 2);
+
+	/* NOTE: currently offset is not perspective correct */
+	if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_OFFSET ||
+		inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE) {
+		int sample_gpr = -1;
+		int gradientsH, gradientsV;
+		struct r600_bytecode_tex tex;
+
+		if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE) {
+			sample_gpr = load_sample_position(ctx, &ctx->src[1], ctx->src[1].swizzle[0]);
+		}
+
+		gradientsH = r600_get_temp(ctx);
+		gradientsV = r600_get_temp(ctx);
+		for (i = 0; i < 2; i++) {
+			memset(&tex, 0, sizeof(struct r600_bytecode_tex));
+			tex.op = i == 0 ? FETCH_OP_GET_GRADIENTS_H : FETCH_OP_GET_GRADIENTS_V;
+			tex.src_gpr = interp_gpr;
+			tex.src_sel_x = interp_base_chan + 0;
+			tex.src_sel_y = interp_base_chan + 1;
+			tex.src_sel_z = 0;
+			tex.src_sel_w = 0;
+			tex.dst_gpr = i == 0 ? gradientsH : gradientsV;
+			tex.dst_sel_x = 0;
+			tex.dst_sel_y = 1;
+			tex.dst_sel_z = 7;
+			tex.dst_sel_w = 7;
+			tex.inst_mod = 1; // Use per pixel gradient calculation
+			tex.sampler_id = 0;
+			tex.resource_id = tex.sampler_id;
+			r = r600_bytecode_add_tex(ctx->bc, &tex);
+			if (r)
+				return r;
+		}
+
+		for (i = 0; i < 2; i++) {
+			memset(&alu, 0, sizeof(struct r600_bytecode_alu));
+			alu.op = ALU_OP3_MULADD;
+			alu.is_op3 = 1;
+			alu.src[0].sel = gradientsH;
+			alu.src[0].chan = i;
+			if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE) {
+				alu.src[1].sel = sample_gpr;
+				alu.src[1].chan = 2;
+			}
+			else {
+				r600_bytecode_src(&alu.src[1], &ctx->src[1], 0);
+			}
+			alu.src[2].sel = interp_gpr;
+			alu.src[2].chan = interp_base_chan + i;
+			alu.dst.sel = ctx->temp_reg;
+			alu.dst.chan = i;
+			alu.last = i == 1;
+
+			r = r600_bytecode_add_alu(ctx->bc, &alu);
+			if (r)
+				return r;
+		}
+
+		for (i = 0; i < 2; i++) {
+			memset(&alu, 0, sizeof(struct r600_bytecode_alu));
+			alu.op = ALU_OP3_MULADD;
+			alu.is_op3 = 1;
+			alu.src[0].sel = gradientsV;
+			alu.src[0].chan = i;
+			if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE) {
+				alu.src[1].sel = sample_gpr;
+				alu.src[1].chan = 3;
+			}
+			else {
+				r600_bytecode_src(&alu.src[1], &ctx->src[1], 1);
+			}
+			alu.src[2].sel = ctx->temp_reg;
+			alu.src[2].chan = i;
+			alu.dst.sel = ctx->temp_reg;
+			alu.dst.chan = i;
+			alu.last = i == 1;
+
+			r = r600_bytecode_add_alu(ctx->bc, &alu);
+			if (r)
+				return r;
+		}
+	}
+
+	tmp = r600_get_temp(ctx);
+	for (i = 0; i < 8; i++) {
+		memset(&alu, 0, sizeof(struct r600_bytecode_alu));
+		alu.op = i < 4 ? ALU_OP2_INTERP_ZW : ALU_OP2_INTERP_XY;
+
+		alu.dst.sel = tmp;
+		if ((i > 1 && i < 6)) {
+			alu.dst.write = 1;
+		}
+		else {
+			alu.dst.write = 0;
+		}
+		alu.dst.chan = i % 4;
+
+		if (inst->Instruction.Opcode == TGSI_OPCODE_INTERP_OFFSET ||
+			inst->Instruction.Opcode == TGSI_OPCODE_INTERP_SAMPLE) {
+			alu.src[0].sel = ctx->temp_reg;
+			alu.src[0].chan = 1 - (i % 2);
+		} else {
+			alu.src[0].sel = interp_gpr;
+			alu.src[0].chan = interp_base_chan + 1 - (i % 2);
+		}
+		alu.src[1].sel = V_SQ_ALU_SRC_PARAM_BASE + ctx->shader->input[input].lds_pos;
+		alu.src[1].chan = 0;
+
+		alu.last = i % 4 == 3;
+		alu.bank_swizzle_force = SQ_ALU_VEC_210;
+
+		r = r600_bytecode_add_alu(ctx->bc, &alu);
+		if (r)
+			return r;
+	}
+
+	// INTERP can't swizzle dst
+	lasti = tgsi_last_instruction(inst->Dst[0].Register.WriteMask);
+	for (i = 0; i <= lasti; i++) {
+		if (!(inst->Dst[0].Register.WriteMask & (1 << i)))
+			continue;
+
+		memset(&alu, 0, sizeof(struct r600_bytecode_alu));
+		alu.op = ALU_OP1_MOV;
+		alu.src[0].sel = tmp;
+		alu.src[0].chan = ctx->src[0].swizzle[i];
+		tgsi_dst(ctx, &inst->Dst[0], i, &alu.dst);
+		alu.dst.write = 1;
+		alu.last = i == lasti;
+		r = r600_bytecode_add_alu(ctx->bc, &alu);
+		if (r)
+			return r;
+	}
+
+	return 0;
+}
+
+
 static int tgsi_helper_copy(struct r600_shader_ctx *ctx, struct tgsi_full_instruction *inst)
 {
 	struct r600_bytecode_alu alu;
@@ -4817,6 +5058,7 @@ static int tgsi_tex(struct r600_shader_ctx *ctx)
 	unsigned sampler_src_reg = inst->Instruction.Opcode == TGSI_OPCODE_TXQ_LZ ? 0 : 1;
 	int8_t offset_x = 0, offset_y = 0, offset_z = 0;
 	boolean has_txq_cube_array_z = false;
+	unsigned sampler_index_mode;
 
 	if (inst->Instruction.Opcode == TGSI_OPCODE_TXQ &&
 	    ((inst->Texture.Texture == TGSI_TEXTURE_CUBE_ARRAY ||
@@ -4850,13 +5092,17 @@ static int tgsi_tex(struct r600_shader_ctx *ctx)
 		/* TGSI moves the sampler to src reg 3 for TXD */
 		sampler_src_reg = 3;
 
+		sampler_index_mode = inst->Src[sampler_src_reg].Indirect.Index == 2 ? 2 : 0; // CF_INDEX_1 : CF_INDEX_NONE
+
 		for (i = 1; i < 3; i++) {
 			/* set gradients h/v */
 			memset(&tex, 0, sizeof(struct r600_bytecode_tex));
 			tex.op = (i == 1) ? FETCH_OP_SET_GRADIENTS_H :
 				FETCH_OP_SET_GRADIENTS_V;
 			tex.sampler_id = tgsi_tex_get_src_gpr(ctx, sampler_src_reg);
+			tex.sampler_index_mode = sampler_index_mode;
 			tex.resource_id = tex.sampler_id + R600_MAX_CONST_BUFFERS;
+			tex.resource_index_mode = sampler_index_mode;
 
 			if (tgsi_tex_src_requires_loading(ctx, i)) {
 				tex.src_gpr = r600_get_temp(ctx);
@@ -4963,6 +5209,10 @@ static int tgsi_tex(struct r600_shader_ctx *ctx)
 		src_gpr = ctx->temp_reg;
 	}
 
+	sampler_index_mode = inst->Src[sampler_src_reg].Indirect.Index == 2 ? 2 : 0; // CF_INDEX_1 : CF_INDEX_NONE
+	if (sampler_index_mode)
+		ctx->shader->uses_index_registers = true;
+
 	if ((inst->Texture.Texture == TGSI_TEXTURE_CUBE ||
 	     inst->Texture.Texture == TGSI_TEXTURE_CUBE_ARRAY ||
 	     inst->Texture.Texture == TGSI_TEXTURE_SHADOWCUBE ||
@@ -5291,7 +5541,9 @@ static int tgsi_tex(struct r600_shader_ctx *ctx)
 		tex.op = FETCH_OP_LD;
 		tex.inst_mod = 1; /* to indicate this is ldfptr */
 		tex.sampler_id = tgsi_tex_get_src_gpr(ctx, sampler_src_reg);
+		tex.sampler_index_mode = sampler_index_mode;
 		tex.resource_id = tex.sampler_id + R600_MAX_CONST_BUFFERS;
+		tex.resource_index_mode = sampler_index_mode;
 		tex.src_gpr = src_gpr;
 		tex.dst_gpr = temp;
 		tex.dst_sel_x = 7; /* mask out these components */
@@ -5422,7 +5674,9 @@ static int tgsi_tex(struct r600_shader_ctx *ctx)
 		memset(&tex, 0, sizeof(struct r600_bytecode_tex));
 		tex.op = FETCH_OP_SET_TEXTURE_OFFSETS;
 		tex.sampler_id = tgsi_tex_get_src_gpr(ctx, sampler_src_reg);
+		tex.sampler_index_mode = sampler_index_mode;
 		tex.resource_id = tex.sampler_id + R600_MAX_CONST_BUFFERS;
+		tex.resource_index_mode = sampler_index_mode;
 
 		tex.src_gpr = ctx->file_offset[inst->TexOffsets[0].File] + inst->TexOffsets[0].Index;
 		tex.src_sel_x = inst->TexOffsets[0].SwizzleX;
@@ -5474,7 +5728,9 @@ static int tgsi_tex(struct r600_shader_ctx *ctx)
 	tex.op = opcode;
 
 	tex.sampler_id = tgsi_tex_get_src_gpr(ctx, sampler_src_reg);
+	tex.sampler_index_mode = sampler_index_mode;
 	tex.resource_id = tex.sampler_id + R600_MAX_CONST_BUFFERS;
+	tex.resource_index_mode = sampler_index_mode;
 	tex.src_gpr = src_gpr;
 	tex.dst_gpr = ctx->file_offset[inst->Dst[0].Register.File] + inst->Dst[0].Register.Index;
 
@@ -6237,7 +6493,9 @@ static int tgsi_eg_arl(struct r600_shader_ctx *ctx)
 	struct r600_bytecode_alu alu;
 	int r;
 	int i, lasti = tgsi_last_instruction(inst->Dst[0].Register.WriteMask);
+	unsigned reg = inst->Dst[0].Register.Index > 0 ? ctx->bc->index_reg[inst->Dst[0].Register.Index - 1] : ctx->bc->ar_reg;
 
+	assert(inst->Dst[0].Register.Index < 3);
 	memset(&alu, 0, sizeof(struct r600_bytecode_alu));
 
 	switch (inst->Instruction.Opcode) {
@@ -6260,7 +6518,7 @@ static int tgsi_eg_arl(struct r600_shader_ctx *ctx)
 			continue;
 		r600_bytecode_src(&alu.src[0], &ctx->src[0], i);
 		alu.last = i == lasti;
-		alu.dst.sel = ctx->bc->ar_reg;
+		alu.dst.sel = reg;
 	        alu.dst.chan = i;
 		alu.dst.write = 1;
 		r = r600_bytecode_add_alu(ctx->bc, &alu);
@@ -6268,7 +6526,11 @@ static int tgsi_eg_arl(struct r600_shader_ctx *ctx)
 			return r;
 	}
 
-	ctx->bc->ar_loaded = 0;
+	if (inst->Dst[0].Register.Index > 0)
+		ctx->bc->index_loaded[inst->Dst[0].Register.Index - 1] = 0;
+	else
+		ctx->bc->ar_loaded = 0;
+
 	return 0;
 }
 static int tgsi_r600_arl(struct r600_shader_ctx *ctx)
@@ -7070,6 +7332,9 @@ static struct r600_shader_tgsi_instruction r600_shader_tgsi_instruction[] = {
 	{TGSI_OPCODE_LSB,	0, ALU_OP1_FFBL_INT, tgsi_unsupported},
 	{TGSI_OPCODE_IMSB,	0, ALU_OP1_FFBH_INT, tgsi_unsupported},
 	{TGSI_OPCODE_UMSB,	0, ALU_OP1_FFBH_UINT, tgsi_unsupported},
+	{TGSI_OPCODE_INTERP_CENTROID,	0, ALU_OP0_NOP, tgsi_unsupported},
+	{TGSI_OPCODE_INTERP_SAMPLE,		0, ALU_OP0_NOP, tgsi_unsupported},
+	{TGSI_OPCODE_INTERP_OFFSET,		0, ALU_OP0_NOP, tgsi_unsupported},
 	{TGSI_OPCODE_LAST,	0, ALU_OP0_NOP, tgsi_unsupported},
 };
 
@@ -7272,6 +7537,9 @@ static struct r600_shader_tgsi_instruction eg_shader_tgsi_instruction[] = {
 	{TGSI_OPCODE_LSB,	0, ALU_OP1_FFBL_INT, tgsi_op2},
 	{TGSI_OPCODE_IMSB,	0, ALU_OP1_FFBH_INT, tgsi_msb},
 	{TGSI_OPCODE_UMSB,	0, ALU_OP1_FFBH_UINT, tgsi_msb},
+	{TGSI_OPCODE_INTERP_CENTROID,	0, ALU_OP0_NOP, tgsi_interp_egcm},
+	{TGSI_OPCODE_INTERP_SAMPLE,		0, ALU_OP0_NOP, tgsi_interp_egcm},
+	{TGSI_OPCODE_INTERP_OFFSET,		0, ALU_OP0_NOP, tgsi_interp_egcm},
 	{TGSI_OPCODE_LAST,	0, ALU_OP0_NOP, tgsi_unsupported},
 };
 
@@ -7475,5 +7743,8 @@ static struct r600_shader_tgsi_instruction cm_shader_tgsi_instruction[] = {
 	{TGSI_OPCODE_LSB,	0, ALU_OP1_FFBL_INT, tgsi_op2},
 	{TGSI_OPCODE_IMSB,	0, ALU_OP1_FFBH_INT, tgsi_msb},
 	{TGSI_OPCODE_UMSB,	0, ALU_OP1_FFBH_UINT, tgsi_msb},
+	{TGSI_OPCODE_INTERP_CENTROID,	0, ALU_OP0_NOP, tgsi_interp_egcm},
+	{TGSI_OPCODE_INTERP_SAMPLE,		0, ALU_OP0_NOP, tgsi_interp_egcm},
+	{TGSI_OPCODE_INTERP_OFFSET,		0, ALU_OP0_NOP, tgsi_interp_egcm},
 	{TGSI_OPCODE_LAST,	0, ALU_OP0_NOP, tgsi_unsupported},
 };
diff --git a/src/gallium/drivers/r600/r600_shader.h b/src/gallium/drivers/r600/r600_shader.h
index 20829fd..ab67013 100644
--- a/src/gallium/drivers/r600/r600_shader.h
+++ b/src/gallium/drivers/r600/r600_shader.h
@@ -69,6 +69,8 @@ struct r600_shader {
 	boolean			has_txq_cube_array_z_comp;
 	boolean			uses_tex_buffers;
 	boolean                 gs_prim_id_input;
+	/* Temporarily workaround SB not handling CF_INDEX_[01] index registers */
+	boolean			uses_index_registers;
 
 	/* geometry shader properties */
 	unsigned		gs_input_prim;
diff --git a/src/gallium/drivers/r600/r600_state.c b/src/gallium/drivers/r600/r600_state.c
index 8dc25da..61f5c5a 100644
--- a/src/gallium/drivers/r600/r600_state.c
+++ b/src/gallium/drivers/r600/r600_state.c
@@ -536,9 +536,9 @@ static void *r600_create_rs_state(struct pipe_context *ctx,
 				 S_028814_CULL_FRONT(state->cull_face & PIPE_FACE_FRONT ? 1 : 0) |
 				 S_028814_CULL_BACK(state->cull_face & PIPE_FACE_BACK ? 1 : 0) |
 				 S_028814_FACE(!state->front_ccw) |
-				 S_028814_POLY_OFFSET_FRONT_ENABLE(state->offset_tri) |
-				 S_028814_POLY_OFFSET_BACK_ENABLE(state->offset_tri) |
-				 S_028814_POLY_OFFSET_PARA_ENABLE(state->offset_tri) |
+				 S_028814_POLY_OFFSET_FRONT_ENABLE(util_get_offset(state, state->fill_front)) |
+				 S_028814_POLY_OFFSET_BACK_ENABLE(util_get_offset(state, state->fill_back)) |
+				 S_028814_POLY_OFFSET_PARA_ENABLE(state->offset_point || state->offset_line) |
 				 S_028814_POLY_MODE(state->fill_front != PIPE_POLYGON_MODE_FILL ||
 									 state->fill_back != PIPE_POLYGON_MODE_FILL) |
 				 S_028814_POLYMODE_FRONT_PTYPE(r600_translate_fill(state->fill_front)) |
diff --git a/src/gallium/drivers/r600/r600_state_common.c b/src/gallium/drivers/r600/r600_state_common.c
index 879ec35..c3f21cb 100644
--- a/src/gallium/drivers/r600/r600_state_common.c
+++ b/src/gallium/drivers/r600/r600_state_common.c
@@ -1103,6 +1103,9 @@ void r600_set_sample_locations_constant_buffer(struct r600_context *rctx)
 	assert(rctx->framebuffer.nr_samples <= Elements(values)/4);
 	for (i = 0; i < rctx->framebuffer.nr_samples; i++) {
 		ctx->get_sample_position(ctx, rctx->framebuffer.nr_samples, i, &values[4*i]);
+		/* Also fill in center-zeroed positions used for interpolateAtSample */
+		values[4*i + 2] = values[4*i + 0] - 0.5f;
+		values[4*i + 3] = values[4*i + 1] - 0.5f;
 	}
 
 	constbuf.user_buffer = values;
diff --git a/src/gallium/drivers/r600/sb/sb_bc_dump.cpp b/src/gallium/drivers/r600/sb/sb_bc_dump.cpp
index 1551e6d..6f6a57e 100644
--- a/src/gallium/drivers/r600/sb/sb_bc_dump.cpp
+++ b/src/gallium/drivers/r600/sb/sb_bc_dump.cpp
@@ -165,13 +165,14 @@ void bc_dump::dump(cf_node& n) {
 		s << " @" << (n.bc.addr << 1);
 
 		if (n.bc.op_ptr->flags & CF_ALU) {
+			static const char *index_mode[] = {"", " CF_INDEX_0", " CF_INDEX_1"};
 
 			for (int k = 0; k < 4; ++k) {
 				bc_kcache &kc = n.bc.kc[k];
 				if (kc.mode) {
 					s << " KC" << k << "[CB" << kc.bank << ":" <<
 							(kc.addr << 4) << "-" <<
-							(((kc.addr + kc.mode) << 4) - 1) << "]";
+							(((kc.addr + kc.mode) << 4) - 1) << index_mode[kc.index_mode] << "]";
 				}
 			}
 		}
@@ -445,6 +446,11 @@ void bc_dump::dump(fetch_node& n) {
 			s << " MFC:" << n.bc.mega_fetch_count;
 		if (n.bc.fetch_whole_quad)
 			s << " FWQ";
+		if (ctx.is_egcm() && n.bc.resource_index_mode)
+			s << " RIM:SQ_CF_INDEX_" << n.bc.resource_index_mode;
+		if (ctx.is_egcm() && n.bc.resource_index_mode)
+			s << " SID:SQ_CF_INDEX_" << n.bc.sampler_index_mode;
+
 		s << " UCF:" << n.bc.use_const_fields
 				<< " FMT(DTA:" << n.bc.data_format
 				<< " NUM:" << n.bc.num_format_all
diff --git a/src/gallium/drivers/r600/sb/sb_sched.h b/src/gallium/drivers/r600/sb/sb_sched.h
index a74484f..87c4586 100644
--- a/src/gallium/drivers/r600/sb/sb_sched.h
+++ b/src/gallium/drivers/r600/sb/sb_sched.h
@@ -32,6 +32,8 @@ namespace r600_sb {
 typedef sb_map<node*, unsigned> uc_map;
 
 // resource trackers for scheduler
+// rp = read port
+// uc = use count
 
 typedef sb_set<unsigned> kc_lines;
 
diff --git a/src/gallium/drivers/radeon/r600_pipe_common.c b/src/gallium/drivers/radeon/r600_pipe_common.c
index a6dbd78..f9393e6 100644
--- a/src/gallium/drivers/radeon/r600_pipe_common.c
+++ b/src/gallium/drivers/radeon/r600_pipe_common.c
@@ -590,7 +590,6 @@ static int r600_get_compute_param(struct pipe_screen *screen,
 
 	case PIPE_COMPUTE_CAP_MAX_MEM_ALLOC_SIZE:
 		if (ret) {
-			uint64_t max_global_size;
 			uint64_t *max_mem_alloc_size = ret;
 
 			/* XXX: The limit in older kernels is 256 MB.  We
diff --git a/src/gallium/drivers/radeon/r600_pipe_common.h b/src/gallium/drivers/radeon/r600_pipe_common.h
index dfd8fff..a699f45 100644
--- a/src/gallium/drivers/radeon/r600_pipe_common.h
+++ b/src/gallium/drivers/radeon/r600_pipe_common.h
@@ -120,11 +120,19 @@ struct radeon_shader_binary {
 	unsigned char *config;
 	unsigned config_size;
 
+	/** The number of bytes of config information for each global symbol.
+	 */
+	unsigned config_size_per_symbol;
+
 	/** Constant data accessed by the shader.  This will be uploaded
 	 * into a constant buffer. */
 	unsigned char *rodata;
 	unsigned rodata_size;
 
+	/** List of symbol offsets for the shader */
+	uint64_t *global_symbol_offsets;
+	unsigned global_symbol_count;
+
 	/** Set to 1 if the disassembly for this binary has been dumped to
 	 *  stderr. */
 	int disassembled;
diff --git a/src/gallium/drivers/radeon/radeon_elf_util.c b/src/gallium/drivers/radeon/radeon_elf_util.c
index 7c5f93e..ec39a89 100644
--- a/src/gallium/drivers/radeon/radeon_elf_util.c
+++ b/src/gallium/drivers/radeon/radeon_elf_util.c
@@ -33,6 +33,48 @@
 #include <libelf.h>
 #include <stdio.h>
 
+static void parse_symbol_table(Elf_Data *symbol_table_data,
+				const GElf_Shdr *symbol_table_header,
+				struct radeon_shader_binary *binary)
+{
+	GElf_Sym symbol;
+	unsigned i = 0;
+	unsigned symbol_count =
+		symbol_table_header->sh_size / symbol_table_header->sh_entsize;
+
+	/* We are over allocating this list, because symbol_count gives the
+ 	 * total number of symbols, and we will only be filling the list
+ 	 * with offsets of global symbols.  The memory savings from
+ 	 * allocating the correct size of this list will be small, and
+ 	 * I don't think it is worth the cost of pre-computing the number
+ 	 * of global symbols.
+ 	 */
+	binary->global_symbol_offsets = CALLOC(symbol_count, sizeof(uint64_t));
+
+	while (gelf_getsym(symbol_table_data, i++, &symbol)) {
+		unsigned i;
+		if (GELF_ST_BIND(symbol.st_info) != STB_GLOBAL) {
+			continue;
+		}
+
+		binary->global_symbol_offsets[binary->global_symbol_count] =
+					symbol.st_value;
+
+		/* Sort the list using bubble sort.  This list will usually
+		 * be small. */
+		for (i = binary->global_symbol_count; i > 0; --i) {
+			uint64_t lhs = binary->global_symbol_offsets[i - 1];
+			uint64_t rhs = binary->global_symbol_offsets[i];
+			if (lhs < rhs) {
+				break;
+			}
+			binary->global_symbol_offsets[i] = lhs;
+			binary->global_symbol_offsets[i - 1] = rhs;
+		}
+		++binary->global_symbol_count;
+	}
+}
+
 void radeon_elf_read(const char *elf_data, unsigned elf_size,
 					struct radeon_shader_binary *binary,
 					unsigned debug)
@@ -85,6 +127,9 @@ void radeon_elf_read(const char *elf_data, unsigned elf_size,
 			binary->rodata_size = section_data->d_size;
 			binary->rodata = MALLOC(binary->rodata_size * sizeof(unsigned char));
 			memcpy(binary->rodata, section_data->d_buf, binary->rodata_size);
+		} else if (!strncmp(name, ".symtab", 7)) {
+			section_data = elf_getdata(section, section_data);
+			parse_symbol_table(section_data, &section_header, binary);
 		}
 	}
 
@@ -92,4 +137,27 @@ void radeon_elf_read(const char *elf_data, unsigned elf_size,
 		elf_end(elf);
 	}
 	FREE(elf_buffer);
+
+	/* Cache the config size per symbol */
+	if (binary->global_symbol_count) {
+		binary->config_size_per_symbol =
+			binary->config_size / binary->global_symbol_count;
+	} else {
+		binary->global_symbol_count = 1;
+		binary->config_size_per_symbol = binary->config_size;
+	}
+}
+
+const unsigned char *radeon_shader_binary_config_start(
+	const struct radeon_shader_binary *binary,
+	uint64_t symbol_offset)
+{
+	unsigned i;
+	for (i = 0; i < binary->global_symbol_count; ++i) {
+		if (binary->global_symbol_offsets[i] == symbol_offset) {
+			unsigned offset = i * binary->config_size_per_symbol;
+			return binary->config + offset;
+		}
+	}
+	return binary->config;
 }
diff --git a/src/gallium/drivers/radeon/radeon_elf_util.h b/src/gallium/drivers/radeon/radeon_elf_util.h
index 60dae42..8095e2f 100644
--- a/src/gallium/drivers/radeon/radeon_elf_util.h
+++ b/src/gallium/drivers/radeon/radeon_elf_util.h
@@ -27,6 +27,8 @@
 #ifndef RADEON_ELF_UTIL_H
 #define RADEON_ELF_UTIL_H
 
+#include <stdint.h>
+
 struct radeon_shader_binary;
 
 /*
@@ -36,4 +38,12 @@ struct radeon_shader_binary;
 void radeon_elf_read(const char *elf_data, unsigned elf_size,
 		struct radeon_shader_binary *binary, unsigned debug);
 
+/**
+ * @returns A pointer to the start of the configuration information for
+ * the function starting at \p symbol_offset of the binary.
+ */
+const unsigned char *radeon_shader_binary_config_start(
+	const struct radeon_shader_binary *binary,
+	uint64_t symbol_offset);
+
 #endif /* RADEON_ELF_UTIL_H */
diff --git a/src/gallium/drivers/radeon/radeon_llvm.h b/src/gallium/drivers/radeon/radeon_llvm.h
index 00714fb..8612ef8 100644
--- a/src/gallium/drivers/radeon/radeon_llvm.h
+++ b/src/gallium/drivers/radeon/radeon_llvm.h
@@ -33,10 +33,10 @@
 
 #define RADEON_LLVM_MAX_INPUTS 32 * 4
 #define RADEON_LLVM_MAX_OUTPUTS 32 * 4
-#define RADEON_LLVM_MAX_BRANCH_DEPTH 16
-#define RADEON_LLVM_MAX_LOOP_DEPTH 16
 #define RADEON_LLVM_MAX_ARRAYS 16
 
+#define RADEON_LLVM_INITIAL_CF_DEPTH 4
+
 #define RADEON_LLVM_MAX_SYSTEM_VALUES 4
 
 struct radeon_llvm_branch {
@@ -122,11 +122,13 @@ struct radeon_llvm_context {
 
 	/*=== Private Members ===*/
 
-	struct radeon_llvm_branch branch[RADEON_LLVM_MAX_BRANCH_DEPTH];
-	struct radeon_llvm_loop loop[RADEON_LLVM_MAX_LOOP_DEPTH];
+	struct radeon_llvm_branch *branch;
+	struct radeon_llvm_loop *loop;
 
 	unsigned branch_depth;
+	unsigned branch_depth_max;
 	unsigned loop_depth;
+	unsigned loop_depth_max;
 
 	struct tgsi_declaration_range arrays[RADEON_LLVM_MAX_ARRAYS];
 	unsigned num_arrays;
diff --git a/src/gallium/drivers/radeon/radeon_llvm_util.c b/src/gallium/drivers/radeon/radeon_llvm_util.c
index ec11559..0dfd9ad 100644
--- a/src/gallium/drivers/radeon/radeon_llvm_util.c
+++ b/src/gallium/drivers/radeon/radeon_llvm_util.c
@@ -34,7 +34,7 @@
 #include <llvm-c/Transforms/PassManagerBuilder.h>
 
 LLVMModuleRef radeon_llvm_parse_bitcode(LLVMContextRef ctx,
-							const unsigned char * bitcode, unsigned bitcode_len)
+							const char * bitcode, unsigned bitcode_len)
 {
 	LLVMMemoryBufferRef buf;
 	LLVMModuleRef module;
@@ -47,7 +47,7 @@ LLVMModuleRef radeon_llvm_parse_bitcode(LLVMContextRef ctx,
 }
 
 unsigned radeon_llvm_get_num_kernels(LLVMContextRef ctx,
-				const unsigned char *bitcode, unsigned bitcode_len)
+				const char *bitcode, unsigned bitcode_len)
 {
 	LLVMModuleRef mod = radeon_llvm_parse_bitcode(ctx, bitcode, bitcode_len);
 	return LLVMGetNamedMetadataNumOperands(mod, "opencl.kernels");
@@ -88,7 +88,7 @@ static void radeon_llvm_optimize(LLVMModuleRef mod)
 }
 
 LLVMModuleRef radeon_llvm_get_kernel_module(LLVMContextRef ctx, unsigned index,
-		const unsigned char *bitcode, unsigned bitcode_len)
+		const char *bitcode, unsigned bitcode_len)
 {
 	LLVMModuleRef mod;
 	unsigned num_kernels;
diff --git a/src/gallium/drivers/radeon/radeon_llvm_util.h b/src/gallium/drivers/radeon/radeon_llvm_util.h
index 733c329..cc1932a 100644
--- a/src/gallium/drivers/radeon/radeon_llvm_util.h
+++ b/src/gallium/drivers/radeon/radeon_llvm_util.h
@@ -30,10 +30,10 @@
 #include <llvm-c/Core.h>
 
 LLVMModuleRef radeon_llvm_parse_bitcode(LLVMContextRef ctx,
-			const unsigned char * bitcode, unsigned bitcode_len);
+			const char * bitcode, unsigned bitcode_len);
 unsigned radeon_llvm_get_num_kernels(LLVMContextRef ctx,
-			const unsigned char *bitcode, unsigned bitcode_len);
+			const char *bitcode, unsigned bitcode_len);
 LLVMModuleRef radeon_llvm_get_kernel_module(LLVMContextRef ctx, unsigned index,
-			const unsigned char *bitcode, unsigned bitcode_len);
+			const char *bitcode, unsigned bitcode_len);
 
 #endif
diff --git a/src/gallium/drivers/radeon/radeon_setup_tgsi_llvm.c b/src/gallium/drivers/radeon/radeon_setup_tgsi_llvm.c
index 2fa23ed..c30a9d0 100644
--- a/src/gallium/drivers/radeon/radeon_setup_tgsi_llvm.c
+++ b/src/gallium/drivers/radeon/radeon_setup_tgsi_llvm.c
@@ -446,7 +446,19 @@ static void bgnloop_emit(
 						endloop_block, "LOOP");
 	LLVMBuildBr(gallivm->builder, loop_block);
 	LLVMPositionBuilderAtEnd(gallivm->builder, loop_block);
-	ctx->loop_depth++;
+
+	if (++ctx->loop_depth > ctx->loop_depth_max) {
+		unsigned new_max = ctx->loop_depth_max << 1;
+
+		if (!new_max)
+			new_max = RADEON_LLVM_INITIAL_CF_DEPTH;
+
+		ctx->loop = REALLOC(ctx->loop, ctx->loop_depth_max *
+				    sizeof(ctx->loop[0]),
+				    new_max * sizeof(ctx->loop[0]));
+		ctx->loop_depth_max = new_max;
+	}
+
 	ctx->loop[ctx->loop_depth - 1].loop_block = loop_block;
 	ctx->loop[ctx->loop_depth - 1].endloop_block = endloop_block;
 }
@@ -577,7 +589,18 @@ static void if_cond_emit(
 	LLVMBuildCondBr(gallivm->builder, cond, if_block, else_block);
 	LLVMPositionBuilderAtEnd(gallivm->builder, if_block);
 
-	ctx->branch_depth++;
+	if (++ctx->branch_depth > ctx->branch_depth_max) {
+		unsigned new_max = ctx->branch_depth_max << 1;
+
+		if (!new_max)
+			new_max = RADEON_LLVM_INITIAL_CF_DEPTH;
+
+		ctx->branch = REALLOC(ctx->branch, ctx->branch_depth_max *
+				      sizeof(ctx->branch[0]),
+				      new_max * sizeof(ctx->branch[0]));
+		ctx->branch_depth_max = new_max;
+	}
+
 	ctx->branch[ctx->branch_depth - 1].endif_block = endif_block;
 	ctx->branch[ctx->branch_depth - 1].if_block = if_block;
 	ctx->branch[ctx->branch_depth - 1].else_block = else_block;
@@ -1440,4 +1463,10 @@ void radeon_llvm_dispose(struct radeon_llvm_context * ctx)
 	LLVMContextDispose(ctx->soa.bld_base.base.gallivm->context);
 	FREE(ctx->temps);
 	ctx->temps = NULL;
+	FREE(ctx->loop);
+	ctx->loop = NULL;
+	ctx->loop_depth_max = 0;
+	FREE(ctx->branch);
+	ctx->branch = NULL;
+	ctx->branch_depth_max = 0;
 }
diff --git a/src/gallium/drivers/radeonsi/si_compute.c b/src/gallium/drivers/radeonsi/si_compute.c
index be64418..6ddb478 100644
--- a/src/gallium/drivers/radeonsi/si_compute.c
+++ b/src/gallium/drivers/radeonsi/si_compute.c
@@ -23,14 +23,15 @@
  */
 
 #include "util/u_memory.h"
+#include "radeon/r600_pipe_common.h"
+#include "radeon/radeon_elf_util.h"
+#include "radeon/radeon_llvm_util.h"
 
 #include "radeon/r600_cs.h"
 #include "si_pipe.h"
 #include "si_shader.h"
 #include "sid.h"
 
-#include "radeon/radeon_llvm_util.h"
-
 #define MAX_GLOBAL_BUFFERS 20
 #if HAVE_LLVM < 0x0305
 #define NUM_USER_SGPRS 2
@@ -44,14 +45,18 @@ struct si_compute {
 	unsigned local_size;
 	unsigned private_size;
 	unsigned input_size;
-	unsigned num_kernels;
-	struct si_shader *kernels;
+	struct radeon_shader_binary binary;
+	struct si_shader program;
 	unsigned num_user_sgprs;
 
 	struct r600_resource *input_buffer;
 	struct pipe_resource *global_buffers[MAX_GLOBAL_BUFFERS];
 
+#if HAVE_LLVM < 0x0306
+	unsigned num_kernels;
+	struct si_shader *kernels;
 	LLVMContextRef llvm_ctx;
+#endif
 };
 
 static void *si_create_compute_state(
@@ -61,10 +66,7 @@ static void *si_create_compute_state(
 	struct si_context *sctx = (struct si_context *)ctx;
 	struct si_compute *program = CALLOC_STRUCT(si_compute);
 	const struct pipe_llvm_program_header *header;
-	const unsigned char *code;
-	unsigned i;
-
-	program->llvm_ctx = LLVMContextCreate();
+	const char *code;
 
 	header = cso->prog;
 	code = cso->prog + sizeof(struct pipe_llvm_program_header);
@@ -74,17 +76,27 @@ static void *si_create_compute_state(
 	program->private_size = cso->req_private_mem;
 	program->input_size = cso->req_input_mem;
 
-	program->num_kernels = radeon_llvm_get_num_kernels(program->llvm_ctx, code,
-							header->num_bytes);
-	program->kernels = CALLOC(sizeof(struct si_shader),
-							program->num_kernels);
-	for (i = 0; i < program->num_kernels; i++) {
-		LLVMModuleRef mod = radeon_llvm_get_kernel_module(program->llvm_ctx, i,
-							code, header->num_bytes);
-		si_compile_llvm(sctx->screen, &program->kernels[i], mod);
-		LLVMDisposeModule(mod);
+#if HAVE_LLVM < 0x0306
+	{
+		unsigned i;
+		program->llvm_ctx = LLVMContextCreate();
+	        program->num_kernels = radeon_llvm_get_num_kernels(program->llvm_ctx,
+					code, header->num_bytes);
+	        program->kernels = CALLOC(sizeof(struct si_shader),
+                                                        program->num_kernels);
+	        for (i = 0; i < program->num_kernels; i++) {
+		        LLVMModuleRef mod = radeon_llvm_get_kernel_module(program->llvm_ctx, i,
+                                                        code, header->num_bytes);
+			si_compile_llvm(sctx->screen, &program->kernels[i], mod);
+			LLVMDisposeModule(mod);
+		}
 	}
+#else
 
+	radeon_elf_read(code, header->num_bytes, &program->binary, true);
+	si_shader_binary_read(sctx->screen, &program->program, &program->binary);
+
+#endif
 	program->input_buffer =	si_resource_create_custom(sctx->b.b.screen,
 		PIPE_USAGE_IMMUTABLE, program->input_size);
 
@@ -181,10 +193,15 @@ static void si_launch_grid(
 	uint64_t shader_va;
 	unsigned arg_user_sgpr_count = NUM_USER_SGPRS;
 	unsigned i;
-	struct si_shader *shader = &program->kernels[pc];
+	struct si_shader *shader = &program->program;
 	unsigned lds_blocks;
 	unsigned num_waves_for_scratch;
 
+#if HAVE_LLVM < 0x0306
+	shader = &program->kernels[pc];
+#endif
+
+
 	radeon_emit(cs, PKT3(PKT3_CONTEXT_CONTROL, 1, 0) | PKT3_SHADER_TYPE_S(1));
 	radeon_emit(cs, 0x80000000);
 	radeon_emit(cs, 0x80000000);
@@ -198,6 +215,11 @@ static void si_launch_grid(
 
 	pm4->compute_pkt = true;
 
+#if HAVE_LLVM >= 0x0306
+	/* Read the config information */
+	si_shader_binary_read_config(&program->binary, &program->program, pc);
+#endif
+
 	/* Upload the kernel arguments */
 
 	/* The extra num_work_size_bytes are for work group / work item size information */
@@ -290,6 +312,10 @@ static void si_launch_grid(
 	}
 
 	shader_va = shader->bo->gpu_address;
+
+#if HAVE_LLVM >= 0x0306
+	shader_va += pc;
+#endif
 	si_pm4_add_bo(pm4, shader->bo, RADEON_USAGE_READ, RADEON_PRIO_SHADER_DATA);
 	si_pm4_set_reg(pm4, R_00B830_COMPUTE_PGM_LO, (shader_va >> 8) & 0xffffffff);
 	si_pm4_set_reg(pm4, R_00B834_COMPUTE_PGM_HI, shader_va >> 40);
@@ -388,6 +414,7 @@ static void si_delete_compute_state(struct pipe_context *ctx, void* state){
 		return;
 	}
 
+#if HAVE_LLVM < 0x0306
 	if (program->kernels) {
 		for (int i = 0; i < program->num_kernels; i++){
 			if (program->kernels[i].bo){
@@ -400,10 +427,16 @@ static void si_delete_compute_state(struct pipe_context *ctx, void* state){
 	if (program->llvm_ctx){
 		LLVMContextDispose(program->llvm_ctx);
 	}
+#else
+	si_shader_destroy(ctx, &program->program);
+#endif
+
 	pipe_resource_reference(
 		(struct pipe_resource **)&program->input_buffer, NULL);
 
-	//And then free the program itself.
+	FREE(program->binary.code);
+	FREE(program->binary.config);
+	FREE(program->binary.rodata);
 	FREE(program);
 }
 
diff --git a/src/gallium/drivers/radeonsi/si_pipe.c b/src/gallium/drivers/radeonsi/si_pipe.c
index 0577cd2..53c83ba 100644
--- a/src/gallium/drivers/radeonsi/si_pipe.c
+++ b/src/gallium/drivers/radeonsi/si_pipe.c
@@ -336,7 +336,11 @@ static int si_get_shader_param(struct pipe_screen* pscreen, unsigned shader, enu
 	case PIPE_SHADER_COMPUTE:
 		switch (param) {
 		case PIPE_SHADER_CAP_PREFERRED_IR:
+#if HAVE_LLVM < 0x0306
 			return PIPE_SHADER_IR_LLVM;
+#else
+			return PIPE_SHADER_IR_NATIVE;
+#endif
 		case PIPE_SHADER_CAP_DOUBLES:
 			return 0; /* XXX: Enable doubles once the compiler can
 			             handle them. */
diff --git a/src/gallium/drivers/radeonsi/si_shader.c b/src/gallium/drivers/radeonsi/si_shader.c
index f8e9fbe..40a2f90 100644
--- a/src/gallium/drivers/radeonsi/si_shader.c
+++ b/src/gallium/drivers/radeonsi/si_shader.c
@@ -33,6 +33,7 @@
 #include "gallivm/lp_bld_arit.h"
 #include "gallivm/lp_bld_flow.h"
 #include "radeon/radeon_llvm.h"
+#include "radeon/radeon_elf_util.h"
 #include "radeon/radeon_llvm_emit.h"
 #include "util/u_memory.h"
 #include "tgsi/tgsi_parse.h"
@@ -2500,52 +2501,34 @@ static void preload_ring_buffers(struct si_shader_context *si_shader_ctx)
 	}
 }
 
-int si_compile_llvm(struct si_screen *sscreen, struct si_shader *shader,
-		    LLVMModuleRef mod)
+void si_shader_binary_read_config(const struct radeon_shader_binary *binary,
+				struct si_shader *shader,
+				unsigned symbol_offset)
 {
-	unsigned r; /* llvm_compile result */
 	unsigned i;
-	unsigned char *ptr;
-	struct radeon_shader_binary binary;
-	bool dump = r600_can_dump_shader(&sscreen->b,
-			shader->selector ? shader->selector->tokens : NULL);
-	const char * gpu_family = r600_get_llvm_processor_name(sscreen->b.family);
-	unsigned code_size;
-
-	/* Use LLVM to compile shader */
-	memset(&binary, 0, sizeof(binary));
-	r = radeon_llvm_compile(mod, &binary, gpu_family, dump);
-
-	/* Output binary dump if rscreen->debug_flags are set */
-	if (dump && ! binary.disassembled) {
-		fprintf(stderr, "SI CODE:\n");
-		for (i = 0; i < binary.code_size; i+=4 ) {
-			fprintf(stderr, "%02x%02x%02x%02x\n", binary.code[i + 3],
-				binary.code[i + 2], binary.code[i + 1],
-				binary.code[i]);
-		}
-	}
+	const unsigned char *config =
+		radeon_shader_binary_config_start(binary, symbol_offset);
 
 	/* XXX: We may be able to emit some of these values directly rather than
 	 * extracting fields to be emitted later.
 	 */
-	/* Parse config data in compiled binary */
-	for (i = 0; i < binary.config_size; i+= 8) {
-		unsigned reg = util_le32_to_cpu(*(uint32_t*)(binary.config + i));
-		unsigned value = util_le32_to_cpu(*(uint32_t*)(binary.config + i + 4));
+
+	for (i = 0; i < binary->config_size_per_symbol; i+= 8) {
+		unsigned reg = util_le32_to_cpu(*(uint32_t*)(config + i));
+		unsigned value = util_le32_to_cpu(*(uint32_t*)(config + i + 4));
 		switch (reg) {
 		case R_00B028_SPI_SHADER_PGM_RSRC1_PS:
 		case R_00B128_SPI_SHADER_PGM_RSRC1_VS:
 		case R_00B228_SPI_SHADER_PGM_RSRC1_GS:
 		case R_00B848_COMPUTE_PGM_RSRC1:
-			shader->num_sgprs = (G_00B028_SGPRS(value) + 1) * 8;
-			shader->num_vgprs = (G_00B028_VGPRS(value) + 1) * 4;
+			shader->num_sgprs = MAX2(shader->num_sgprs, (G_00B028_SGPRS(value) + 1) * 8);
+			shader->num_vgprs = MAX2(shader->num_vgprs, (G_00B028_VGPRS(value) + 1) * 4);
 			break;
 		case R_00B02C_SPI_SHADER_PGM_RSRC2_PS:
-			shader->lds_size = G_00B02C_EXTRA_LDS_SIZE(value);
+			shader->lds_size = MAX2(shader->lds_size, G_00B02C_EXTRA_LDS_SIZE(value));
 			break;
 		case R_00B84C_COMPUTE_PGM_RSRC2:
-			shader->lds_size = G_00B84C_LDS_SIZE(value);
+			shader->lds_size = MAX2(shader->lds_size, G_00B84C_LDS_SIZE(value));
 			break;
 		case R_0286CC_SPI_PS_INPUT_ENA:
 			shader->spi_ps_input_ena = value;
@@ -2561,9 +2544,32 @@ int si_compile_llvm(struct si_screen *sscreen, struct si_shader *shader,
 			break;
 		}
 	}
+}
+
+int si_shader_binary_read(struct si_screen *sscreen,
+			struct si_shader *shader,
+			const struct radeon_shader_binary *binary)
+{
+
+	unsigned i;
+	unsigned code_size;
+	unsigned char *ptr;
+	bool dump  = r600_can_dump_shader(&sscreen->b,
+		shader->selector ? shader->selector->tokens : NULL);
+
+	if (dump && !binary->disassembled) {
+		fprintf(stderr, "SI CODE:\n");
+		for (i = 0; i < binary->code_size; i+=4 ) {
+			fprintf(stderr, "@0x%x: %02x%02x%02x%02x\n", i, binary->code[i + 3],
+				binary->code[i + 2], binary->code[i + 1],
+				binary->code[i]);
+		}
+	}
+
+	si_shader_binary_read_config(binary, shader, 0);
 
 	/* copy new shader */
-	code_size = binary.code_size + binary.rodata_size;
+	code_size = binary->code_size + binary->rodata_size;
 	r600_resource_reference(&shader->bo, NULL);
 	shader->bo = si_resource_create_custom(&sscreen->b.b, PIPE_USAGE_IMMUTABLE,
 					       code_size);
@@ -2571,19 +2577,37 @@ int si_compile_llvm(struct si_screen *sscreen, struct si_shader *shader,
 		return -ENOMEM;
 	}
 
-	ptr = sscreen->b.ws->buffer_map(shader->bo->cs_buf, NULL, PIPE_TRANSFER_WRITE);
-	util_memcpy_cpu_to_le32(ptr, binary.code, binary.code_size);
-	if (binary.rodata_size > 0) {
-		ptr += binary.code_size;
-		util_memcpy_cpu_to_le32(ptr, binary.rodata, binary.rodata_size);
+
+	ptr = sscreen->b.ws->buffer_map(shader->bo->cs_buf, NULL, PIPE_TRANSFER_READ_WRITE);
+	util_memcpy_cpu_to_le32(ptr, binary->code, binary->code_size);
+	if (binary->rodata_size > 0) {
+		ptr += binary->code_size;
+		util_memcpy_cpu_to_le32(ptr, binary->rodata, binary->rodata_size);
 	}
 
 	sscreen->b.ws->buffer_unmap(shader->bo->cs_buf);
 
-	free(binary.code);
-	free(binary.config);
-	free(binary.rodata);
+	return 0;
+}
+
+int si_compile_llvm(struct si_screen *sscreen, struct si_shader *shader,
+							LLVMModuleRef mod)
+{
+	int r = 0;
+	struct radeon_shader_binary binary;
+	bool dump = r600_can_dump_shader(&sscreen->b,
+			shader->selector ? shader->selector->tokens : NULL);
+	memset(&binary, 0, sizeof(binary));
+	r = radeon_llvm_compile(mod, &binary,
+		r600_get_llvm_processor_name(sscreen->b.family), dump);
 
+	if (r) {
+		return r;
+	}
+	r = si_shader_binary_read(sscreen, shader, &binary);
+	FREE(binary.code);
+	FREE(binary.config);
+	FREE(binary.rodata);
 	return r;
 }
 
diff --git a/src/gallium/drivers/radeonsi/si_shader.h b/src/gallium/drivers/radeonsi/si_shader.h
index 30e6854..5e8c9e6 100644
--- a/src/gallium/drivers/radeonsi/si_shader.h
+++ b/src/gallium/drivers/radeonsi/si_shader.h
@@ -33,6 +33,8 @@
 #include "tgsi/tgsi_scan.h"
 #include "si_state.h"
 
+struct radeon_shader_binary;
+
 #define SI_SGPR_RW_BUFFERS	0  /* rings (& stream-out, VS only) */
 #define SI_SGPR_CONST		2
 #define SI_SGPR_SAMPLER		4
@@ -180,5 +182,10 @@ int si_compile_llvm(struct si_screen *sscreen, struct si_shader *shader,
 		    LLVMModuleRef mod);
 void si_shader_destroy(struct pipe_context *ctx, struct si_shader *shader);
 unsigned si_shader_io_get_unique_index(unsigned semantic_name, unsigned index);
+int si_shader_binary_read(struct si_screen *sscreen, struct si_shader *shader,
+		const struct radeon_shader_binary *binary);
+void si_shader_binary_read_config(const struct radeon_shader_binary *binary,
+				struct si_shader *shader,
+				unsigned symbol_offset);
 
 #endif
diff --git a/src/gallium/drivers/radeonsi/si_state.c b/src/gallium/drivers/radeonsi/si_state.c
index 16d8493..030d6e9 100644
--- a/src/gallium/drivers/radeonsi/si_state.c
+++ b/src/gallium/drivers/radeonsi/si_state.c
@@ -599,9 +599,9 @@ static void *si_create_rs_state(struct pipe_context *ctx,
 		S_028814_CULL_FRONT(state->rasterizer_discard || (state->cull_face & PIPE_FACE_FRONT) ? 1 : 0) |
 		S_028814_CULL_BACK(state->rasterizer_discard || (state->cull_face & PIPE_FACE_BACK) ? 1 : 0) |
 		S_028814_FACE(!state->front_ccw) |
-		S_028814_POLY_OFFSET_FRONT_ENABLE(state->offset_tri) |
-		S_028814_POLY_OFFSET_BACK_ENABLE(state->offset_tri) |
-		S_028814_POLY_OFFSET_PARA_ENABLE(state->offset_tri) |
+		S_028814_POLY_OFFSET_FRONT_ENABLE(util_get_offset(state, state->fill_front)) |
+		S_028814_POLY_OFFSET_BACK_ENABLE(util_get_offset(state, state->fill_back)) |
+		S_028814_POLY_OFFSET_PARA_ENABLE(state->offset_point || state->offset_line) |
 		S_028814_POLY_MODE(polygon_dual_mode) |
 		S_028814_POLYMODE_FRONT_PTYPE(si_translate_fill(state->fill_front)) |
 		S_028814_POLYMODE_BACK_PTYPE(si_translate_fill(state->fill_back));
diff --git a/src/gallium/drivers/radeonsi/si_state_draw.c b/src/gallium/drivers/radeonsi/si_state_draw.c
index 4f81dac..708e42a 100644
--- a/src/gallium/drivers/radeonsi/si_state_draw.c
+++ b/src/gallium/drivers/radeonsi/si_state_draw.c
@@ -750,7 +750,7 @@ static void si_state_draw(struct si_context *sctx,
 
 	if (info->indexed) {
 		uint32_t max_size = (ib->buffer->width0 - ib->offset) /
-				 sctx->index_buffer.index_size;
+				    ib->index_size;
 		uint64_t va = r600_resource(ib->buffer)->gpu_address + ib->offset;
 
 		si_pm4_add_bo(pm4, (struct r600_resource *)ib->buffer, RADEON_USAGE_READ,
diff --git a/src/gallium/drivers/softpipe/sp_fs.h b/src/gallium/drivers/softpipe/sp_fs.h
index 5e4f1a1..4fac9b4 100644
--- a/src/gallium/drivers/softpipe/sp_fs.h
+++ b/src/gallium/drivers/softpipe/sp_fs.h
@@ -33,8 +33,7 @@
 
 
 struct sp_fragment_shader_variant *
-softpipe_create_fs_variant_exec(struct softpipe_context *softpipe,
-                                const struct pipe_shader_state *templ);
+softpipe_create_fs_variant_exec(struct softpipe_context *softpipe);
 
 
 struct tgsi_interp_coef;
diff --git a/src/gallium/drivers/softpipe/sp_fs_exec.c b/src/gallium/drivers/softpipe/sp_fs_exec.c
index 3188dd1..f3814fd 100644
--- a/src/gallium/drivers/softpipe/sp_fs_exec.c
+++ b/src/gallium/drivers/softpipe/sp_fs_exec.c
@@ -189,8 +189,7 @@ exec_delete(struct sp_fragment_shader_variant *var,
 
 
 struct sp_fragment_shader_variant *
-softpipe_create_fs_variant_exec(struct softpipe_context *softpipe,
-                                const struct pipe_shader_state *templ)
+softpipe_create_fs_variant_exec(struct softpipe_context *softpipe)
 {
    struct sp_exec_fragment_shader *shader;
 
diff --git a/src/gallium/drivers/softpipe/sp_state_derived.c b/src/gallium/drivers/softpipe/sp_state_derived.c
index dc73910..2a6a6f4 100644
--- a/src/gallium/drivers/softpipe/sp_state_derived.c
+++ b/src/gallium/drivers/softpipe/sp_state_derived.c
@@ -402,6 +402,7 @@ softpipe_update_derived(struct softpipe_context *softpipe, unsigned prim)
    if (softpipe->dirty & (SP_NEW_BLEND |
                           SP_NEW_DEPTH_STENCIL_ALPHA |
                           SP_NEW_FRAMEBUFFER |
+                          SP_NEW_STIPPLE |
                           SP_NEW_FS))
       sp_build_quad_pipeline(softpipe);
 
diff --git a/src/gallium/drivers/softpipe/sp_state_shader.c b/src/gallium/drivers/softpipe/sp_state_shader.c
index a2960e5..58a2498 100644
--- a/src/gallium/drivers/softpipe/sp_state_shader.c
+++ b/src/gallium/drivers/softpipe/sp_state_shader.c
@@ -51,25 +51,27 @@ create_fs_variant(struct softpipe_context *softpipe,
                   const struct sp_fragment_shader_variant_key *key)
 {
    struct sp_fragment_shader_variant *var;
-   struct pipe_shader_state *stipple_fs = NULL, *curfs = &fs->shader;
-   unsigned unit = 0;
-
-#if DO_PSTIPPLE_IN_HELPER_MODULE
-   if (key->polygon_stipple) {
-      /* get new shader that implements polygon stippling */
-      stipple_fs = util_pstipple_create_fragment_shader(&softpipe->pipe,
-                                                        curfs, &unit);
-      curfs = stipple_fs;
-   }
-#endif
+   struct pipe_shader_state *curfs = &fs->shader;
 
    /* codegen, create variant object */
-   var = softpipe_create_fs_variant_exec(softpipe, curfs);
+   var = softpipe_create_fs_variant_exec(softpipe);
 
    if (var) {
       var->key = *key;
-      var->tokens = tgsi_dup_tokens(curfs->tokens);
-      var->stipple_sampler_unit = unit;
+
+#if DO_PSTIPPLE_IN_HELPER_MODULE
+      if (key->polygon_stipple) {
+         /* get new shader that implements polygon stippling */
+         var->tokens = 
+            util_pstipple_create_fragment_shader(curfs->tokens,
+                                                 &var->stipple_sampler_unit);
+      }
+      else
+#endif
+      {
+         var->tokens = tgsi_dup_tokens(curfs->tokens);
+         var->stipple_sampler_unit = 0;
+      }
 
       tgsi_scan_shader(var->tokens, &var->info);
 
@@ -90,11 +92,6 @@ create_fs_variant(struct softpipe_context *softpipe,
       fs->variants = var;
    }
 
-   if (stipple_fs) {
-      FREE((void *) stipple_fs->tokens);
-      FREE(stipple_fs);
-   }
-
    return var;
 }
 
@@ -135,7 +132,7 @@ softpipe_create_fs_state(struct pipe_context *pipe,
    state->draw_shader = draw_create_fragment_shader(softpipe->draw,
                                                     &state->shader);
    if (!state->draw_shader) {
-      FREE((void *) state->shader.tokens);
+      tgsi_free_tokens(state->shader.tokens);
       FREE(state);
       return NULL;
    }
@@ -197,7 +194,7 @@ softpipe_delete_fs_state(struct pipe_context *pipe, void *fs)
 
    draw_delete_fragment_shader(softpipe->draw, state->draw_shader);
 
-   FREE((void *) state->shader.tokens);
+   tgsi_free_tokens(state->shader.tokens);
    FREE(state);
 }
 
@@ -229,7 +226,7 @@ softpipe_create_vs_state(struct pipe_context *pipe,
 
 fail:
    if (state) {
-      FREE( (void *)state->shader.tokens );
+      tgsi_free_tokens(state->shader.tokens);
       FREE( state->draw_data );
       FREE( state );
    }
@@ -259,7 +256,7 @@ softpipe_delete_vs_state(struct pipe_context *pipe, void *vs)
    struct sp_vertex_shader *state = (struct sp_vertex_shader *) vs;
 
    draw_delete_vertex_shader(softpipe->draw, state->draw_data);
-   FREE( (void *)state->shader.tokens );
+   tgsi_free_tokens(state->shader.tokens);
    FREE( state );
 }
 
@@ -299,7 +296,7 @@ softpipe_create_gs_state(struct pipe_context *pipe,
 
 fail:
    if (state) {
-      FREE( (void *)state->shader.tokens );
+      tgsi_free_tokens(state->shader.tokens);
       FREE( state->draw_data );
       FREE( state );
    }
@@ -332,7 +329,7 @@ softpipe_delete_gs_state(struct pipe_context *pipe, void *gs)
    draw_delete_geometry_shader(softpipe->draw,
                                (state) ? state->draw_data : 0);
 
-   FREE((void *) state->shader.tokens);
+   tgsi_free_tokens(state->shader.tokens);
    FREE(state);
 }
 
diff --git a/src/gallium/drivers/vc4/kernel/.dir-locals.el b/src/gallium/drivers/vc4/kernel/.dir-locals.el
new file mode 100644
index 0000000..2e58e90
--- /dev/null
+++ b/src/gallium/drivers/vc4/kernel/.dir-locals.el
@@ -0,0 +1,12 @@
+((nil
+  (indent-tabs-mode . t)
+  (tab-width . 8)
+  (c-basic-offset . 8)
+  (c-file-style . "stroustrup")
+  (fill-column . 78)
+  (eval . (progn
+	    (c-set-offset 'innamespace '0)
+	    (c-set-offset 'inline-open '0)))
+  )
+ (makefile-mode (indent-tabs-mode . t))
+ )
diff --git a/src/gallium/drivers/vc4/kernel/vc4_drv.h b/src/gallium/drivers/vc4/kernel/vc4_drv.h
index 45d9c40..b0eb3f0 100644
--- a/src/gallium/drivers/vc4/kernel/vc4_drv.h
+++ b/src/gallium/drivers/vc4/kernel/vc4_drv.h
@@ -128,6 +128,7 @@ struct exec_info {
  * Setup") for definitions of the texture parameters.
  */
 struct vc4_texture_sample_info {
+	bool is_direct;
 	uint32_t p_offset[4];
 };
 
diff --git a/src/gallium/drivers/vc4/kernel/vc4_validate.c b/src/gallium/drivers/vc4/kernel/vc4_validate.c
index 86b8fa5..8b04eb9 100644
--- a/src/gallium/drivers/vc4/kernel/vc4_validate.c
+++ b/src/gallium/drivers/vc4/kernel/vc4_validate.c
@@ -478,7 +478,7 @@ validate_tile_binning_config(VALIDATE_ARGS)
 	}
 	tile_allocation_size = *(uint32_t *)(untrusted + 4);
 	if (tile_allocation_size > tile_allocation->base.size) {
-		DRM_ERROR("tile allocation size %d > BO size %d",
+		DRM_ERROR("tile allocation size %d > BO size %d\n",
 			  tile_allocation_size, tile_allocation->base.size);
 		return -EINVAL;
 	}
@@ -767,6 +767,23 @@ reloc_tex(struct exec_info *exec,
 	uint32_t cube_map_stride = 0;
 	enum vc4_texture_data_type type;
 
+	if (!vc4_use_bo(exec, texture_handle_index, VC4_MODE_RENDER, &tex))
+		return false;
+
+	if (sample->is_direct) {
+		uint32_t remaining_size = tex->base.size - p0;
+		if (p0 > tex->base.size - 4) {
+			DRM_ERROR("UBO offset greater than UBO size\n");
+			return false;
+		}
+		if (p1 > remaining_size - 4) {
+			DRM_ERROR("UBO clamp would allow reads outside of UBO\n");
+			return false;
+		}
+		*validated_p0 = tex->paddr + p0;
+		return true;
+	}
+
 	if (width == 0)
 		width = 2048;
 	if (height == 0)
@@ -778,14 +795,14 @@ reloc_tex(struct exec_info *exec,
 		if ((p3 & (3 << 30)) == (1 << 30)) {
 			if (cube_map_stride) {
 				DRM_ERROR("Cube map stride set twice\n");
-				return -EINVAL;
+				return false;
 			}
 
 			cube_map_stride = p3 & 0x3ffff000;
 		}
 		if (!cube_map_stride) {
 			DRM_ERROR("Cube map stride not set\n");
-			return -EINVAL;
+			return false;
 		}
 	}
 
@@ -832,9 +849,6 @@ reloc_tex(struct exec_info *exec,
 			tiling_format = VC4_TILING_FORMAT_T;
 	}
 
-	if (!vc4_use_bo(exec, texture_handle_index, VC4_MODE_RENDER, &tex))
-		return false;
-
 	if (!check_tex_size(exec, tex, offset + cube_map_stride * 5,
 			    tiling_format, width, height, cpp)) {
 		return false;
diff --git a/src/gallium/drivers/vc4/kernel/vc4_validate_shaders.c b/src/gallium/drivers/vc4/kernel/vc4_validate_shaders.c
index dc958c7..e797c59 100644
--- a/src/gallium/drivers/vc4/kernel/vc4_validate_shaders.c
+++ b/src/gallium/drivers/vc4/kernel/vc4_validate_shaders.c
@@ -51,8 +51,39 @@
 struct vc4_shader_validation_state {
 	struct vc4_texture_sample_info tmu_setup[2];
 	int tmu_write_count[2];
+
+	/* For registers that were last written to by a MIN instruction with
+	 * one argument being a uniform, the address of the uniform.
+	 * Otherwise, ~0.
+	 *
+	 * This is used for the validation of direct address memory reads.
+	 */
+	uint32_t live_clamp_offsets[32 + 32 + 4];
 };
 
+static uint32_t
+waddr_to_live_reg_index(uint32_t waddr, bool is_b)
+{
+	if (waddr < 32) {
+		if (is_b)
+			return 32 + waddr;
+		else
+			return waddr;
+	} else if (waddr <= QPU_W_ACC3) {
+
+		return 64 + waddr - QPU_W_ACC0;
+	} else {
+		return ~0;
+	}
+}
+
+static bool
+is_tmu_submit(uint32_t waddr)
+{
+	return (waddr == QPU_W_TMU0_S ||
+		waddr == QPU_W_TMU1_S);
+}
+
 static bool
 is_tmu_write(uint32_t waddr)
 {
@@ -75,27 +106,86 @@ record_validated_texture_sample(struct vc4_validated_shader_info *validated_shad
 	if (!temp_samples)
 		return false;
 
-	memcpy(temp_samples[s].p_offset,
-	       validation_state->tmu_setup[tmu].p_offset,
-	       validation_state->tmu_write_count[tmu] * sizeof(uint32_t));
-	for (i = validation_state->tmu_write_count[tmu]; i < 4; i++)
-		temp_samples[s].p_offset[i] = ~0;
+	memcpy(&temp_samples[s],
+	       &validation_state->tmu_setup[tmu],
+	       sizeof(*temp_samples));
 
 	validated_shader->num_texture_samples = s + 1;
 	validated_shader->texture_samples = temp_samples;
 
+	for (i = 0; i < 4; i++)
+		validation_state->tmu_setup[tmu].p_offset[i] = ~0;
+
 	return true;
 }
 
 static bool
-check_tmu_write(struct vc4_validated_shader_info *validated_shader,
+check_tmu_write(uint64_t inst,
+		struct vc4_validated_shader_info *validated_shader,
 		struct vc4_shader_validation_state *validation_state,
-		uint32_t waddr)
+		bool is_mul)
 {
+	uint32_t waddr = (is_mul ?
+			  QPU_GET_FIELD(inst, QPU_WADDR_MUL) :
+			  QPU_GET_FIELD(inst, QPU_WADDR_ADD));
+	uint32_t raddr_a = QPU_GET_FIELD(inst, QPU_RADDR_A);
+	uint32_t raddr_b = QPU_GET_FIELD(inst, QPU_RADDR_B);
 	int tmu = waddr > QPU_W_TMU0_B;
+	bool submit = is_tmu_submit(waddr);
+	bool is_direct = submit && validation_state->tmu_write_count[tmu] == 0;
 
-	if (!is_tmu_write(waddr))
-		return true;
+	if (is_direct) {
+		uint32_t add_a = QPU_GET_FIELD(inst, QPU_ADD_A);
+		uint32_t add_b = QPU_GET_FIELD(inst, QPU_ADD_B);
+		uint32_t clamp_offset = ~0;
+
+		/* Make sure that this texture load is an add of the base
+		 * address of the UBO to a clamped offset within the UBO.
+		 */
+		if (is_mul ||
+		    QPU_GET_FIELD(inst, QPU_OP_ADD) != QPU_A_ADD) {
+			DRM_ERROR("direct TMU load wasn't an add\n");
+			return false;
+		}
+
+		/* We assert that the the clamped address is the first
+		 * argument, and the UBO base address is the second argument.
+		 * This is arbitrary, but simpler than supporting flipping the
+		 * two either way.
+		 */
+		if (add_a == QPU_MUX_A) {
+			clamp_offset = validation_state->live_clamp_offsets[raddr_a];
+		} else if (add_a == QPU_MUX_B) {
+			clamp_offset = validation_state->live_clamp_offsets[32 + raddr_b];
+		} else if (add_a <= QPU_MUX_R4) {
+			clamp_offset = validation_state->live_clamp_offsets[64 + add_a];
+		}
+
+		if (clamp_offset == ~0) {
+			DRM_ERROR("direct TMU load wasn't clamped\n");
+			return false;
+		}
+
+		/* Store the clamp value's offset in p1 (see reloc_tex() in
+		 * vc4_validate.c).
+		 */
+		validation_state->tmu_setup[tmu].p_offset[1] =
+			clamp_offset;
+
+		if (!(add_b == QPU_MUX_A && raddr_a == QPU_R_UNIF) &&
+		    !(add_b == QPU_MUX_B && raddr_b == QPU_R_UNIF)) {
+			DRM_ERROR("direct TMU load didn't add to a uniform\n");
+			return false;
+		}
+
+		validation_state->tmu_setup[tmu].is_direct = true;
+	} else {
+		if (raddr_a == QPU_R_UNIF || raddr_b == QPU_R_UNIF) {
+			DRM_ERROR("uniform read in the same instruction as "
+				  "texture setup.\n");
+			return false;
+		}
+	}
 
 	if (validation_state->tmu_write_count[tmu] >= 4) {
 		DRM_ERROR("TMU%d got too many parameters before dispatch\n",
@@ -105,9 +195,13 @@ check_tmu_write(struct vc4_validated_shader_info *validated_shader,
 	validation_state->tmu_setup[tmu].p_offset[validation_state->tmu_write_count[tmu]] =
 		validated_shader->uniforms_size;
 	validation_state->tmu_write_count[tmu]++;
-	validated_shader->uniforms_size += 4;
+	/* Since direct uses a RADDR uniform reference, it will get counted in
+	 * check_instruction_reads()
+	 */
+	if (!is_direct)
+		validated_shader->uniforms_size += 4;
 
-	if (waddr == QPU_W_TMU0_S || waddr == QPU_W_TMU1_S) {
+	if (submit) {
 		if (!record_validated_texture_sample(validated_shader,
 						     validation_state, tmu)) {
 			return false;
@@ -120,10 +214,17 @@ check_tmu_write(struct vc4_validated_shader_info *validated_shader,
 }
 
 static bool
-check_register_write(struct vc4_validated_shader_info *validated_shader,
+check_register_write(uint64_t inst,
+		     struct vc4_validated_shader_info *validated_shader,
 		     struct vc4_shader_validation_state *validation_state,
-		     uint32_t waddr)
+		     bool is_mul)
 {
+	uint32_t waddr = (is_mul ?
+			  QPU_GET_FIELD(inst, QPU_WADDR_MUL) :
+			  QPU_GET_FIELD(inst, QPU_WADDR_ADD));
+	bool is_b = is_mul != ((inst & QPU_PM) != 0);
+	uint32_t live_reg_index;
+
 	switch (waddr) {
 	case QPU_W_UNIFORMS_ADDRESS:
 		/* XXX: We'll probably need to support this for reladdr, but
@@ -148,8 +249,8 @@ check_register_write(struct vc4_validated_shader_info *validated_shader,
 	case QPU_W_TMU1_T:
 	case QPU_W_TMU1_R:
 	case QPU_W_TMU1_B:
-		return check_tmu_write(validated_shader, validation_state,
-				       waddr);
+		return check_tmu_write(inst, validated_shader, validation_state,
+				       is_mul);
 
 	case QPU_W_HOST_INT:
 	case QPU_W_TMU_NOSWAP:
@@ -177,9 +278,44 @@ check_register_write(struct vc4_validated_shader_info *validated_shader,
                 return true;
 	}
 
+	/* Clear out the live offset clamp tracking for the written register.
+	 * If this particular instruction is setting up an offset clamp, it'll
+	 * get tracked immediately after we return.
+	 */
+	live_reg_index = waddr_to_live_reg_index(waddr, is_b);
+	if (live_reg_index != ~0)
+		validation_state->live_clamp_offsets[live_reg_index] = ~0;
+
 	return true;
 }
 
+static void
+track_live_clamps(uint64_t inst,
+		  struct vc4_validated_shader_info *validated_shader,
+		  struct vc4_shader_validation_state *validation_state)
+{
+	uint32_t waddr_add = QPU_GET_FIELD(inst, QPU_WADDR_ADD);
+	uint32_t add_b = QPU_GET_FIELD(inst, QPU_ADD_B);
+	uint32_t raddr_a = QPU_GET_FIELD(inst, QPU_RADDR_A);
+	uint32_t raddr_b = QPU_GET_FIELD(inst, QPU_RADDR_B);
+	bool pm = inst & QPU_PM;
+	uint32_t live_reg_index;
+
+	if (QPU_GET_FIELD(inst, QPU_OP_ADD) != QPU_A_MIN)
+		return;
+
+	if (!(add_b == QPU_MUX_A && raddr_a == QPU_R_UNIF) &&
+	    !(add_b == QPU_MUX_B && raddr_b == QPU_R_UNIF)) {
+		return;
+	}
+
+	live_reg_index = waddr_to_live_reg_index(waddr_add, pm);
+	if (live_reg_index != ~0) {
+		validation_state->live_clamp_offsets[live_reg_index] =
+			validated_shader->uniforms_size;
+	}
+}
+
 static bool
 check_instruction_writes(uint64_t inst,
 			 struct vc4_validated_shader_info *validated_shader,
@@ -187,33 +323,30 @@ check_instruction_writes(uint64_t inst,
 {
 	uint32_t waddr_add = QPU_GET_FIELD(inst, QPU_WADDR_ADD);
 	uint32_t waddr_mul = QPU_GET_FIELD(inst, QPU_WADDR_MUL);
+	bool ok;
 
 	if (is_tmu_write(waddr_add) && is_tmu_write(waddr_mul)) {
 		DRM_ERROR("ADD and MUL both set up textures\n");
 		return false;
 	}
 
-	return (check_register_write(validated_shader, validation_state, waddr_add) &&
-		check_register_write(validated_shader, validation_state, waddr_mul));
+	ok = (check_register_write(inst, validated_shader, validation_state, false) &&
+	      check_register_write(inst, validated_shader, validation_state, true));
+
+	track_live_clamps(inst, validated_shader, validation_state);
+
+	return ok;
 }
 
 static bool
 check_instruction_reads(uint64_t inst,
 			struct vc4_validated_shader_info *validated_shader)
 {
-	uint32_t waddr_add = QPU_GET_FIELD(inst, QPU_WADDR_ADD);
-	uint32_t waddr_mul = QPU_GET_FIELD(inst, QPU_WADDR_MUL);
 	uint32_t raddr_a = QPU_GET_FIELD(inst, QPU_RADDR_A);
 	uint32_t raddr_b = QPU_GET_FIELD(inst, QPU_RADDR_B);
 
 	if (raddr_a == QPU_R_UNIF ||
 	    raddr_b == QPU_R_UNIF) {
-		if (is_tmu_write(waddr_add) || is_tmu_write(waddr_mul)) {
-			DRM_ERROR("uniform read in the same instruction as "
-				  "texture setup");
-			return false;
-		}
-
 		/* This can't overflow the uint32_t, because we're reading 8
 		 * bytes of instruction to increment by 4 here, so we'd
 		 * already be OOM.
@@ -234,9 +367,15 @@ vc4_validate_shader(struct drm_gem_cma_object *shader_obj,
 	uint64_t *shader;
 	struct vc4_validated_shader_info *validated_shader;
 	struct vc4_shader_validation_state validation_state;
+	int i;
 
 	memset(&validation_state, 0, sizeof(validation_state));
 
+	for (i = 0; i < 8; i++)
+		validation_state.tmu_setup[i / 4].p_offset[i % 4] = ~0;
+	for (i = 0; i < ARRAY_SIZE(validation_state.live_clamp_offsets); i++)
+		validation_state.live_clamp_offsets[i] = ~0;
+
 	if (start_offset + sizeof(uint64_t) > shader_obj->base.size) {
 		DRM_ERROR("shader starting at %d outside of BO sized %d\n",
 			  start_offset,
@@ -261,6 +400,7 @@ vc4_validate_shader(struct drm_gem_cma_object *shader_obj,
 		case QPU_SIG_COLOR_LOAD:
 		case QPU_SIG_LOAD_TMU0:
 		case QPU_SIG_LOAD_TMU1:
+		case QPU_SIG_PROG_END:
 			if (!check_instruction_writes(inst, validated_shader,
 						      &validation_state)) {
 				DRM_ERROR("Bad write at ip %d\n", ip);
@@ -270,6 +410,11 @@ vc4_validate_shader(struct drm_gem_cma_object *shader_obj,
 			if (!check_instruction_reads(inst, validated_shader))
 				goto fail;
 
+			if (sig == QPU_SIG_PROG_END) {
+				found_shader_end = true;
+				shader_end_ip = ip;
+			}
+
 			break;
 
 		case QPU_SIG_LOAD_IMM:
@@ -280,11 +425,6 @@ vc4_validate_shader(struct drm_gem_cma_object *shader_obj,
 			}
 			break;
 
-		case QPU_SIG_PROG_END:
-			found_shader_end = true;
-			shader_end_ip = ip;
-			break;
-
 		default:
 			DRM_ERROR("Unsupported QPU signal %d at "
 				  "instruction %d\n", sig, ip);
diff --git a/src/gallium/drivers/vc4/vc4_context.h b/src/gallium/drivers/vc4/vc4_context.h
index 9eaff8f..6a82d8f 100644
--- a/src/gallium/drivers/vc4/vc4_context.h
+++ b/src/gallium/drivers/vc4/vc4_context.h
@@ -87,12 +87,35 @@ struct vc4_uncompiled_shader {
         const struct tgsi_token *twoside_tokens;
 };
 
+struct vc4_ubo_range {
+        /**
+         * offset in bytes from the start of the ubo where this range is
+         * uploaded.
+         *
+         * Only set once used is set.
+         */
+        uint32_t dst_offset;
+
+        /**
+         * offset in bytes from the start of the gallium uniforms where the
+         * data comes from.
+         */
+        uint32_t src_offset;
+
+        /** size in bytes of this ubo range */
+        uint32_t size;
+};
+
 struct vc4_compiled_shader {
         uint64_t program_id;
         struct vc4_bo *bo;
 
         struct vc4_shader_uniform_info uniforms;
 
+        struct vc4_ubo_range *ubo_ranges;
+        uint32_t num_ubo_ranges;
+        uint32_t ubo_size;
+
         /** bitmask of which inputs are color inputs, for flat shade handling. */
         uint32_t color_inputs;
 
diff --git a/src/gallium/drivers/vc4/vc4_opt_dead_code.c b/src/gallium/drivers/vc4/vc4_opt_dead_code.c
index d958dcb..408bd43 100644
--- a/src/gallium/drivers/vc4/vc4_opt_dead_code.c
+++ b/src/gallium/drivers/vc4/vc4_opt_dead_code.c
@@ -92,7 +92,8 @@ qir_opt_dead_code(struct vc4_compile *c)
                 if (dce_tex && (inst->op == QOP_TEX_S ||
                                 inst->op == QOP_TEX_T ||
                                 inst->op == QOP_TEX_R ||
-                                inst->op == QOP_TEX_B)) {
+                                inst->op == QOP_TEX_B ||
+                                inst->op == QOP_TEX_DIRECT)) {
                         dce(c, inst);
                         progress = true;
                         continue;
diff --git a/src/gallium/drivers/vc4/vc4_program.c b/src/gallium/drivers/vc4/vc4_program.c
index c6b7edb..72bbcd8 100644
--- a/src/gallium/drivers/vc4/vc4_program.c
+++ b/src/gallium/drivers/vc4/vc4_program.c
@@ -164,9 +164,41 @@ qir_uniform_f(struct vc4_compile *c, float f)
 }
 
 static struct qreg
+indirect_uniform_load(struct vc4_compile *c,
+                      struct tgsi_full_src_register *src, int swiz)
+{
+        struct tgsi_ind_register *indirect = &src->Indirect;
+        struct vc4_compiler_ubo_range *range = &c->ubo_ranges[indirect->ArrayID];
+        if (!range->used) {
+                range->used = true;
+                range->dst_offset = c->next_ubo_dst_offset;
+                c->next_ubo_dst_offset += range->size;
+                c->num_ubo_ranges++;
+        };
+
+        assert(src->Register.Indirect);
+        assert(indirect->File == TGSI_FILE_ADDRESS);
+
+        struct qreg addr_val = c->addr[indirect->Swizzle];
+        struct qreg indirect_offset =
+                qir_ADD(c, addr_val, qir_uniform_ui(c,
+                                                    range->dst_offset +
+                                                    (src->Register.Index * 16)+
+                                                    swiz * 4));
+        indirect_offset = qir_MIN(c, indirect_offset, qir_uniform_ui(c, (range->dst_offset +
+                                                                         range->size - 4)));
+
+        qir_TEX_DIRECT(c, indirect_offset, add_uniform(c, QUNIFORM_UBO_ADDR, 0));
+        struct qreg r4 = qir_TEX_RESULT(c);
+        c->num_texture_samples++;
+        return qir_MOV(c, r4);
+}
+
+static struct qreg
 get_src(struct vc4_compile *c, unsigned tgsi_op,
-        struct tgsi_src_register *src, int i)
+        struct tgsi_full_src_register *full_src, int i)
 {
+        struct tgsi_src_register *src = &full_src->Register;
         struct qreg r = c->undef;
 
         uint32_t s = i;
@@ -187,8 +219,6 @@ get_src(struct vc4_compile *c, unsigned tgsi_op,
                 abort();
         }
 
-        assert(!src->Indirect);
-
         switch (src->File) {
         case TGSI_FILE_NULL:
                 return r;
@@ -199,8 +229,12 @@ get_src(struct vc4_compile *c, unsigned tgsi_op,
                 r = c->consts[src->Index * 4 + s];
                 break;
         case TGSI_FILE_CONSTANT:
-                r = get_temp_for_uniform(c, QUNIFORM_UNIFORM,
-                                         src->Index * 4 + s);
+                if (src->Indirect) {
+                        r = indirect_uniform_load(c, full_src, s);
+                } else {
+                        r = get_temp_for_uniform(c, QUNIFORM_UNIFORM,
+                                                 src->Index * 4 + s);
+                }
                 break;
         case TGSI_FILE_INPUT:
                 r = c->inputs[src->Index * 4 + s];
@@ -250,6 +284,10 @@ update_dst(struct vc4_compile *c, struct tgsi_full_instruction *tgsi_inst,
                 c->num_outputs = MAX2(c->num_outputs,
                                       tgsi_dst->Index * 4 + i + 1);
                 break;
+        case TGSI_FILE_ADDRESS:
+                assert(tgsi_dst->Index == 0);
+                c->addr[i] = val;
+                break;
         default:
                 fprintf(stderr, "unknown dst file %d\n", tgsi_dst->File);
                 abort();
@@ -906,6 +944,29 @@ tgsi_to_qir_ssg(struct vc4_compile *c,
                               qir_uniform_f(c, -1.0));
 }
 
+/* Compare to tgsi_to_qir_flr() for the floor logic. */
+static struct qreg
+tgsi_to_qir_arl(struct vc4_compile *c,
+                struct tgsi_full_instruction *tgsi_inst,
+                enum qop op, struct qreg *src, int i)
+{
+        struct qreg trunc = qir_FTOI(c, src[0 * 4 + i]);
+        struct qreg scaled = qir_SHL(c, trunc, qir_uniform_ui(c, 4));
+
+        qir_SF(c, qir_FSUB(c, src[0 * 4 + i], qir_ITOF(c, trunc)));
+
+        return qir_SEL_X_Y_NS(c, qir_SUB(c, scaled, qir_uniform_ui(c, 4)),
+                              scaled);
+}
+
+static struct qreg
+tgsi_to_qir_uarl(struct vc4_compile *c,
+                struct tgsi_full_instruction *tgsi_inst,
+                enum qop op, struct qreg *src, int i)
+{
+        return qir_SHL(c, src[0 * 4 + i], qir_uniform_ui(c, 4));
+}
+
 static void
 emit_vertex_input(struct vc4_compile *c, int attr)
 {
@@ -1087,6 +1148,24 @@ add_output(struct vc4_compile *c,
 }
 
 static void
+add_array_info(struct vc4_compile *c, uint32_t array_id,
+               uint32_t start, uint32_t size)
+{
+        if (array_id >= c->ubo_ranges_array_size) {
+                c->ubo_ranges_array_size = MAX2(c->ubo_ranges_array_size * 2,
+                                                array_id + 1);
+                c->ubo_ranges = reralloc(c, c->ubo_ranges,
+                                         struct vc4_compiler_ubo_range,
+                                         c->ubo_ranges_array_size);
+        }
+
+        c->ubo_ranges[array_id].dst_offset = 0;
+        c->ubo_ranges[array_id].src_offset = start;
+        c->ubo_ranges[array_id].size = size;
+        c->ubo_ranges[array_id].used = false;
+}
+
+static void
 emit_tgsi_declaration(struct vc4_compile *c,
                       struct tgsi_full_declaration *decl)
 {
@@ -1152,6 +1231,14 @@ emit_tgsi_declaration(struct vc4_compile *c,
                 }
 
                 break;
+
+        case TGSI_FILE_CONSTANT:
+                add_array_info(c,
+                               decl->Array.ArrayID,
+                               decl->Range.First * 16,
+                               (decl->Range.Last -
+                                decl->Range.First + 1) * 16);
+                break;
         }
         }
 }
@@ -1219,6 +1306,8 @@ emit_tgsi_instruction(struct vc4_compile *c,
                 [TGSI_OPCODE_COS] = { 0, tgsi_to_qir_cos },
                 [TGSI_OPCODE_CLAMP] = { 0, tgsi_to_qir_clamp },
                 [TGSI_OPCODE_SSG] = { 0, tgsi_to_qir_ssg },
+                [TGSI_OPCODE_ARL] = { 0, tgsi_to_qir_arl },
+                [TGSI_OPCODE_UARL] = { 0, tgsi_to_qir_uarl },
         };
         static int asdf = 0;
         uint32_t tgsi_op = tgsi_inst->Instruction.Opcode;
@@ -1231,7 +1320,7 @@ emit_tgsi_instruction(struct vc4_compile *c,
                 for (int i = 0; i < 4; i++) {
                         src_regs[4 * s + i] =
                                 get_src(c, tgsi_inst->Instruction.Opcode,
-                                        &tgsi_inst->Src[s].Register, i);
+                                        &tgsi_inst->Src[s], i);
                 }
         }
 
@@ -1833,6 +1922,9 @@ vc4_shader_tgsi_to_qir(struct vc4_context *vc4, enum qstage stage,
         int ret;
 
         c->stage = stage;
+        for (int i = 0; i < 4; i++)
+                c->addr[i] = qir_uniform_f(c, 0.0);
+
         c->shader_state = &key->shader_state->base;
         c->program_id = key->shader_state->program_id;
         c->variant_id = key->shader_state->compiled_variant_count++;
@@ -2065,6 +2157,31 @@ vc4_get_compiled_shader(struct vc4_context *vc4, enum qstage stage,
                                       c->qpu_inst_count * sizeof(uint64_t),
                                       "code");
 
+        /* Copy the compiler UBO range state to the compiled shader, dropping
+         * out arrays that were never referenced by an indirect load.
+         *
+         * (Note that QIR dead code elimination of an array access still
+         * leaves that array alive, though)
+         */
+        if (c->num_ubo_ranges) {
+                shader->num_ubo_ranges = c->num_ubo_ranges;
+                shader->ubo_ranges = ralloc_array(shader, struct vc4_ubo_range,
+                                                  c->num_ubo_ranges);
+                uint32_t j = 0;
+                for (int i = 0; i < c->ubo_ranges_array_size; i++) {
+                        struct vc4_compiler_ubo_range *range =
+                                &c->ubo_ranges[i];
+                        if (!range->used)
+                                continue;
+
+                        shader->ubo_ranges[j].dst_offset = range->dst_offset;
+                        shader->ubo_ranges[j].src_offset = range->src_offset;
+                        shader->ubo_ranges[j].size = range->size;
+                        shader->ubo_size += c->ubo_ranges[i].size;
+                        j++;
+                }
+        }
+
         qir_compile_destroy(c);
 
         struct vc4_key *dup_key;
@@ -2461,6 +2578,24 @@ get_texrect_scale(struct vc4_texture_stateobj *texstate,
         return fui(1.0f / dim);
 }
 
+static struct vc4_bo *
+vc4_upload_ubo(struct vc4_context *vc4, struct vc4_compiled_shader *shader,
+               const uint32_t *gallium_uniforms)
+{
+        if (!shader->ubo_size)
+                return NULL;
+
+        struct vc4_bo *ubo = vc4_bo_alloc(vc4->screen, shader->ubo_size, "ubo");
+        uint32_t *data = vc4_bo_map(ubo);
+        for (uint32_t i = 0; i < shader->num_ubo_ranges; i++) {
+                memcpy(data + shader->ubo_ranges[i].dst_offset,
+                       gallium_uniforms + shader->ubo_ranges[i].src_offset,
+                       shader->ubo_ranges[i].size);
+        }
+
+        return ubo;
+}
+
 void
 vc4_write_uniforms(struct vc4_context *vc4, struct vc4_compiled_shader *shader,
                    struct vc4_constbuf_stateobj *cb,
@@ -2468,6 +2603,7 @@ vc4_write_uniforms(struct vc4_context *vc4, struct vc4_compiled_shader *shader,
 {
         struct vc4_shader_uniform_info *uinfo = &shader->uniforms;
         const uint32_t *gallium_uniforms = cb->cb[0].user_buffer;
+        struct vc4_bo *ubo = vc4_upload_ubo(vc4, shader, gallium_uniforms);
 
         cl_start_shader_reloc(&vc4->uniforms, uinfo->num_texture_samples);
 
@@ -2512,6 +2648,10 @@ vc4_write_uniforms(struct vc4_context *vc4, struct vc4_compiled_shader *shader,
                         write_texture_p2(vc4, texstate, uinfo->data[i]);
                         break;
 
+                case QUNIFORM_UBO_ADDR:
+                        cl_reloc(vc4, &vc4->uniforms, ubo, 0);
+                        break;
+
                 case QUNIFORM_TEXTURE_BORDER_COLOR:
                         write_texture_border_color(vc4, texstate, uinfo->data[i]);
                         break;
diff --git a/src/gallium/drivers/vc4/vc4_qir.c b/src/gallium/drivers/vc4/vc4_qir.c
index a7a4d96..cd731bc 100644
--- a/src/gallium/drivers/vc4/vc4_qir.c
+++ b/src/gallium/drivers/vc4/vc4_qir.c
@@ -93,6 +93,7 @@ static const struct qir_op_info qir_op_info[] = {
         [QOP_TEX_T] = { "tex_t", 0, 2 },
         [QOP_TEX_R] = { "tex_r", 0, 2 },
         [QOP_TEX_B] = { "tex_b", 0, 2 },
+        [QOP_TEX_DIRECT] = { "tex_direct", 0, 2 },
         [QOP_TEX_RESULT] = { "tex_result", 1, 0, true },
         [QOP_R4_UNPACK_A] = { "r4_unpack_a", 1, 1 },
         [QOP_R4_UNPACK_B] = { "r4_unpack_b", 1, 1 },
diff --git a/src/gallium/drivers/vc4/vc4_qir.h b/src/gallium/drivers/vc4/vc4_qir.h
index 077a55a..cb02db5 100644
--- a/src/gallium/drivers/vc4/vc4_qir.h
+++ b/src/gallium/drivers/vc4/vc4_qir.h
@@ -122,6 +122,16 @@ enum qop {
         QOP_TEX_R,
         /** Texture LOD bias parameter write */
         QOP_TEX_B,
+
+        /**
+         * Texture-unit 4-byte read with address provided direct in S
+         * cooordinate.
+         *
+         * The first operand is the offset from the start of the UBO, and the
+         * second is the uniform that has the UBO's base pointer.
+         */
+        QOP_TEX_DIRECT,
+
         /**
          * Signal of texture read being necessary and then reading r4 into
          * the destination
@@ -207,6 +217,8 @@ enum quniform_contents {
         /** A reference to a texture config parameter 2 cubemap stride uniform */
         QUNIFORM_TEXTURE_CONFIG_P2,
 
+        QUNIFORM_UBO_ADDR,
+
         QUNIFORM_TEXRECT_SCALE_X,
         QUNIFORM_TEXRECT_SCALE_Y,
 
@@ -224,6 +236,31 @@ struct vc4_varying_semantic {
         uint8_t swizzle;
 };
 
+struct vc4_compiler_ubo_range {
+        /**
+         * offset in bytes from the start of the ubo where this range is
+         * uploaded.
+         *
+         * Only set once used is set.
+         */
+        uint32_t dst_offset;
+
+        /**
+         * offset in bytes from the start of the gallium uniforms where the
+         * data comes from.
+         */
+        uint32_t src_offset;
+
+        /** size in bytes of this ubo range */
+        uint32_t size;
+
+        /**
+         * Set if this range is used by the shader for indirect uniforms
+         * access.
+         */
+        bool used;
+};
+
 struct vc4_compile {
         struct vc4_context *vc4;
         struct tgsi_parse_context parser;
@@ -236,12 +273,19 @@ struct vc4_compile {
         struct qreg *inputs;
         struct qreg *outputs;
         struct qreg *consts;
+        struct qreg addr[4]; /* TGSI ARL destination. */
         uint32_t temps_array_size;
         uint32_t inputs_array_size;
         uint32_t outputs_array_size;
         uint32_t uniforms_array_size;
         uint32_t consts_array_size;
         uint32_t num_consts;
+
+        struct vc4_compiler_ubo_range *ubo_ranges;
+        uint32_t ubo_ranges_array_size;
+        uint32_t num_ubo_ranges;
+        uint32_t next_ubo_dst_offset;
+
         struct qreg line_x, point_x, point_y;
         struct qreg discard;
 
@@ -409,6 +453,7 @@ QIR_NODST_2(TEX_S)
 QIR_NODST_2(TEX_T)
 QIR_NODST_2(TEX_R)
 QIR_NODST_2(TEX_B)
+QIR_NODST_2(TEX_DIRECT)
 QIR_ALU0(FRAG_X)
 QIR_ALU0(FRAG_Y)
 QIR_ALU0(FRAG_Z)
diff --git a/src/gallium/drivers/vc4/vc4_qpu_emit.c b/src/gallium/drivers/vc4/vc4_qpu_emit.c
index 1d9bff3..1d12d11 100644
--- a/src/gallium/drivers/vc4/vc4_qpu_emit.c
+++ b/src/gallium/drivers/vc4/vc4_qpu_emit.c
@@ -517,6 +517,11 @@ vc4_generate_code(struct vc4_context *vc4, struct vc4_compile *c)
                                            src[0]));
                         break;
 
+                case QOP_TEX_DIRECT:
+                        fixup_raddr_conflict(c, &src[0], &src[1]);
+                        queue(c, qpu_a_ADD(qpu_rb(QPU_W_TMU0_S), src[0], src[1]));
+                        break;
+
                 case QOP_TEX_RESULT:
                         queue(c, qpu_NOP());
                         *last_inst(c) = qpu_set_sig(*last_inst(c),
diff --git a/src/gallium/drivers/vc4/vc4_screen.c b/src/gallium/drivers/vc4/vc4_screen.c
index b84b6b0..c18760c 100644
--- a/src/gallium/drivers/vc4/vc4_screen.c
+++ b/src/gallium/drivers/vc4/vc4_screen.c
@@ -299,8 +299,9 @@ vc4_screen_get_shader_param(struct pipe_screen *pscreen, unsigned shader,
         case PIPE_SHADER_CAP_INDIRECT_INPUT_ADDR:
         case PIPE_SHADER_CAP_INDIRECT_OUTPUT_ADDR:
         case PIPE_SHADER_CAP_INDIRECT_TEMP_ADDR:
-        case PIPE_SHADER_CAP_INDIRECT_CONST_ADDR:
                 return 0;
+        case PIPE_SHADER_CAP_INDIRECT_CONST_ADDR:
+                return 1;
         case PIPE_SHADER_CAP_SUBROUTINES:
                 return 0;
         case PIPE_SHADER_CAP_TGSI_SQRT_SUPPORTED:
diff --git a/src/gallium/state_trackers/clover/api/program.cpp b/src/gallium/state_trackers/clover/api/program.cpp
index a8a6291..3a6c054 100644
--- a/src/gallium/state_trackers/clover/api/program.cpp
+++ b/src/gallium/state_trackers/clover/api/program.cpp
@@ -25,6 +25,25 @@
 
 using namespace clover;
 
+namespace {
+   void validate_build_program_common(const program &prog, cl_uint num_devs,
+                                      const cl_device_id *d_devs,
+                                      void (*pfn_notify)(cl_program, void *),
+                                      void *user_data) {
+
+      if ((!pfn_notify && user_data))
+         throw error(CL_INVALID_VALUE);
+
+      if (prog.kernel_ref_count())
+         throw error(CL_INVALID_OPERATION);
+
+      if (any_of([&](const device &dev) {
+               return !count(dev, prog.context().devices());
+            }, objs<allow_empty_tag>(d_devs, num_devs)))
+         throw error(CL_INVALID_DEVICE);
+   }
+}
+
 CLOVER_API cl_program
 clCreateProgramWithSource(cl_context d_ctx, cl_uint count,
                           const char **strings, const size_t *lengths,
@@ -152,12 +171,20 @@ CLOVER_API cl_int
 clBuildProgram(cl_program d_prog, cl_uint num_devs,
                const cl_device_id *d_devs, const char *p_opts,
                void (*pfn_notify)(cl_program, void *),
-               void *user_data) {
-   cl_int ret = clCompileProgram(d_prog, num_devs, d_devs, p_opts,
-                                 0, NULL, NULL, pfn_notify, user_data);
+               void *user_data) try {
+   auto &prog = obj(d_prog);
+   auto devs = (d_devs ? objs(d_devs, num_devs) :
+                ref_vector<device>(prog.context().devices()));
+   auto opts = (p_opts ? p_opts : "");
+
+   validate_build_program_common(prog, num_devs, d_devs, pfn_notify, user_data);
 
-   return (ret == CL_COMPILE_PROGRAM_FAILURE ?
-           CL_BUILD_PROGRAM_FAILURE : ret);
+   prog.build(devs, opts);
+   return CL_SUCCESS;
+} catch (error &e) {
+   if (e.get() == CL_COMPILE_PROGRAM_FAILURE)
+      return CL_BUILD_PROGRAM_FAILURE;
+   return e.get();
 }
 
 CLOVER_API cl_int
@@ -173,18 +200,12 @@ clCompileProgram(cl_program d_prog, cl_uint num_devs,
    auto opts = (p_opts ? p_opts : "");
    header_map headers;
 
-   if (bool(num_devs) != bool(d_devs) ||
-       (!pfn_notify && user_data) ||
-       bool(num_headers) != bool(header_names))
-      throw error(CL_INVALID_VALUE);
+   validate_build_program_common(prog, num_devs, d_devs, pfn_notify, user_data);
 
-   if (any_of([&](const device &dev) {
-            return !count(dev, prog.context().devices());
-         }, devs))
-      throw error(CL_INVALID_DEVICE);
+   if (bool(num_headers) != bool(header_names))
+      throw error(CL_INVALID_VALUE);
 
-   if (prog.kernel_ref_count() ||
-       !prog.has_source)
+   if (!prog.has_source)
       throw error(CL_INVALID_OPERATION);
 
 
diff --git a/src/gallium/state_trackers/clover/core/program.hpp b/src/gallium/state_trackers/clover/core/program.hpp
index b5aae7e..661fa03 100644
--- a/src/gallium/state_trackers/clover/core/program.hpp
+++ b/src/gallium/state_trackers/clover/core/program.hpp
@@ -48,7 +48,7 @@ namespace clover {
       operator=(const program &prog) = delete;
 
       void build(const ref_vector<device> &devs, const char *opts,
-                 const header_map &headers);
+                 const header_map &headers = {});
 
       const bool has_source;
       const std::string &source() const;
diff --git a/src/gallium/state_trackers/clover/llvm/invocation.cpp b/src/gallium/state_trackers/clover/llvm/invocation.cpp
index e953822..3a4fcf0 100644
--- a/src/gallium/state_trackers/clover/llvm/invocation.cpp
+++ b/src/gallium/state_trackers/clover/llvm/invocation.cpp
@@ -282,7 +282,11 @@ namespace {
 
       for (unsigned i = 0; i < kernel_node->getNumOperands(); ++i) {
          kernels.push_back(llvm::dyn_cast<llvm::Function>(
+#if HAVE_LLVM >= 0x0306
+                                    kernel_node->getOperandAsMDNode(i)->getOperand(0)));
+#else
                                     kernel_node->getOperand(i)->getOperand(0)));
+#endif
       }
    }
 
diff --git a/src/gallium/targets/pipe-loader/pipe_i965.c b/src/gallium/targets/pipe-loader/pipe_i965.c
index f4d447c..810dffc 100644
--- a/src/gallium/targets/pipe-loader/pipe_i965.c
+++ b/src/gallium/targets/pipe-loader/pipe_i965.c
@@ -21,6 +21,27 @@ create_screen(int fd)
 
    return screen;
 }
+static const struct drm_conf_ret throttle_ret = {
+   .type = DRM_CONF_INT,
+   .val.val_int = 2,
+};
 
+static const struct drm_conf_ret share_fd_ret = {
+   .type = DRM_CONF_BOOL,
+   .val.val_int = true,
+};
+
+static const struct drm_conf_ret *drm_configuration(enum drm_conf conf)
+{
+   switch (conf) {
+   case DRM_CONF_THROTTLE:
+      return &throttle_ret;
+   case DRM_CONF_SHARE_FD:
+      return &share_fd_ret;
+   default:
+      break;
+   }
+   return NULL;
+}
 PUBLIC
-DRM_DRIVER_DESCRIPTOR("i965", "i915", create_screen, NULL)
+DRM_DRIVER_DESCRIPTOR("i965", "i915", create_screen, drm_configuration)
diff --git a/src/gallium/targets/vdpau/Makefile.am b/src/gallium/targets/vdpau/Makefile.am
index 9bec6a3..ac80dfb 100644
--- a/src/gallium/targets/vdpau/Makefile.am
+++ b/src/gallium/targets/vdpau/Makefile.am
@@ -42,6 +42,7 @@ TARGET_LIB_DEPS = $(top_builddir)/src/loader/libloader.la
 
 include $(top_srcdir)/src/gallium/drivers/nouveau/Automake.inc
 
+include $(top_srcdir)/src/gallium/drivers/r300/Automake.inc
 include $(top_srcdir)/src/gallium/drivers/r600/Automake.inc
 include $(top_srcdir)/src/gallium/drivers/radeonsi/Automake.inc
 
diff --git a/src/gallium/winsys/intel/drm/intel_drm_winsys.c b/src/gallium/winsys/intel/drm/intel_drm_winsys.c
index 7b542dc..9b94ac6 100644
--- a/src/gallium/winsys/intel/drm/intel_drm_winsys.c
+++ b/src/gallium/winsys/intel/drm/intel_drm_winsys.c
@@ -610,7 +610,13 @@ intel_bo_wait(struct intel_bo *bo, int64_t timeout)
 {
    int err;
 
-   err = drm_intel_gem_bo_wait(gem_bo(bo), timeout);
+   if (timeout >= 0) {
+      err = drm_intel_gem_bo_wait(gem_bo(bo), timeout);
+   } else {
+      drm_intel_bo_wait_rendering(gem_bo(bo));
+      err = 0;
+   }
+
    /* consider the bo idle on errors */
    if (err && err != -ETIME)
       err = 0;
diff --git a/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c b/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
index caba373..c207a85 100644
--- a/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
+++ b/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
@@ -97,13 +97,11 @@ static boolean radeon_set_fd_access(struct radeon_drm_cs *applier,
     if (enable) {
         if (value) {
             *owner = applier;
-            printf("radeon: Acquired access to %s.\n", request_name);
             pipe_mutex_unlock(*mutex);
             return TRUE;
         }
     } else {
         *owner = NULL;
-        printf("radeon: Released access to %s.\n", request_name);
     }
 
     pipe_mutex_unlock(*mutex);
diff --git a/src/glsl/Makefile.sources b/src/glsl/Makefile.sources
index 0c55327..676fa0d 100644
--- a/src/glsl/Makefile.sources
+++ b/src/glsl/Makefile.sources
@@ -59,6 +59,7 @@ LIBGLSL_FILES = \
 	$(GLSL_SRCDIR)/loop_controls.cpp \
 	$(GLSL_SRCDIR)/loop_unroll.cpp \
 	$(GLSL_SRCDIR)/lower_clip_distance.cpp \
+	$(GLSL_SRCDIR)/lower_const_arrays_to_uniforms.cpp \
 	$(GLSL_SRCDIR)/lower_discard.cpp \
 	$(GLSL_SRCDIR)/lower_discard_flow.cpp \
 	$(GLSL_SRCDIR)/lower_if_to_cond_assign.cpp \
@@ -104,8 +105,7 @@ LIBGLSL_FILES = \
 	$(GLSL_SRCDIR)/opt_swizzle_swizzle.cpp \
 	$(GLSL_SRCDIR)/opt_tree_grafting.cpp \
 	$(GLSL_SRCDIR)/opt_vectorize.cpp \
-	$(GLSL_SRCDIR)/s_expression.cpp \
-	$(GLSL_SRCDIR)/strtod.c
+	$(GLSL_SRCDIR)/s_expression.cpp
 
 # glsl_compiler
 
diff --git a/src/glsl/glsl_lexer.ll b/src/glsl/glsl_lexer.ll
index e66a935..ad6d32f 100644
--- a/src/glsl/glsl_lexer.ll
+++ b/src/glsl/glsl_lexer.ll
@@ -23,7 +23,7 @@
  */
 #include <ctype.h>
 #include <limits.h>
-#include "strtod.h"
+#include "util/strtod.h"
 #include "ast.h"
 #include "glsl_parser_extras.h"
 #include "glsl_parser.h"
@@ -451,23 +451,23 @@ layout		{
 			}
 
 [0-9]+\.[0-9]+([eE][+-]?[0-9]+)?[fF]?	{
-			    yylval->real = glsl_strtof(yytext, NULL);
+			    yylval->real = _mesa_strtof(yytext, NULL);
 			    return FLOATCONSTANT;
 			}
 \.[0-9]+([eE][+-]?[0-9]+)?[fF]?		{
-			    yylval->real = glsl_strtof(yytext, NULL);
+			    yylval->real = _mesa_strtof(yytext, NULL);
 			    return FLOATCONSTANT;
 			}
 [0-9]+\.([eE][+-]?[0-9]+)?[fF]?		{
-			    yylval->real = glsl_strtof(yytext, NULL);
+			    yylval->real = _mesa_strtof(yytext, NULL);
 			    return FLOATCONSTANT;
 			}
 [0-9]+[eE][+-]?[0-9]+[fF]?		{
-			    yylval->real = glsl_strtof(yytext, NULL);
+			    yylval->real = _mesa_strtof(yytext, NULL);
 			    return FLOATCONSTANT;
 			}
 [0-9]+[fF]		{
-			    yylval->real = glsl_strtof(yytext, NULL);
+			    yylval->real = _mesa_strtof(yytext, NULL);
 			    return FLOATCONSTANT;
 			}
 
diff --git a/src/glsl/glsl_parser_extras.cpp b/src/glsl/glsl_parser_extras.cpp
index 79f8494..27e3301 100644
--- a/src/glsl/glsl_parser_extras.cpp
+++ b/src/glsl/glsl_parser_extras.cpp
@@ -1350,9 +1350,15 @@ ast_struct_specifier::ast_struct_specifier(const char *identifier,
 					   ast_declarator_list *declarator_list)
 {
    if (identifier == NULL) {
+      static mtx_t mutex = _MTX_INITIALIZER_NP;
       static unsigned anon_count = 1;
-      identifier = ralloc_asprintf(this, "#anon_struct_%04x", anon_count);
-      anon_count++;
+      unsigned count;
+
+      mtx_lock(&mutex);
+      count = anon_count++;
+      mtx_unlock(&mutex);
+
+      identifier = ralloc_asprintf(this, "#anon_struct_%04x", count);
    }
    name = identifier;
    this->declarations.push_degenerate_list_at_head(&declarator_list->link);
diff --git a/src/glsl/glsl_types.cpp b/src/glsl/glsl_types.cpp
index c11d864..321df25 100644
--- a/src/glsl/glsl_types.cpp
+++ b/src/glsl/glsl_types.cpp
@@ -29,6 +29,7 @@ extern "C" {
 #include "program/hash_table.h"
 }
 
+mtx_t glsl_type::mutex = _MTX_INITIALIZER_NP;
 hash_table *glsl_type::array_types = NULL;
 hash_table *glsl_type::record_types = NULL;
 hash_table *glsl_type::interface_types = NULL;
@@ -53,9 +54,14 @@ glsl_type::glsl_type(GLenum gl_type,
    vector_elements(vector_elements), matrix_columns(matrix_columns),
    length(0)
 {
+   mtx_lock(&glsl_type::mutex);
+
    init_ralloc_type_ctx();
    assert(name != NULL);
    this->name = ralloc_strdup(this->mem_ctx, name);
+
+   mtx_unlock(&glsl_type::mutex);
+
    /* Neither dimension is zero or both dimensions are zero.
     */
    assert((vector_elements == 0) == (matrix_columns == 0));
@@ -71,9 +77,14 @@ glsl_type::glsl_type(GLenum gl_type, glsl_base_type base_type,
    sampler_array(array), sampler_type(type), interface_packing(0),
    length(0)
 {
+   mtx_lock(&glsl_type::mutex);
+
    init_ralloc_type_ctx();
    assert(name != NULL);
    this->name = ralloc_strdup(this->mem_ctx, name);
+
+   mtx_unlock(&glsl_type::mutex);
+
    memset(& fields, 0, sizeof(fields));
 
    if (base_type == GLSL_TYPE_SAMPLER) {
@@ -95,11 +106,14 @@ glsl_type::glsl_type(const glsl_struct_field *fields, unsigned num_fields,
 {
    unsigned int i;
 
+   mtx_lock(&glsl_type::mutex);
+
    init_ralloc_type_ctx();
    assert(name != NULL);
    this->name = ralloc_strdup(this->mem_ctx, name);
    this->fields.structure = ralloc_array(this->mem_ctx,
 					 glsl_struct_field, length);
+
    for (i = 0; i < length; i++) {
       this->fields.structure[i].type = fields[i].type;
       this->fields.structure[i].name = ralloc_strdup(this->fields.structure,
@@ -110,6 +124,8 @@ glsl_type::glsl_type(const glsl_struct_field *fields, unsigned num_fields,
       this->fields.structure[i].sample = fields[i].sample;
       this->fields.structure[i].matrix_layout = fields[i].matrix_layout;
    }
+
+   mtx_unlock(&glsl_type::mutex);
 }
 
 glsl_type::glsl_type(const glsl_struct_field *fields, unsigned num_fields,
@@ -123,6 +139,8 @@ glsl_type::glsl_type(const glsl_struct_field *fields, unsigned num_fields,
 {
    unsigned int i;
 
+   mtx_lock(&glsl_type::mutex);
+
    init_ralloc_type_ctx();
    assert(name != NULL);
    this->name = ralloc_strdup(this->mem_ctx, name);
@@ -138,6 +156,8 @@ glsl_type::glsl_type(const glsl_struct_field *fields, unsigned num_fields,
       this->fields.structure[i].sample = fields[i].sample;
       this->fields.structure[i].matrix_layout = fields[i].matrix_layout;
    }
+
+   mtx_unlock(&glsl_type::mutex);
 }
 
 
@@ -285,6 +305,8 @@ const glsl_type *glsl_type::get_scalar_type() const
 void
 _mesa_glsl_release_types(void)
 {
+   mtx_lock(&glsl_type::mutex);
+
    if (glsl_type::array_types != NULL) {
       hash_table_dtor(glsl_type::array_types);
       glsl_type::array_types = NULL;
@@ -294,6 +316,8 @@ _mesa_glsl_release_types(void)
       hash_table_dtor(glsl_type::record_types);
       glsl_type::record_types = NULL;
    }
+
+   mtx_unlock(&glsl_type::mutex);
 }
 
 
@@ -316,7 +340,10 @@ glsl_type::glsl_type(const glsl_type *array, unsigned length) :
     * NUL.
     */
    const unsigned name_length = strlen(array->name) + 10 + 3;
+
+   mtx_lock(&glsl_type::mutex);
    char *const n = (char *) ralloc_size(this->mem_ctx, name_length);
+   mtx_unlock(&glsl_type::mutex);
 
    if (length == 0)
       snprintf(n, name_length, "%s[]", array->name);
@@ -452,12 +479,6 @@ glsl_type::get_instance(unsigned base_type, unsigned rows, unsigned columns)
 const glsl_type *
 glsl_type::get_array_instance(const glsl_type *base, unsigned array_size)
 {
-
-   if (array_types == NULL) {
-      array_types = hash_table_ctor(64, hash_table_string_hash,
-				    hash_table_string_compare);
-   }
-
    /* Generate a name using the base type pointer in the key.  This is
     * done because the name of the base type may not be unique across
     * shaders.  For example, two shaders may have different record types
@@ -466,9 +487,19 @@ glsl_type::get_array_instance(const glsl_type *base, unsigned array_size)
    char key[128];
    snprintf(key, sizeof(key), "%p[%u]", (void *) base, array_size);
 
+   mtx_lock(&glsl_type::mutex);
+
+   if (array_types == NULL) {
+      array_types = hash_table_ctor(64, hash_table_string_hash,
+				    hash_table_string_compare);
+   }
+
    const glsl_type *t = (glsl_type *) hash_table_find(array_types, key);
+
    if (t == NULL) {
+      mtx_unlock(&glsl_type::mutex);
       t = new glsl_type(base, array_size);
+      mtx_lock(&glsl_type::mutex);
 
       hash_table_insert(array_types, (void *) t, ralloc_strdup(mem_ctx, key));
    }
@@ -477,6 +508,8 @@ glsl_type::get_array_instance(const glsl_type *base, unsigned array_size)
    assert(t->length == array_size);
    assert(t->fields.array == base);
 
+   mtx_unlock(&glsl_type::mutex);
+
    return t;
 }
 
@@ -575,13 +608,17 @@ glsl_type::get_record_instance(const glsl_struct_field *fields,
 {
    const glsl_type key(fields, num_fields, name);
 
+   mtx_lock(&glsl_type::mutex);
+
    if (record_types == NULL) {
       record_types = hash_table_ctor(64, record_key_hash, record_key_compare);
    }
 
    const glsl_type *t = (glsl_type *) hash_table_find(record_types, & key);
    if (t == NULL) {
+      mtx_unlock(&glsl_type::mutex);
       t = new glsl_type(fields, num_fields, name);
+      mtx_lock(&glsl_type::mutex);
 
       hash_table_insert(record_types, (void *) t, t);
    }
@@ -590,6 +627,8 @@ glsl_type::get_record_instance(const glsl_struct_field *fields,
    assert(t->length == num_fields);
    assert(strcmp(t->name, name) == 0);
 
+   mtx_unlock(&glsl_type::mutex);
+
    return t;
 }
 
@@ -602,13 +641,17 @@ glsl_type::get_interface_instance(const glsl_struct_field *fields,
 {
    const glsl_type key(fields, num_fields, packing, block_name);
 
+   mtx_lock(&glsl_type::mutex);
+
    if (interface_types == NULL) {
       interface_types = hash_table_ctor(64, record_key_hash, record_key_compare);
    }
 
    const glsl_type *t = (glsl_type *) hash_table_find(interface_types, & key);
    if (t == NULL) {
+      mtx_unlock(&glsl_type::mutex);
       t = new glsl_type(fields, num_fields, packing, block_name);
+      mtx_lock(&glsl_type::mutex);
 
       hash_table_insert(interface_types, (void *) t, t);
    }
@@ -617,6 +660,8 @@ glsl_type::get_interface_instance(const glsl_struct_field *fields,
    assert(t->length == num_fields);
    assert(strcmp(t->name, block_name) == 0);
 
+   mtx_unlock(&glsl_type::mutex);
+
    return t;
 }
 
diff --git a/src/glsl/glsl_types.h b/src/glsl/glsl_types.h
index eeb14c2..6543041 100644
--- a/src/glsl/glsl_types.h
+++ b/src/glsl/glsl_types.h
@@ -122,16 +122,18 @@ struct glsl_type {
     * easier to just ralloc_free 'mem_ctx' (or any of its ancestors). */
    static void* operator new(size_t size)
    {
-      if (glsl_type::mem_ctx == NULL) {
-	 glsl_type::mem_ctx = ralloc_context(NULL);
-	 assert(glsl_type::mem_ctx != NULL);
-      }
+      mtx_lock(&glsl_type::mutex);
+
+      /* mem_ctx should have been created by the static members */
+      assert(glsl_type::mem_ctx != NULL);
 
       void *type;
 
       type = ralloc_size(glsl_type::mem_ctx, size);
       assert(type != NULL);
 
+      mtx_unlock(&glsl_type::mutex);
+
       return type;
    }
 
@@ -139,7 +141,9 @@ struct glsl_type {
     * ralloc_free in that case. */
    static void operator delete(void *type)
    {
+      mtx_lock(&glsl_type::mutex);
       ralloc_free(type);
+      mtx_unlock(&glsl_type::mutex);
    }
 
    /**
@@ -618,6 +622,9 @@ struct glsl_type {
    bool record_compare(const glsl_type *b) const;
 
 private:
+
+   static mtx_t mutex;
+
    /**
     * ralloc context for all glsl_type allocations
     *
diff --git a/src/glsl/ir.cpp b/src/glsl/ir.cpp
index c712c6a..fe5601a 100644
--- a/src/glsl/ir.cpp
+++ b/src/glsl/ir.cpp
@@ -46,11 +46,6 @@ bool ir_rvalue::is_negative_one() const
    return false;
 }
 
-bool ir_rvalue::is_basis() const
-{
-   return false;
-}
-
 /**
  * Modify the swizzle make to move one component to another
  *
@@ -1191,49 +1186,6 @@ ir_constant::is_negative_one() const
 }
 
 bool
-ir_constant::is_basis() const
-{
-   if (!this->type->is_scalar() && !this->type->is_vector())
-      return false;
-
-   if (this->type->is_boolean())
-      return false;
-
-   unsigned ones = 0;
-   for (unsigned c = 0; c < this->type->vector_elements; c++) {
-      switch (this->type->base_type) {
-      case GLSL_TYPE_FLOAT:
-	 if (this->value.f[c] == 1.0)
-	    ones++;
-	 else if (this->value.f[c] != 0.0)
-	    return false;
-	 break;
-      case GLSL_TYPE_INT:
-	 if (this->value.i[c] == 1)
-	    ones++;
-	 else if (this->value.i[c] != 0)
-	    return false;
-	 break;
-      case GLSL_TYPE_UINT:
-	 if (int(this->value.u[c]) == 1)
-	    ones++;
-	 else if (int(this->value.u[c]) != 0)
-	    return false;
-	 break;
-      default:
-	 /* The only other base types are structures, arrays, samplers, and
-	  * booleans.  Samplers cannot be constants, and the others should
-	  * have been filtered out above.
-	  */
-	 assert(!"Should not get here.");
-	 return false;
-      }
-   }
-
-   return ones == 1;
-}
-
-bool
 ir_constant::is_uint16_constant() const
 {
    if (!type->is_integer())
diff --git a/src/glsl/ir.h b/src/glsl/ir.h
index 90c443c..a0f48b2 100644
--- a/src/glsl/ir.h
+++ b/src/glsl/ir.h
@@ -251,8 +251,7 @@ public:
     * for vector and scalar types that have all elements set to the value
     * zero (or \c false for booleans).
     *
-    * \sa ir_constant::has_value, ir_rvalue::is_one, ir_rvalue::is_negative_one,
-    *     ir_constant::is_basis
+    * \sa ir_constant::has_value, ir_rvalue::is_one, ir_rvalue::is_negative_one
     */
    virtual bool is_zero() const;
 
@@ -264,8 +263,7 @@ public:
     * for vector and scalar types that have all elements set to the value
     * one (or \c true for booleans).
     *
-    * \sa ir_constant::has_value, ir_rvalue::is_zero, ir_rvalue::is_negative_one,
-    *     ir_constant::is_basis
+    * \sa ir_constant::has_value, ir_rvalue::is_zero, ir_rvalue::is_negative_one
     */
    virtual bool is_one() const;
 
@@ -278,25 +276,10 @@ public:
     * negative one.  For boolean types, the result is always \c false.
     *
     * \sa ir_constant::has_value, ir_rvalue::is_zero, ir_rvalue::is_one
-    *     ir_constant::is_basis
     */
    virtual bool is_negative_one() const;
 
    /**
-    * Determine if an r-value is a basis vector
-    *
-    * The base implementation of this function always returns \c false.  The
-    * \c ir_constant class over-rides this function to return \c true \b only
-    * for vector and scalar types that have one element set to the value one,
-    * and the other elements set to the value zero.  For boolean types, the
-    * result is always \c false.
-    *
-    * \sa ir_constant::has_value, ir_rvalue::is_zero, ir_rvalue::is_one,
-    *     is_constant::is_negative_one
-    */
-   virtual bool is_basis() const;
-
-   /**
     * Determine if an r-value is an unsigned integer constant which can be
     * stored in 16 bits.
     *
@@ -359,6 +342,12 @@ enum ir_var_declaration_type {
     * re-declared by the shader.
     */
    ir_var_declared_implicitly,
+
+   /**
+    * Variable is implicitly generated by the compiler and should not be
+    * visible via the API.
+    */
+   ir_var_hidden,
 };
 
 /**
@@ -2257,7 +2246,7 @@ public:
     * Determine whether a constant has the same value as another constant
     *
     * \sa ir_constant::is_zero, ir_constant::is_one,
-    * ir_constant::is_negative_one, ir_constant::is_basis
+    * ir_constant::is_negative_one
     */
    bool has_value(const ir_constant *) const;
 
@@ -2270,7 +2259,6 @@ public:
    virtual bool is_zero() const;
    virtual bool is_one() const;
    virtual bool is_negative_one() const;
-   virtual bool is_basis() const;
 
    /**
     * Return true for constants that could be stored as 16-bit unsigned values.
diff --git a/src/glsl/ir_optimization.h b/src/glsl/ir_optimization.h
index e25857a..34e0b4b 100644
--- a/src/glsl/ir_optimization.h
+++ b/src/glsl/ir_optimization.h
@@ -114,6 +114,7 @@ bool lower_noise(exec_list *instructions);
 bool lower_variable_index_to_cond_assign(exec_list *instructions,
     bool lower_input, bool lower_output, bool lower_temp, bool lower_uniform);
 bool lower_quadop_vector(exec_list *instructions, bool dont_lower_swz);
+bool lower_const_arrays_to_uniforms(exec_list *instructions);
 bool lower_clip_distance(gl_shader *shader);
 void lower_output_reads(exec_list *instructions);
 bool lower_packing_builtins(exec_list *instructions, int op_mask);
diff --git a/src/glsl/ir_uniform.h b/src/glsl/ir_uniform.h
index b9ecf7c..21b5d05 100644
--- a/src/glsl/ir_uniform.h
+++ b/src/glsl/ir_uniform.h
@@ -175,6 +175,12 @@ struct gl_uniform_storage {
     * arrays this is the first element in the array.
     */
    unsigned remap_location;
+
+   /**
+    * This is a compiler-generated uniform that should not be advertised
+    * via the API.
+    */
+   bool hidden;
 };
 
 #ifdef __cplusplus
diff --git a/src/glsl/link_uniforms.cpp b/src/glsl/link_uniforms.cpp
index 400e134..de2f6c9 100644
--- a/src/glsl/link_uniforms.cpp
+++ b/src/glsl/link_uniforms.cpp
@@ -585,6 +585,8 @@ private:
       this->uniforms[id].driver_storage = NULL;
       this->uniforms[id].storage = this->values;
       this->uniforms[id].atomic_buffer_index = -1;
+      this->uniforms[id].hidden =
+         current_var->data.how_declared == ir_var_hidden;
       if (this->ubo_block_index != -1) {
 	 this->uniforms[id].block_index = this->ubo_block_index;
 
@@ -806,6 +808,50 @@ link_set_image_access_qualifiers(struct gl_shader_program *prog)
    }
 }
 
+/**
+ * Sort the array of uniform storage so that the non-hidden uniforms are first
+ *
+ * This function sorts the list "in place."  This is important because some of
+ * the storage accessible from \c uniforms has \c uniforms as its \c ralloc
+ * context.  If \c uniforms is freed, some other storage will also be freed.
+ */
+static unsigned
+move_hidden_uniforms_to_end(struct gl_shader_program *prog,
+                            struct gl_uniform_storage *uniforms,
+                            unsigned num_elements)
+{
+   struct gl_uniform_storage *sorted_uniforms =
+      ralloc_array(prog, struct gl_uniform_storage, num_elements);
+   unsigned hidden_uniforms = 0;
+   unsigned j = 0;
+
+   /* Add the non-hidden uniforms. */
+   for (unsigned i = 0; i < num_elements; i++) {
+      if (!uniforms[i].hidden)
+         sorted_uniforms[j++] = uniforms[i];
+   }
+
+   /* Add and count the hidden uniforms. */
+   for (unsigned i = 0; i < num_elements; i++) {
+      if (uniforms[i].hidden) {
+         sorted_uniforms[j++] = uniforms[i];
+         hidden_uniforms++;
+      }
+   }
+
+   assert(prog->UniformHash != NULL);
+   prog->UniformHash->clear();
+   for (unsigned i = 0; i < num_elements; i++) {
+      if (sorted_uniforms[i].name != NULL)
+         prog->UniformHash->put(i, sorted_uniforms[i].name);
+   }
+
+   memcpy(uniforms, sorted_uniforms, sizeof(uniforms[0]) * num_elements);
+   ralloc_free(sorted_uniforms);
+
+   return hidden_uniforms;
+}
+
 void
 link_assign_uniform_locations(struct gl_shader_program *prog,
                               unsigned int boolean_true)
@@ -926,6 +972,9 @@ link_assign_uniform_locations(struct gl_shader_program *prog,
              sizeof(prog->_LinkedShaders[i]->SamplerTargets));
    }
 
+   const unsigned hidden_uniforms =
+      move_hidden_uniforms_to_end(prog, uniforms, num_user_uniforms);
+
    /* Reserve all the explicit locations of the active uniforms. */
    for (unsigned i = 0; i < num_user_uniforms; i++) {
       if (uniforms[i].remap_location != UNMAPPED_UNIFORM_LOC) {
@@ -978,6 +1027,7 @@ link_assign_uniform_locations(struct gl_shader_program *prog,
 #endif
 
    prog->NumUserUniformStorage = num_user_uniforms;
+   prog->NumHiddenUniforms = hidden_uniforms;
    prog->UniformStorage = uniforms;
 
    link_set_image_access_qualifiers(prog);
diff --git a/src/glsl/linker.cpp b/src/glsl/linker.cpp
index 2d31801..bd2aa3c 100644
--- a/src/glsl/linker.cpp
+++ b/src/glsl/linker.cpp
@@ -2678,6 +2678,8 @@ link_shaders(struct gl_context *ctx, struct gl_shader_program *prog)
                                     &ctx->Const.ShaderCompilerOptions[i],
                                     ctx->Const.NativeIntegers))
 	 ;
+
+      lower_const_arrays_to_uniforms(prog->_LinkedShaders[i]->ir);
    }
 
    /* Check and validate stream emissions in geometry shaders */
diff --git a/src/glsl/loop_unroll.cpp b/src/glsl/loop_unroll.cpp
index ce795f6..635e1dd 100644
--- a/src/glsl/loop_unroll.cpp
+++ b/src/glsl/loop_unroll.cpp
@@ -64,6 +64,7 @@ class loop_unroll_count : public ir_hierarchical_visitor {
 public:
    int nodes;
    bool unsupported_variable_indexing;
+   bool array_indexed_by_induction_var_with_exact_iterations;
    /* If there are nested loops, the node count will be inaccurate. */
    bool nested_loop;
 
@@ -74,6 +75,7 @@ public:
       nodes = 0;
       nested_loop = false;
       unsupported_variable_indexing = false;
+      array_indexed_by_induction_var_with_exact_iterations = false;
 
       run(list);
    }
@@ -112,6 +114,14 @@ public:
          ir_variable *array = ir->array->variable_referenced();
          loop_variable *lv = ls->get(ir->array_index->variable_referenced());
          if (array && lv && lv->is_induction_var()) {
+            /* If an array is indexed by a loop induction variable, and the
+             * array size is exactly the number of loop iterations, this is
+             * probably a simple for-loop trying to access each element in
+             * turn; the application may expect it to be unrolled.
+             */
+            if (int(array->type->length) == ls->limiting_terminator->iterations)
+               array_indexed_by_induction_var_with_exact_iterations = true;
+
             switch (array->data.mode) {
             case ir_var_auto:
             case ir_var_temporary:
@@ -314,7 +324,8 @@ loop_unroll_visitor::visit_leave(ir_loop *ir)
    bool loop_too_large =
       count.nested_loop || count.nodes * iterations > max_iterations * 5;
 
-   if (loop_too_large && !count.unsupported_variable_indexing)
+   if (loop_too_large && !count.unsupported_variable_indexing &&
+       !count.array_indexed_by_induction_var_with_exact_iterations)
       return visit_continue;
 
    /* Note: the limiting terminator contributes 1 to ls->num_loop_jumps.
diff --git a/src/glsl/lower_const_arrays_to_uniforms.cpp b/src/glsl/lower_const_arrays_to_uniforms.cpp
new file mode 100644
index 0000000..b3c0ee2
--- /dev/null
+++ b/src/glsl/lower_const_arrays_to_uniforms.cpp
@@ -0,0 +1,102 @@
+/*
+ * Copyright © 2014 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+/**
+ * \file lower_const_arrays_to_uniforms.cpp
+ *
+ * Lower constant arrays to uniform arrays.
+ *
+ * Some driver backends (such as i965 and nouveau) don't handle constant arrays
+ * gracefully, instead treating them as ordinary writable temporary arrays.
+ * Since arrays can be large, this often means spilling them to scratch memory,
+ * which usually involves a large number of instructions.
+ *
+ * This must be called prior to link_set_uniform_initializers(); we need the
+ * linker to process our new uniform's constant initializer.
+ *
+ * This should be called after optimizations, since those can result in
+ * splitting and removing arrays that are indexed by constant expressions.
+ */
+#include "ir.h"
+#include "ir_visitor.h"
+#include "ir_rvalue_visitor.h"
+#include "glsl_types.h"
+
+namespace {
+class lower_const_array_visitor : public ir_rvalue_visitor {
+public:
+   lower_const_array_visitor(exec_list *insts)
+   {
+      instructions = insts;
+      progress = false;
+   }
+
+   bool run()
+   {
+      visit_list_elements(this, instructions);
+      return progress;
+   }
+
+   void handle_rvalue(ir_rvalue **rvalue);
+
+private:
+   exec_list *instructions;
+   bool progress;
+};
+
+void
+lower_const_array_visitor::handle_rvalue(ir_rvalue **rvalue)
+{
+   if (!*rvalue)
+      return;
+
+   ir_constant *con = (*rvalue)->as_constant();
+   if (!con || !con->type->is_array())
+      return;
+
+   void *mem_ctx = ralloc_parent(con);
+
+   ir_variable *uni =
+      new(mem_ctx) ir_variable(con->type, "constarray", ir_var_uniform);
+   uni->constant_initializer = con;
+   uni->constant_value = con;
+   uni->data.has_initializer = true;
+   uni->data.how_declared = ir_var_hidden;
+   uni->data.read_only = true;
+   /* Assume the whole thing is accessed. */
+   uni->data.max_array_access = uni->type->length - 1;
+   instructions->push_head(uni);
+
+   *rvalue = new(mem_ctx) ir_dereference_variable(uni);
+
+   progress = true;
+}
+
+} /* anonymous namespace */
+
+bool
+lower_const_arrays_to_uniforms(exec_list *instructions)
+{
+   lower_const_array_visitor v(instructions);
+   return v.run();
+}
diff --git a/src/glsl/opt_algebraic.cpp b/src/glsl/opt_algebraic.cpp
index 0cdb8ec..430f5cb 100644
--- a/src/glsl/opt_algebraic.cpp
+++ b/src/glsl/opt_algebraic.cpp
@@ -105,12 +105,6 @@ is_vec_negative_one(ir_constant *ir)
 }
 
 static inline bool
-is_vec_basis(ir_constant *ir)
-{
-   return (ir == NULL) ? false : ir->is_basis();
-}
-
-static inline bool
 is_valid_vec_const(ir_constant *ir)
 {
    if (ir == NULL)
@@ -537,21 +531,34 @@ ir_algebraic_visitor::handle_expression(ir_expression *ir)
       if (is_vec_zero(op_const[0]) || is_vec_zero(op_const[1]))
 	 return ir_constant::zero(mem_ctx, ir->type);
 
-      if (is_vec_basis(op_const[0])) {
-	 unsigned component = 0;
-	 for (unsigned c = 0; c < op_const[0]->type->vector_elements; c++) {
-	    if (op_const[0]->value.f[c] == 1.0)
-	       component = c;
-	 }
-	 return new(mem_ctx) ir_swizzle(ir->operands[1], component, 0, 0, 0, 1);
-      }
-      if (is_vec_basis(op_const[1])) {
-	 unsigned component = 0;
-	 for (unsigned c = 0; c < op_const[1]->type->vector_elements; c++) {
-	    if (op_const[1]->value.f[c] == 1.0)
-	       component = c;
-	 }
-	 return new(mem_ctx) ir_swizzle(ir->operands[0], component, 0, 0, 0, 1);
+      for (int i = 0; i < 2; i++) {
+         if (!op_const[i])
+            continue;
+
+         unsigned components[4] = { 0 }, count = 0;
+
+         for (unsigned c = 0; c < op_const[i]->type->vector_elements; c++) {
+            if (op_const[i]->value.f[c] == 0.0)
+               continue;
+
+            components[count] = c;
+            count++;
+         }
+
+         /* No channels had zero values; bail. */
+         if (count >= op_const[i]->type->vector_elements)
+            break;
+
+         ir_expression_operation op = count == 1 ?
+            ir_binop_mul : ir_binop_dot;
+
+         /* Swizzle both operands to remove the channels that were zero. */
+         return new(mem_ctx)
+            ir_expression(op, glsl_type::float_type,
+                          new(mem_ctx) ir_swizzle(ir->operands[0],
+                                                  components, count),
+                          new(mem_ctx) ir_swizzle(ir->operands[1],
+                                                  components, count));
       }
       break;
 
diff --git a/src/glsl/opt_cse.cpp b/src/glsl/opt_cse.cpp
index 9c96835..b0b67f4 100644
--- a/src/glsl/opt_cse.cpp
+++ b/src/glsl/opt_cse.cpp
@@ -194,6 +194,8 @@ is_cse_candidate_visitor::visit(ir_dereference_variable *ir)
    if (ir->var->data.read_only) {
       return visit_continue;
    } else {
+      if (debug)
+         printf("CSE: non-candidate: var %s is not read only\n", ir->var->name);
       ok = false;
       return visit_stop;
    }
@@ -220,8 +222,11 @@ is_cse_candidate(ir_rvalue *ir)
    /* Our temporary variable assignment generation isn't ready to handle
     * anything bigger than a vector.
     */
-   if (!ir->type->is_vector() && !ir->type->is_scalar())
+   if (!ir->type->is_vector() && !ir->type->is_scalar()) {
+      if (debug)
+         printf("CSE: non-candidate: not a vector/scalar\n");
       return false;
+   }
 
    /* Only handle expressions and textures currently.  We may want to extend
     * to variable-index array dereferences at some point.
@@ -231,6 +236,8 @@ is_cse_candidate(ir_rvalue *ir)
    case ir_type_texture:
       break;
    default:
+      if (debug)
+         printf("CSE: non-candidate: not an expression/texture\n");
       return false;
    }
 
diff --git a/src/glsl/s_expression.cpp b/src/glsl/s_expression.cpp
index 1a28e1d..2928a4d 100644
--- a/src/glsl/s_expression.cpp
+++ b/src/glsl/s_expression.cpp
@@ -73,7 +73,7 @@ read_atom(void *ctx, const char *&src, char *&symbol_buffer)
    } else {
       // Check if the atom is a number.
       char *float_end = NULL;
-      float f = glsl_strtof(src, &float_end);
+      float f = _mesa_strtof(src, &float_end);
       if (float_end != src) {
          char *int_end = NULL;
          int i = strtol(src, &int_end, 10);
diff --git a/src/glsl/s_expression.h b/src/glsl/s_expression.h
index 642af19..1d47535 100644
--- a/src/glsl/s_expression.h
+++ b/src/glsl/s_expression.h
@@ -27,7 +27,7 @@
 #define S_EXPRESSION_H
 
 #include "main/core.h" /* for Elements */
-#include "strtod.h"
+#include "util/strtod.h"
 #include "list.h"
 
 /* Type-safe downcasting macros (also safe to pass NULL) */
diff --git a/src/glsl/strtod.c b/src/glsl/strtod.c
deleted file mode 100644
index 5d4346b..0000000
--- a/src/glsl/strtod.c
+++ /dev/null
@@ -1,79 +0,0 @@
-/*
- * Copyright 2010 VMware, Inc.
- * All Rights Reserved.
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the
- * "Software"), to deal in the Software without restriction, including
- * without limitation the rights to use, copy, modify, merge, publish,
- * distribute, sub license, and/or sell copies of the Software, and to
- * permit persons to whom the Software is furnished to do so, subject to
- * the following conditions:
- *
- * The above copyright notice and this permission notice (including the
- * next paragraph) shall be included in all copies or substantial portions
- * of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
- * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
- * IN NO EVENT SHALL VMWARE AND/OR ITS SUPPLIERS BE LIABLE FOR
- * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
- * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
- * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- */
-
-
-#include <stdlib.h>
-
-#ifdef _GNU_SOURCE
-#include <locale.h>
-#ifdef __APPLE__
-#include <xlocale.h>
-#endif
-#endif
-
-#include "strtod.h"
-
-
-
-/**
- * Wrapper around strtod which uses the "C" locale so the decimal
- * point is always '.'
- */
-double
-glsl_strtod(const char *s, char **end)
-{
-#if defined(_GNU_SOURCE) && !defined(__CYGWIN__) && !defined(__FreeBSD__) && \
-   !defined(__HAIKU__) && !defined(__UCLIBC__)
-   static locale_t loc = NULL;
-   if (!loc) {
-      loc = newlocale(LC_CTYPE_MASK, "C", NULL);
-   }
-   return strtod_l(s, end, loc);
-#else
-   return strtod(s, end);
-#endif
-}
-
-
-/**
- * Wrapper around strtof which uses the "C" locale so the decimal
- * point is always '.'
- */
-float
-glsl_strtof(const char *s, char **end)
-{
-#if defined(_GNU_SOURCE) && !defined(__CYGWIN__) && !defined(__FreeBSD__) && \
-   !defined(__HAIKU__) && !defined(__UCLIBC__)
-   static locale_t loc = NULL;
-   if (!loc) {
-      loc = newlocale(LC_CTYPE_MASK, "C", NULL);
-   }
-   return strtof_l(s, end, loc);
-#elif _XOPEN_SOURCE >= 600 || _ISOC99_SOURCE
-   return strtof(s, end);
-#else
-   return (float) strtod(s, end);
-#endif
-}
diff --git a/src/glsl/strtod.h b/src/glsl/strtod.h
deleted file mode 100644
index ad847db..0000000
--- a/src/glsl/strtod.h
+++ /dev/null
@@ -1,46 +0,0 @@
-/*
- * Copyright 2010 VMware, Inc.
- * All Rights Reserved.
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the
- * "Software"), to deal in the Software without restriction, including
- * without limitation the rights to use, copy, modify, merge, publish,
- * distribute, sub license, and/or sell copies of the Software, and to
- * permit persons to whom the Software is furnished to do so, subject to
- * the following conditions:
- *
- * The above copyright notice and this permission notice (including the
- * next paragraph) shall be included in all copies or substantial portions
- * of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
- * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
- * IN NO EVENT SHALL VMWARE AND/OR ITS SUPPLIERS BE LIABLE FOR
- * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
- * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
- * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- */
-
-
-#ifndef STRTOD_H
-#define STRTOD_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-extern double
-glsl_strtod(const char *s, char **end);
-
-extern float
-glsl_strtof(const char *s, char **end);
-
-
-#ifdef __cplusplus
-}
-#endif
-
-
-#endif
diff --git a/src/glx/dri3_glx.c b/src/glx/dri3_glx.c
index e8e5c4a..a9ff73b 100644
--- a/src/glx/dri3_glx.c
+++ b/src/glx/dri3_glx.c
@@ -361,12 +361,34 @@ dri3_create_drawable(struct glx_screen *base, XID xDrawable,
    return &pdraw->base;
 }
 
+static void
+show_fps(struct dri3_drawable *draw, uint64_t current_ust)
+{
+   const uint64_t interval =
+      ((struct dri3_screen *) draw->base.psc)->show_fps_interval;
+
+   draw->frames++;
+
+   /* DRI3+Present together uses microseconds for UST. */
+   if (draw->previous_ust + interval * 1000000 <= current_ust) {
+      if (draw->previous_ust) {
+         fprintf(stderr, "libGL: FPS = %.1f\n",
+                 ((uint64_t) draw->frames * 1000000) /
+                 (double)(current_ust - draw->previous_ust));
+      }
+      draw->frames = 0;
+      draw->previous_ust = current_ust;
+   }
+}
+
 /*
  * Process one Present event
  */
 static void
 dri3_handle_present_event(struct dri3_drawable *priv, xcb_present_generic_event_t *ge)
 {
+   struct dri3_screen *psc = (struct dri3_screen *) priv->base.psc;
+
    switch (ge->evtype) {
    case XCB_PRESENT_CONFIGURE_NOTIFY: {
       xcb_present_configure_notify_event_t *ce = (void *) ge;
@@ -395,6 +417,9 @@ dri3_handle_present_event(struct dri3_drawable *priv, xcb_present_generic_event_
             break;
          }
          dri3_update_num_back(priv);
+
+         if (psc->show_fps_interval)
+            show_fps(priv, ce->ust);
       } else {
          priv->recv_msc_serial = ce->serial;
       }
@@ -1830,7 +1855,7 @@ dri3_create_screen(int screen, struct glx_display * priv)
    struct dri3_screen *psc;
    __GLXDRIscreen *psp;
    struct glx_config *configs = NULL, *visuals = NULL;
-   char *driverName, *deviceName;
+   char *driverName, *deviceName, *tmp;
    int i;
 
    psc = calloc(1, sizeof *psc);
@@ -1969,6 +1994,11 @@ dri3_create_screen(int screen, struct glx_display * priv)
    free(driverName);
    free(deviceName);
 
+   tmp = getenv("LIBGL_SHOW_FPS");
+   psc->show_fps_interval = tmp ? atoi(tmp) : 0;
+   if (psc->show_fps_interval < 0)
+      psc->show_fps_interval = 0;
+
    return &psc->base;
 
 handle_error:
diff --git a/src/glx/dri3_priv.h b/src/glx/dri3_priv.h
index bdfe224..8e46640 100644
--- a/src/glx/dri3_priv.h
+++ b/src/glx/dri3_priv.h
@@ -138,7 +138,7 @@ struct dri3_screen {
    int fd;
    int is_different_gpu;
 
-   Bool show_fps;
+   int show_fps_interval;
 };
 
 struct dri3_context
@@ -198,6 +198,10 @@ struct dri3_drawable {
    xcb_present_event_t eid;
    xcb_gcontext_t gc;
    xcb_special_event_t *special_event;
+
+   /* LIBGL_SHOW_FPS support */
+   uint64_t previous_ust;
+   unsigned frames;
 };
 
 
diff --git a/src/mapi/glapi/gen/ARB_clip_control.xml b/src/mapi/glapi/gen/ARB_clip_control.xml
index 2973a31..ab1a388 100644
--- a/src/mapi/glapi/gen/ARB_clip_control.xml
+++ b/src/mapi/glapi/gen/ARB_clip_control.xml
@@ -17,7 +17,7 @@
     <function name="ClipControl" offset="assign">
         <param name="origin" type="GLenum"/>
         <param name="depth" type="GLenum"/>
-        <glx rop="1340"/>
+        <!-- <glx rop="1340"/> -->
     </function>
 
 </category>
diff --git a/src/mapi/glapi/gen/KHR_context_flush_control.xml b/src/mapi/glapi/gen/KHR_context_flush_control.xml
new file mode 100644
index 0000000..bc72435
--- /dev/null
+++ b/src/mapi/glapi/gen/KHR_context_flush_control.xml
@@ -0,0 +1,11 @@
+<?xml version="1.0"?>
+<!DOCTYPE OpenGLAPI SYSTEM "gl_API.dtd">
+
+<OpenGLAPI>
+
+<category name="GL_KHR_context_flush_control" number="168">
+    <enum name="CONTEXT_RELEASE_BEHAVIOR"            value="0x82FB"/>
+    <enum name="CONTEXT_RELEASE_BEHAVIOR_FLUSH"      value="0x82FC"/>
+</category>
+
+</OpenGLAPI>
diff --git a/src/mapi/glapi/gen/Makefile.am b/src/mapi/glapi/gen/Makefile.am
index 2fbc598..72e5095 100644
--- a/src/mapi/glapi/gen/Makefile.am
+++ b/src/mapi/glapi/gen/Makefile.am
@@ -113,6 +113,7 @@ API_XML = \
 	ARB_blend_func_extended.xml \
 	ARB_clear_buffer_object.xml \
 	ARB_clear_texture.xml \
+	ARB_clip_control.xml \
 	ARB_color_buffer_float.xml \
 	ARB_compressed_texture_pixel_storage.xml \
 	ARB_compute_shader.xml \
diff --git a/src/mapi/glapi/gen/gl_API.xml b/src/mapi/glapi/gen/gl_API.xml
index 534e6a0..e1b1246 100644
--- a/src/mapi/glapi/gen/gl_API.xml
+++ b/src/mapi/glapi/gen/gl_API.xml
@@ -8379,6 +8379,8 @@
 
 <xi:include href="ARB_texture_barrier.xml" xmlns:xi="http://www.w3.org/2001/XInclude"/>
 
+<xi:include href="KHR_context_flush_control.xml" xmlns:xi="http://www.w3.org/2001/XInclude"/>
+
 <!-- Non-ARB extensions sorted by extension number. -->
 
 <category name="GL_EXT_blend_color" number="2">
diff --git a/src/mesa/Android.libmesa_dricore.mk b/src/mesa/Android.libmesa_dricore.mk
index 1e6d948..2ab593d 100644
--- a/src/mesa/Android.libmesa_dricore.mk
+++ b/src/mesa/Android.libmesa_dricore.mk
@@ -51,10 +51,16 @@ endif # MESA_ENABLE_ASM
 
 ifeq ($(ARCH_X86_HAVE_SSE4_1),true)
 LOCAL_SRC_FILES += \
-	$(SRCDIR)main/streaming-load-memcpy.c
+	$(SRCDIR)main/streaming-load-memcpy.c \
+	$(SRCDIR)main/sse_minmax.c
 LOCAL_CFLAGS := -msse4.1
 endif
 
+ifeq ($(ARCH_X86_HAVE_SSE4_1),true)
+LOCAL_CFLAGS += \
+       -DUSE_SSE41
+endif
+
 LOCAL_C_INCLUDES := \
 	$(call intermediates-dir-for STATIC_LIBRARIES,libmesa_program,,) \
 	$(MESA_TOP)/src \
diff --git a/src/mesa/Android.libmesa_st_mesa.mk b/src/mesa/Android.libmesa_st_mesa.mk
index 8b8d652..618d6bf 100644
--- a/src/mesa/Android.libmesa_st_mesa.mk
+++ b/src/mesa/Android.libmesa_st_mesa.mk
@@ -48,6 +48,11 @@ ifeq ($(TARGET_ARCH),x86)
 endif # x86
 endif # MESA_ENABLE_ASM
 
+ifeq ($(ARCH_X86_HAVE_SSE4_1),true)
+LOCAL_CFLAGS := \
+       -DUSE_SSE41
+endif
+
 LOCAL_C_INCLUDES := \
 	$(call intermediates-dir-for STATIC_LIBRARIES,libmesa_program,,) \
 	$(MESA_TOP)/src/gallium/auxiliary \
diff --git a/src/mesa/Makefile.am b/src/mesa/Makefile.am
index e71bccb..932db4f 100644
--- a/src/mesa/Makefile.am
+++ b/src/mesa/Makefile.am
@@ -151,7 +151,8 @@ libmesagallium_la_LIBADD = \
 	$(ARCH_LIBS)
 
 libmesa_sse41_la_SOURCES = \
-	main/streaming-load-memcpy.c
+	main/streaming-load-memcpy.c \
+	main/sse_minmax.c
 libmesa_sse41_la_CFLAGS = $(AM_CFLAGS) -msse4.1
 
 pkgconfigdir = $(libdir)/pkgconfig
diff --git a/src/mesa/drivers/dri/common/dri_util.c b/src/mesa/drivers/dri/common/dri_util.c
index 6c78928..02499f2 100644
--- a/src/mesa/drivers/dri/common/dri_util.c
+++ b/src/mesa/drivers/dri/common/dri_util.c
@@ -569,6 +569,12 @@ static int driUnbindContext(__DRIcontext *pcp)
     if (pcp == NULL)
 	return GL_FALSE;
 
+    /*
+    ** Call driUnbindContext before checking for valid drawables
+    ** to handle surfaceless contexts properly.
+    */
+    pcp->driScreenPriv->driver->UnbindContext(pcp);
+
     pdp = pcp->driDrawablePriv;
     prp = pcp->driReadablePriv;
 
@@ -576,8 +582,6 @@ static int driUnbindContext(__DRIcontext *pcp)
     if (!pdp && !prp)
 	return GL_TRUE;
 
-    pcp->driScreenPriv->driver->UnbindContext(pcp);
-
     assert(pdp);
     if (pdp->refcount == 0) {
 	/* ERROR!!! */
diff --git a/src/mesa/drivers/dri/i965/Makefile.sources b/src/mesa/drivers/dri/i965/Makefile.sources
index 9c006da..711aabe 100644
--- a/src/mesa/drivers/dri/i965/Makefile.sources
+++ b/src/mesa/drivers/dri/i965/Makefile.sources
@@ -50,6 +50,8 @@ i965_FILES = \
 	brw_eu_compact.c \
 	brw_eu_emit.c \
 	brw_eu_util.c \
+	brw_ff_gs.c \
+	brw_ff_gs_emit.c \
 	brw_fs.cpp \
 	brw_fs_channel_expressions.cpp \
 	brw_fs_copy_propagation.cpp \
@@ -66,7 +68,6 @@ i965_FILES = \
 	brw_fs_vector_splitting.cpp \
 	brw_fs_visitor.cpp \
 	brw_gs.c \
-	brw_gs_emit.c \
 	brw_gs_state.c \
 	brw_gs_surface_state.c \
 	brw_interpolation_map.c \
@@ -102,7 +103,6 @@ i965_FILES = \
 	brw_vec4_copy_propagation.cpp \
 	brw_vec4_cse.cpp \
 	brw_vec4_generator.cpp \
-	brw_vec4_gs.c \
 	brw_vec4_gs_visitor.cpp \
 	brw_vec4_live_variables.cpp \
 	brw_vec4_reg_allocate.cpp \
diff --git a/src/mesa/drivers/dri/i965/brw_binding_tables.c b/src/mesa/drivers/dri/i965/brw_binding_tables.c
index 709cb9c..cb50d3b 100644
--- a/src/mesa/drivers/dri/i965/brw_binding_tables.c
+++ b/src/mesa/drivers/dri/i965/brw_binding_tables.c
@@ -61,7 +61,7 @@ brw_upload_binding_table(struct brw_context *brw,
 
    if (prog_data->binding_table.size_bytes == 0) {
       /* There are no surfaces; skip making the binding table altogether. */
-      if (stage_state->bind_bo_offset == 0)
+      if (stage_state->bind_bo_offset == 0 && brw->gen < 9)
          return;
 
       stage_state->bind_bo_offset = 0;
diff --git a/src/mesa/drivers/dri/i965/brw_cfg.h b/src/mesa/drivers/dri/i965/brw_cfg.h
index c06ed61..388d29e 100644
--- a/src/mesa/drivers/dri/i965/brw_cfg.h
+++ b/src/mesa/drivers/dri/i965/brw_cfg.h
@@ -71,6 +71,12 @@ struct bblock_t {
    const bblock_t *next() const;
    bblock_t *prev();
    const bblock_t *prev() const;
+
+   bool starts_with_control_flow() const;
+   bool ends_with_control_flow() const;
+
+   backend_instruction *first_non_control_flow_inst();
+   backend_instruction *last_non_control_flow_inst();
 #endif
 
    struct exec_node link;
@@ -141,6 +147,50 @@ bblock_prev_const(const struct bblock_t *block)
    return (const struct bblock_t *)block->link.prev;
 }
 
+static inline bool
+bblock_starts_with_control_flow(const struct bblock_t *block)
+{
+   enum opcode op = bblock_start_const(block)->opcode;
+   return op == BRW_OPCODE_DO || op == BRW_OPCODE_ENDIF;
+}
+
+static inline bool
+bblock_ends_with_control_flow(const struct bblock_t *block)
+{
+   enum opcode op = bblock_end_const(block)->opcode;
+   return op == BRW_OPCODE_IF ||
+          op == BRW_OPCODE_ELSE ||
+          op == BRW_OPCODE_WHILE ||
+          op == BRW_OPCODE_BREAK ||
+          op == BRW_OPCODE_CONTINUE;
+}
+
+static inline struct backend_instruction *
+bblock_first_non_control_flow_inst(struct bblock_t *block)
+{
+   struct backend_instruction *inst = bblock_start(block);
+   if (bblock_starts_with_control_flow(block))
+#ifdef __cplusplus
+      inst = (struct backend_instruction *)inst->next;
+#else
+      inst = (struct backend_instruction *)inst->link.next;
+#endif
+   return inst;
+}
+
+static inline struct backend_instruction *
+bblock_last_non_control_flow_inst(struct bblock_t *block)
+{
+   struct backend_instruction *inst = bblock_end(block);
+   if (bblock_ends_with_control_flow(block))
+#ifdef __cplusplus
+      inst = (struct backend_instruction *)inst->prev;
+#else
+      inst = (struct backend_instruction *)inst->link.prev;
+#endif
+   return inst;
+}
+
 #ifdef __cplusplus
 inline backend_instruction *
 bblock_t::start()
@@ -189,6 +239,30 @@ bblock_t::prev() const
 {
    return bblock_prev_const(this);
 }
+
+inline bool
+bblock_t::starts_with_control_flow() const
+{
+   return bblock_starts_with_control_flow(this);
+}
+
+inline bool
+bblock_t::ends_with_control_flow() const
+{
+   return bblock_ends_with_control_flow(this);
+}
+
+inline backend_instruction *
+bblock_t::first_non_control_flow_inst()
+{
+   return bblock_first_non_control_flow_inst(this);
+}
+
+inline backend_instruction *
+bblock_t::last_non_control_flow_inst()
+{
+   return bblock_last_non_control_flow_inst(this);
+}
 #endif
 
 struct cfg_t {
diff --git a/src/mesa/drivers/dri/i965/brw_clear.c b/src/mesa/drivers/dri/i965/brw_clear.c
index 0e5fef5..1231420 100644
--- a/src/mesa/drivers/dri/i965/brw_clear.c
+++ b/src/mesa/drivers/dri/i965/brw_clear.c
@@ -242,7 +242,7 @@ brw_clear(struct gl_context *ctx, GLbitfield mask)
    }
 
    /* Clear color buffers with fast clear or at least rep16 writes. */
-   if (brw->gen >= 6 && mask & BUFFER_BITS_COLOR) {
+   if (brw->gen >= 6 && brw->gen < 9 && (mask & BUFFER_BITS_COLOR)) {
       if (brw_meta_fast_clear(brw, fb, mask, partial_clear)) {
          debug_mask("blorp color", mask & BUFFER_BITS_COLOR);
          mask &= ~BUFFER_BITS_COLOR;
diff --git a/src/mesa/drivers/dri/i965/brw_context.h b/src/mesa/drivers/dri/i965/brw_context.h
index eb37e75..656cbe8 100644
--- a/src/mesa/drivers/dri/i965/brw_context.h
+++ b/src/mesa/drivers/dri/i965/brw_context.h
@@ -1092,6 +1092,9 @@ struct brw_context
    /* Whether the last depth/stencil packets were both NULL. */
    bool no_depth_or_stencil;
 
+   /* The last PMA stall bits programmed. */
+   uint32_t pma_stall_bits;
+
    struct {
       /** Does the current draw use the index buffer? */
       bool indexed;
diff --git a/src/mesa/drivers/dri/i965/brw_defines.h b/src/mesa/drivers/dri/i965/brw_defines.h
index ab45d3d..ee3d871 100644
--- a/src/mesa/drivers/dri/i965/brw_defines.h
+++ b/src/mesa/drivers/dri/i965/brw_defines.h
@@ -744,17 +744,21 @@ enum PACKED brw_conditional_mod {
 #define BRW_DEPENDENCY_NOTCHECKED     2
 #define BRW_DEPENDENCY_DISABLE        3
 
-#define BRW_EXECUTE_1     0
-#define BRW_EXECUTE_2     1
-#define BRW_EXECUTE_4     2
-#define BRW_EXECUTE_8     3
-#define BRW_EXECUTE_16    4
-#define BRW_EXECUTE_32    5
-
-#define BRW_HORIZONTAL_STRIDE_0   0
-#define BRW_HORIZONTAL_STRIDE_1   1
-#define BRW_HORIZONTAL_STRIDE_2   2
-#define BRW_HORIZONTAL_STRIDE_4   3
+enum PACKED brw_execution_size {
+   BRW_EXECUTE_1  = 0,
+   BRW_EXECUTE_2  = 1,
+   BRW_EXECUTE_4  = 2,
+   BRW_EXECUTE_8  = 3,
+   BRW_EXECUTE_16 = 4,
+   BRW_EXECUTE_32 = 5,
+};
+
+enum PACKED brw_horizontal_stride {
+   BRW_HORIZONTAL_STRIDE_0 = 0,
+   BRW_HORIZONTAL_STRIDE_1 = 1,
+   BRW_HORIZONTAL_STRIDE_2 = 2,
+   BRW_HORIZONTAL_STRIDE_4 = 3,
+};
 
 #define BRW_INSTRUCTION_NORMAL    0
 #define BRW_INSTRUCTION_SATURATE  1
@@ -1248,23 +1252,24 @@ enum PACKED brw_predicate {
 #define BRW_THREAD_ATOMIC     1
 #define BRW_THREAD_SWITCH     2
 
-#define BRW_VERTICAL_STRIDE_0                 0
-#define BRW_VERTICAL_STRIDE_1                 1
-#define BRW_VERTICAL_STRIDE_2                 2
-#define BRW_VERTICAL_STRIDE_4                 3
-#define BRW_VERTICAL_STRIDE_8                 4
-#define BRW_VERTICAL_STRIDE_16                5
-#define BRW_VERTICAL_STRIDE_32                6
-#define BRW_VERTICAL_STRIDE_64                7
-#define BRW_VERTICAL_STRIDE_128               8
-#define BRW_VERTICAL_STRIDE_256               9
-#define BRW_VERTICAL_STRIDE_ONE_DIMENSIONAL   0xF
-
-#define BRW_WIDTH_1       0
-#define BRW_WIDTH_2       1
-#define BRW_WIDTH_4       2
-#define BRW_WIDTH_8       3
-#define BRW_WIDTH_16      4
+enum PACKED brw_vertical_stride {
+   BRW_VERTICAL_STRIDE_0               = 0,
+   BRW_VERTICAL_STRIDE_1               = 1,
+   BRW_VERTICAL_STRIDE_2               = 2,
+   BRW_VERTICAL_STRIDE_4               = 3,
+   BRW_VERTICAL_STRIDE_8               = 4,
+   BRW_VERTICAL_STRIDE_16              = 5,
+   BRW_VERTICAL_STRIDE_32              = 6,
+   BRW_VERTICAL_STRIDE_ONE_DIMENSIONAL = 0xF,
+};
+
+enum PACKED brw_width {
+   BRW_WIDTH_1  = 0,
+   BRW_WIDTH_2  = 1,
+   BRW_WIDTH_4  = 2,
+   BRW_WIDTH_8  = 3,
+   BRW_WIDTH_16 = 4,
+};
 
 #define BRW_STATELESS_BUFFER_BOUNDARY_1K      0
 #define BRW_STATELESS_BUFFER_BOUNDARY_2K      1
@@ -1904,10 +1909,17 @@ enum brw_message_target {
 /* DW12: attr 0-7 wrap shortest enables */
 /* DW13: attr 8-16 wrap shortest enables */
 
+/* DW4-5: Attribute active components (gen9) */
+#define GEN9_SBE_ACTIVE_COMPONENT_NONE			0
+#define GEN9_SBE_ACTIVE_COMPONENT_XY			1
+#define GEN9_SBE_ACTIVE_COMPONENT_XYZ			2
+#define GEN9_SBE_ACTIVE_COMPONENT_XYZW			3
+
 #define _3DSTATE_SBE_SWIZ                       0x7851 /* GEN8+ */
 
 #define _3DSTATE_RASTER                         0x7850 /* GEN8+ */
 /* DW1 */
+# define GEN9_RASTER_VIEWPORT_Z_FAR_CLIP_TEST_ENABLE    (1 << 26)
 # define GEN8_RASTER_FRONT_WINDING_CCW                  (1 << 21)
 # define GEN8_RASTER_CULL_BOTH                          (0 << 16)
 # define GEN8_RASTER_CULL_NONE                          (1 << 16)
@@ -1918,6 +1930,7 @@ enum brw_message_target {
 # define GEN8_RASTER_LINE_AA_ENABLE                     (1 << 2)
 # define GEN8_RASTER_SCISSOR_ENABLE                     (1 << 1)
 # define GEN8_RASTER_VIEWPORT_Z_CLIP_TEST_ENABLE        (1 << 0)
+# define GEN9_RASTER_VIEWPORT_Z_NEAR_CLIP_TEST_ENABLE   (1 << 0)
 
 /* Gen8 BLEND_STATE */
 /* DW0 */
@@ -2028,6 +2041,11 @@ enum brw_message_target {
 # define GEN8_WM_DS_BF_STENCIL_TEST_MASK_SHIFT          8
 # define GEN8_WM_DS_BF_STENCIL_WRITE_MASK_MASK          INTEL_MASK(7, 0)
 # define GEN8_WM_DS_BF_STENCIL_WRITE_MASK_SHIFT         0
+/* DW3 */
+# define GEN9_WM_DS_STENCIL_REF_MASK                    INTEL_MASK(15, 8)
+# define GEN9_WM_DS_STENCIL_REF_SHIFT                   8
+# define GEN9_WM_DS_BF_STENCIL_REF_MASK                 INTEL_MASK(7, 0)
+# define GEN9_WM_DS_BF_STENCIL_REF_SHIFT                0
 
 #define _3DSTATE_PS_EXTRA                       0x784F /* GEN8+ */
 /* DW1 */
@@ -2394,4 +2412,11 @@ enum brw_wm_barycentric_interp_mode {
 #define BDW_MOCS_WT  0x58
 #define BDW_MOCS_PTE 0x18
 
+/* Skylake: MOCS is now an index into an array of 64 different configurable
+ * cache settings.  We still use only either write-back or write-through; and
+ * rely on the documented default values.
+ */
+#define SKL_MOCS_WB 9
+#define SKL_MOCS_WT 5
+
 #endif
diff --git a/src/mesa/drivers/dri/i965/brw_device_info.c b/src/mesa/drivers/dri/i965/brw_device_info.c
index 18e4c80..35ca125 100644
--- a/src/mesa/drivers/dri/i965/brw_device_info.c
+++ b/src/mesa/drivers/dri/i965/brw_device_info.c
@@ -240,8 +240,8 @@ static const struct brw_device_info brw_device_info_bdw_gt3 = {
 static const struct brw_device_info brw_device_info_chv = {
    GEN8_FEATURES, .is_cherryview = 1, .gt = 1,
    .has_llc = false,
-   .max_vs_threads = 70,
-   .max_gs_threads = 70,
+   .max_vs_threads = 80,
+   .max_gs_threads = 80,
    .max_wm_threads = 102,
    .urb = {
       .size = 128,
diff --git a/src/mesa/drivers/dri/i965/brw_eu_compact.c b/src/mesa/drivers/dri/i965/brw_eu_compact.c
index 048f430..7117890 100644
--- a/src/mesa/drivers/dri/i965/brw_eu_compact.c
+++ b/src/mesa/drivers/dri/i965/brw_eu_compact.c
@@ -795,7 +795,7 @@ set_3src_control_index(struct brw_context *brw, brw_compact_inst *dst, brw_inst
       (brw_inst_bits(src, 34, 32) << 21) | /*  3b */
       (brw_inst_bits(src, 28,  8));        /* 21b */
 
-   if (brw->is_cherryview)
+   if (brw->gen >= 9 || brw->is_cherryview)
       uncompacted |= brw_inst_bits(src, 36, 35) << 24; /* 2b */
 
    for (int i = 0; i < ARRAY_SIZE(gen8_3src_control_index_table); i++) {
@@ -820,7 +820,7 @@ set_3src_source_index(struct brw_context *brw, brw_compact_inst *dst, brw_inst *
       (brw_inst_bits(src,  72,  65) << 19) | /*  8b */
       (brw_inst_bits(src,  55,  37));        /* 19b */
 
-   if (brw->is_cherryview) {
+   if (brw->gen >= 9 || brw->is_cherryview) {
       uncompacted |=
          (brw_inst_bits(src, 126, 125) << 47) | /* 2b */
          (brw_inst_bits(src, 105, 104) << 45) | /* 2b */
@@ -1057,7 +1057,7 @@ set_uncompacted_3src_control_index(struct brw_context *brw, brw_inst *dst,
    brw_inst_set_bits(dst, 34, 32, (uncompacted >> 21) & 0x7);
    brw_inst_set_bits(dst, 28,  8, (uncompacted >>  0) & 0x1fffff);
 
-   if (brw->is_cherryview)
+   if (brw->gen >= 9 || brw->is_cherryview)
       brw_inst_set_bits(dst, 36, 35, (uncompacted >> 24) & 0x3);
 }
 
@@ -1076,7 +1076,7 @@ set_uncompacted_3src_source_index(struct brw_context *brw, brw_inst *dst,
    brw_inst_set_bits(dst,  72,  65, (uncompacted >> 19) & 0xff);
    brw_inst_set_bits(dst,  55,  37, (uncompacted >>  0) & 0x7ffff);
 
-   if (brw->is_cherryview) {
+   if (brw->gen >= 9 || brw->is_cherryview) {
       brw_inst_set_bits(dst, 126, 125, (uncompacted >> 47) & 0x3);
       brw_inst_set_bits(dst, 105, 104, (uncompacted >> 45) & 0x3);
       brw_inst_set_bits(dst,  84,  84, (uncompacted >> 44) & 0x1);
@@ -1265,6 +1265,7 @@ brw_init_compaction_tables(struct brw_context *brw)
    assert(gen8_src_index_table[ARRAY_SIZE(gen8_src_index_table) - 1] != 0);
 
    switch (brw->gen) {
+   case 9:
    case 8:
       control_index_table = gen8_control_index_table;
       datatype_table = gen8_datatype_table;
@@ -1311,12 +1312,6 @@ brw_compact_instructions(struct brw_compile *p, int start_offset,
     */
    int old_ip[(p->next_insn_offset - start_offset) / sizeof(brw_compact_inst)];
 
-   /* FIXME: Mark reported that SNB GT2 (GT1 appears fine) is hanging after
-    * commit a36631b74.
-    */
-   if (brw->gen == 6)
-      return;
-
    if (brw->gen == 4 && !brw->is_g4x)
       return;
 
diff --git a/src/mesa/drivers/dri/i965/brw_eu_emit.c b/src/mesa/drivers/dri/i965/brw_eu_emit.c
index 92f19e2..c475393 100644
--- a/src/mesa/drivers/dri/i965/brw_eu_emit.c
+++ b/src/mesa/drivers/dri/i965/brw_eu_emit.c
@@ -227,7 +227,7 @@ static void
 validate_reg(const struct brw_context *brw, brw_inst *inst, struct brw_reg reg)
 {
    int hstride_for_reg[] = {0, 1, 2, 4};
-   int vstride_for_reg[] = {0, 1, 2, 4, 8, 16, 32, 64, 128, 256};
+   int vstride_for_reg[] = {0, 1, 2, 4, 8, 16, 32};
    int width_for_reg[] = {1, 2, 4, 8, 16};
    int execsize_for_reg[] = {1, 2, 4, 8, 16};
    int width, hstride, vstride, execsize;
@@ -2099,7 +2099,18 @@ brw_oword_block_read_scratch(struct brw_compile *p,
    if (brw->gen >= 6)
       offset /= 16;
 
-   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);
+   if (p->brw->gen >= 7) {
+      /* On gen 7 and above, we no longer have message registers and we can
+       * send from any register we want.  By using the destination register
+       * for the message, we guarantee that the implied message write won't
+       * accidentally overwrite anything.  This has been a problem because
+       * the MRF registers and source for the final FB write are both fixed
+       * and may overlap.
+       */
+      mrf = retype(dest, BRW_REGISTER_TYPE_UD);
+   } else {
+      mrf = retype(mrf, BRW_REGISTER_TYPE_UD);
+   }
    dest = retype(dest, BRW_REGISTER_TYPE_UW);
 
    if (num_regs == 1) {
@@ -2118,11 +2129,7 @@ brw_oword_block_read_scratch(struct brw_compile *p,
       brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));
 
       /* set message header global offset field (reg 0, element 2) */
-      brw_MOV(p,
-	      retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
-				  mrf.nr,
-				  2), BRW_REGISTER_TYPE_UD),
-	      brw_imm_ud(offset));
+      brw_MOV(p, get_element_ud(mrf, 2), brw_imm_ud(offset));
 
       brw_pop_insn_state(p);
    }
@@ -2402,7 +2409,7 @@ void brw_adjust_sampler_state_pointer(struct brw_compile *p,
 
       struct brw_reg temp = vec1(retype(scratch, BRW_REGISTER_TYPE_UD));
 
-      brw_AND(p, temp, sampler_index, brw_imm_ud(0x0f0));
+      brw_AND(p, temp, get_element_ud(sampler_index, 0), brw_imm_ud(0x0f0));
       brw_SHL(p, temp, temp, brw_imm_ud(4));
       brw_ADD(p,
               get_element_ud(header, 3),
diff --git a/src/mesa/drivers/dri/i965/brw_ff_gs.c b/src/mesa/drivers/dri/i965/brw_ff_gs.c
new file mode 100644
index 0000000..6ca9e7f
--- /dev/null
+++ b/src/mesa/drivers/dri/i965/brw_ff_gs.c
@@ -0,0 +1,259 @@
+/*
+ Copyright (C) Intel Corp.  2006.  All Rights Reserved.
+ Intel funded Tungsten Graphics to
+ develop this 3D driver.
+
+ Permission is hereby granted, free of charge, to any person obtaining
+ a copy of this software and associated documentation files (the
+ "Software"), to deal in the Software without restriction, including
+ without limitation the rights to use, copy, modify, merge, publish,
+ distribute, sublicense, and/or sell copies of the Software, and to
+ permit persons to whom the Software is furnished to do so, subject to
+ the following conditions:
+
+ The above copyright notice and this permission notice (including the
+ next paragraph) shall be included in all copies or substantial
+ portions of the Software.
+
+ THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+ **********************************************************************/
+ /*
+  * Authors:
+  *   Keith Whitwell <keithw@vmware.com>
+  */
+
+#include "main/glheader.h"
+#include "main/macros.h"
+#include "main/enums.h"
+#include "main/transformfeedback.h"
+
+#include "intel_batchbuffer.h"
+
+#include "brw_defines.h"
+#include "brw_context.h"
+#include "brw_eu.h"
+#include "brw_util.h"
+#include "brw_state.h"
+#include "brw_ff_gs.h"
+
+#include "util/ralloc.h"
+
+static void compile_ff_gs_prog(struct brw_context *brw,
+                               struct brw_ff_gs_prog_key *key)
+{
+   struct brw_ff_gs_compile c;
+   const GLuint *program;
+   void *mem_ctx;
+   GLuint program_size;
+
+   memset(&c, 0, sizeof(c));
+
+   c.key = *key;
+   c.vue_map = brw->vs.prog_data->base.vue_map;
+   c.nr_regs = (c.vue_map.num_slots + 1)/2;
+
+   mem_ctx = ralloc_context(NULL);
+
+   /* Begin the compilation:
+    */
+   brw_init_compile(brw, &c.func, mem_ctx);
+
+   c.func.single_program_flow = 1;
+
+   /* For some reason the thread is spawned with only 4 channels
+    * unmasked.
+    */
+   brw_set_default_mask_control(&c.func, BRW_MASK_DISABLE);
+
+   if (brw->gen >= 6) {
+      unsigned num_verts;
+      bool check_edge_flag;
+      /* On Sandybridge, we use the GS for implementing transform feedback
+       * (called "Stream Out" in the PRM).
+       */
+      switch (key->primitive) {
+      case _3DPRIM_POINTLIST:
+         num_verts = 1;
+         check_edge_flag = false;
+	 break;
+      case _3DPRIM_LINELIST:
+      case _3DPRIM_LINESTRIP:
+      case _3DPRIM_LINELOOP:
+         num_verts = 2;
+         check_edge_flag = false;
+	 break;
+      case _3DPRIM_TRILIST:
+      case _3DPRIM_TRIFAN:
+      case _3DPRIM_TRISTRIP:
+      case _3DPRIM_RECTLIST:
+	 num_verts = 3;
+         check_edge_flag = false;
+         break;
+      case _3DPRIM_QUADLIST:
+      case _3DPRIM_QUADSTRIP:
+      case _3DPRIM_POLYGON:
+         num_verts = 3;
+         check_edge_flag = true;
+         break;
+      default:
+	 unreachable("Unexpected primitive type in Gen6 SOL program.");
+      }
+      gen6_sol_program(&c, key, num_verts, check_edge_flag);
+   } else {
+      /* On Gen4-5, we use the GS to decompose certain types of primitives.
+       * Note that primitives which don't require a GS program have already
+       * been weeded out by now.
+       */
+      switch (key->primitive) {
+      case _3DPRIM_QUADLIST:
+	 brw_ff_gs_quads( &c, key );
+	 break;
+      case _3DPRIM_QUADSTRIP:
+	 brw_ff_gs_quad_strip( &c, key );
+	 break;
+      case _3DPRIM_LINELOOP:
+	 brw_ff_gs_lines( &c );
+	 break;
+      default:
+	 ralloc_free(mem_ctx);
+	 return;
+      }
+   }
+
+   brw_compact_instructions(&c.func, 0, 0, NULL);
+
+   /* get the program
+    */
+   program = brw_get_program(&c.func, &program_size);
+
+   if (unlikely(INTEL_DEBUG & DEBUG_GS)) {
+      fprintf(stderr, "gs:\n");
+      brw_disassemble(brw, c.func.store, 0, program_size, stderr);
+      fprintf(stderr, "\n");
+    }
+
+   brw_upload_cache(&brw->cache, BRW_FF_GS_PROG,
+		    &c.key, sizeof(c.key),
+		    program, program_size,
+		    &c.prog_data, sizeof(c.prog_data),
+		    &brw->ff_gs.prog_offset, &brw->ff_gs.prog_data);
+   ralloc_free(mem_ctx);
+}
+
+static void populate_key(struct brw_context *brw,
+                         struct brw_ff_gs_prog_key *key)
+{
+   static const unsigned swizzle_for_offset[4] = {
+      BRW_SWIZZLE4(0, 1, 2, 3),
+      BRW_SWIZZLE4(1, 2, 3, 3),
+      BRW_SWIZZLE4(2, 3, 3, 3),
+      BRW_SWIZZLE4(3, 3, 3, 3)
+   };
+
+   struct gl_context *ctx = &brw->ctx;
+
+   memset(key, 0, sizeof(*key));
+
+   /* CACHE_NEW_VS_PROG (part of VUE map) */
+   key->attrs = brw->vs.prog_data->base.vue_map.slots_valid;
+
+   /* BRW_NEW_PRIMITIVE */
+   key->primitive = brw->primitive;
+
+   /* _NEW_LIGHT */
+   key->pv_first = (ctx->Light.ProvokingVertex == GL_FIRST_VERTEX_CONVENTION);
+   if (key->primitive == _3DPRIM_QUADLIST && ctx->Light.ShadeModel != GL_FLAT) {
+      /* Provide consistent primitive order with brw_set_prim's
+       * optimization of single quads to trifans.
+       */
+      key->pv_first = true;
+   }
+
+   if (brw->gen >= 7) {
+      /* On Gen7 and later, we don't use GS (yet). */
+      key->need_gs_prog = false;
+   } else if (brw->gen == 6) {
+      /* On Gen6, GS is used for transform feedback. */
+      /* BRW_NEW_TRANSFORM_FEEDBACK */
+      if (_mesa_is_xfb_active_and_unpaused(ctx)) {
+         const struct gl_shader_program *shaderprog =
+            ctx->_Shader->CurrentProgram[MESA_SHADER_VERTEX];
+         const struct gl_transform_feedback_info *linked_xfb_info =
+            &shaderprog->LinkedTransformFeedback;
+         int i;
+
+         /* Make sure that the VUE slots won't overflow the unsigned chars in
+          * key->transform_feedback_bindings[].
+          */
+         STATIC_ASSERT(BRW_VARYING_SLOT_COUNT <= 256);
+
+         /* Make sure that we don't need more binding table entries than we've
+          * set aside for use in transform feedback.  (We shouldn't, since we
+          * set aside enough binding table entries to have one per component).
+          */
+         assert(linked_xfb_info->NumOutputs <= BRW_MAX_SOL_BINDINGS);
+
+         key->need_gs_prog = true;
+         key->num_transform_feedback_bindings = linked_xfb_info->NumOutputs;
+         for (i = 0; i < key->num_transform_feedback_bindings; ++i) {
+            key->transform_feedback_bindings[i] =
+               linked_xfb_info->Outputs[i].OutputRegister;
+            key->transform_feedback_swizzles[i] =
+               swizzle_for_offset[linked_xfb_info->Outputs[i].ComponentOffset];
+         }
+      }
+   } else {
+      /* Pre-gen6, GS is used to transform QUADLIST, QUADSTRIP, and LINELOOP
+       * into simpler primitives.
+       */
+      key->need_gs_prog = (brw->primitive == _3DPRIM_QUADLIST ||
+                           brw->primitive == _3DPRIM_QUADSTRIP ||
+                           brw->primitive == _3DPRIM_LINELOOP);
+   }
+}
+
+/* Calculate interpolants for triangle and line rasterization.
+ */
+static void
+brw_upload_ff_gs_prog(struct brw_context *brw)
+{
+   struct brw_ff_gs_prog_key key;
+   /* Populate the key:
+    */
+   populate_key(brw, &key);
+
+   if (brw->ff_gs.prog_active != key.need_gs_prog) {
+      brw->state.dirty.cache |= CACHE_NEW_FF_GS_PROG;
+      brw->ff_gs.prog_active = key.need_gs_prog;
+   }
+
+   if (brw->ff_gs.prog_active) {
+      if (!brw_search_cache(&brw->cache, BRW_FF_GS_PROG,
+			    &key, sizeof(key),
+			    &brw->ff_gs.prog_offset, &brw->ff_gs.prog_data)) {
+	 compile_ff_gs_prog( brw, &key );
+      }
+   }
+}
+
+void gen6_brw_upload_ff_gs_prog(struct brw_context *brw)
+{
+   brw_upload_ff_gs_prog(brw);
+}
+
+const struct brw_tracked_state brw_ff_gs_prog = {
+   .dirty = {
+      .mesa  = (_NEW_LIGHT),
+      .brw   = (BRW_NEW_PRIMITIVE |
+                BRW_NEW_TRANSFORM_FEEDBACK),
+      .cache = CACHE_NEW_VS_PROG
+   },
+   .emit = brw_upload_ff_gs_prog
+};
diff --git a/src/mesa/drivers/dri/i965/brw_ff_gs.h b/src/mesa/drivers/dri/i965/brw_ff_gs.h
new file mode 100644
index 0000000..a538948
--- /dev/null
+++ b/src/mesa/drivers/dri/i965/brw_ff_gs.h
@@ -0,0 +1,115 @@
+/*
+ Copyright (C) Intel Corp.  2006.  All Rights Reserved.
+ Intel funded Tungsten Graphics to
+ develop this 3D driver.
+
+ Permission is hereby granted, free of charge, to any person obtaining
+ a copy of this software and associated documentation files (the
+ "Software"), to deal in the Software without restriction, including
+ without limitation the rights to use, copy, modify, merge, publish,
+ distribute, sublicense, and/or sell copies of the Software, and to
+ permit persons to whom the Software is furnished to do so, subject to
+ the following conditions:
+
+ The above copyright notice and this permission notice (including the
+ next paragraph) shall be included in all copies or substantial
+ portions of the Software.
+
+ THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+ **********************************************************************/
+ /*
+  * Authors:
+  *   Keith Whitwell <keithw@vmware.com>
+  */
+
+
+#ifndef BRW_GS_H
+#define BRW_GS_H
+
+
+#include "brw_context.h"
+#include "brw_eu.h"
+
+#define MAX_GS_VERTS (4)	
+
+struct brw_ff_gs_prog_key {
+   GLbitfield64 attrs;
+
+   /**
+    * Hardware primitive type being drawn, e.g. _3DPRIM_TRILIST.
+    */
+   GLuint primitive:8;
+
+   GLuint pv_first:1;
+   GLuint need_gs_prog:1;
+
+   /**
+    * Number of varyings that are output to transform feedback.
+    */
+   GLuint num_transform_feedback_bindings:7; /* 0-BRW_MAX_SOL_BINDINGS */
+
+   /**
+    * Map from the index of a transform feedback binding table entry to the
+    * gl_varying_slot that should be streamed out through that binding table
+    * entry.
+    */
+   unsigned char transform_feedback_bindings[BRW_MAX_SOL_BINDINGS];
+
+   /**
+    * Map from the index of a transform feedback binding table entry to the
+    * swizzles that should be used when streaming out data through that
+    * binding table entry.
+    */
+   unsigned char transform_feedback_swizzles[BRW_MAX_SOL_BINDINGS];
+};
+
+struct brw_ff_gs_compile {
+   struct brw_compile func;
+   struct brw_ff_gs_prog_key key;
+   struct brw_ff_gs_prog_data prog_data;
+
+   struct {
+      struct brw_reg R0;
+
+      /**
+       * Register holding streamed vertex buffer pointers -- see the Sandy
+       * Bridge PRM, volume 2 part 1, section 4.4.2 (GS Thread Payload
+       * [DevSNB]).  These pointers are delivered in GRF 1.
+       */
+      struct brw_reg SVBI;
+
+      struct brw_reg vertex[MAX_GS_VERTS];
+      struct brw_reg header;
+      struct brw_reg temp;
+
+      /**
+       * Register holding destination indices for streamed buffer writes.
+       * Only used for SOL programs.
+       */
+      struct brw_reg destination_indices;
+   } reg;
+
+   /* Number of registers used to store vertex data */
+   GLuint nr_regs;
+
+   struct brw_vue_map vue_map;
+};
+
+void brw_ff_gs_quads(struct brw_ff_gs_compile *c,
+                     struct brw_ff_gs_prog_key *key);
+void brw_ff_gs_quad_strip(struct brw_ff_gs_compile *c,
+                          struct brw_ff_gs_prog_key *key);
+void brw_ff_gs_lines(struct brw_ff_gs_compile *c);
+void gen6_sol_program(struct brw_ff_gs_compile *c,
+                      struct brw_ff_gs_prog_key *key,
+                      unsigned num_verts, bool check_edge_flag);
+void gen6_brw_upload_ff_gs_prog(struct brw_context *brw);
+
+#endif
diff --git a/src/mesa/drivers/dri/i965/brw_ff_gs_emit.c b/src/mesa/drivers/dri/i965/brw_ff_gs_emit.c
new file mode 100644
index 0000000..3f31597
--- /dev/null
+++ b/src/mesa/drivers/dri/i965/brw_ff_gs_emit.c
@@ -0,0 +1,529 @@
+/*
+ Copyright (C) Intel Corp.  2006.  All Rights Reserved.
+ Intel funded Tungsten Graphics to
+ develop this 3D driver.
+
+ Permission is hereby granted, free of charge, to any person obtaining
+ a copy of this software and associated documentation files (the
+ "Software"), to deal in the Software without restriction, including
+ without limitation the rights to use, copy, modify, merge, publish,
+ distribute, sublicense, and/or sell copies of the Software, and to
+ permit persons to whom the Software is furnished to do so, subject to
+ the following conditions:
+
+ The above copyright notice and this permission notice (including the
+ next paragraph) shall be included in all copies or substantial
+ portions of the Software.
+
+ THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+ **********************************************************************/
+ /*
+  * Authors:
+  *   Keith Whitwell <keithw@vmware.com>
+  */
+
+
+#include "main/glheader.h"
+#include "main/macros.h"
+#include "main/enums.h"
+
+#include "program/program.h"
+#include "intel_batchbuffer.h"
+
+#include "brw_defines.h"
+#include "brw_context.h"
+#include "brw_eu.h"
+#include "brw_ff_gs.h"
+
+/**
+ * Allocate registers for GS.
+ *
+ * If sol_program is true, then:
+ *
+ * - The thread will be spawned with the "SVBI Payload Enable" bit set, so GRF
+ *   1 needs to be set aside to hold the streamed vertex buffer indices.
+ *
+ * - The thread will need to use the destination_indices register.
+ */
+static void brw_ff_gs_alloc_regs(struct brw_ff_gs_compile *c,
+                                 GLuint nr_verts,
+                                 bool sol_program)
+{
+   GLuint i = 0,j;
+
+   /* Register usage is static, precompute here:
+    */
+   c->reg.R0 = retype(brw_vec8_grf(i, 0), BRW_REGISTER_TYPE_UD); i++;
+
+   /* Streamed vertex buffer indices */
+   if (sol_program)
+      c->reg.SVBI = retype(brw_vec8_grf(i++, 0), BRW_REGISTER_TYPE_UD);
+
+   /* Payload vertices plus space for more generated vertices:
+    */
+   for (j = 0; j < nr_verts; j++) {
+      c->reg.vertex[j] = brw_vec4_grf(i, 0);
+      i += c->nr_regs;
+   }
+
+   c->reg.header = retype(brw_vec8_grf(i++, 0), BRW_REGISTER_TYPE_UD);
+   c->reg.temp = retype(brw_vec8_grf(i++, 0), BRW_REGISTER_TYPE_UD);
+
+   if (sol_program) {
+      c->reg.destination_indices =
+         retype(brw_vec4_grf(i++, 0), BRW_REGISTER_TYPE_UD);
+   }
+
+   c->prog_data.urb_read_length = c->nr_regs;
+   c->prog_data.total_grf = i;
+}
+
+
+/**
+ * Set up the initial value of c->reg.header register based on c->reg.R0.
+ *
+ * The following information is passed to the GS thread in R0, and needs to be
+ * included in the first URB_WRITE or FF_SYNC message sent by the GS:
+ *
+ * - DWORD 0 [31:0] handle info (Gen4 only)
+ * - DWORD 5 [7:0] FFTID
+ * - DWORD 6 [31:0] Debug info
+ * - DWORD 7 [31:0] Debug info
+ *
+ * This function sets up the above data by copying by copying the contents of
+ * R0 to the header register.
+ */
+static void brw_ff_gs_initialize_header(struct brw_ff_gs_compile *c)
+{
+   struct brw_compile *p = &c->func;
+   brw_MOV(p, c->reg.header, c->reg.R0);
+}
+
+/**
+ * Overwrite DWORD 2 of c->reg.header with the given immediate unsigned value.
+ *
+ * In URB_WRITE messages, DWORD 2 contains the fields PrimType, PrimStart,
+ * PrimEnd, Increment CL_INVOCATIONS, and SONumPrimsWritten, many of which we
+ * need to be able to update on a per-vertex basis.
+ */
+static void brw_ff_gs_overwrite_header_dw2(struct brw_ff_gs_compile *c,
+                                           unsigned dw2)
+{
+   struct brw_compile *p = &c->func;
+   brw_MOV(p, get_element_ud(c->reg.header, 2), brw_imm_ud(dw2));
+}
+
+/**
+ * Overwrite DWORD 2 of c->reg.header with the primitive type from c->reg.R0.
+ *
+ * When the thread is spawned, GRF 0 contains the primitive type in bits 4:0
+ * of DWORD 2.  URB_WRITE messages need the primitive type in bits 6:2 of
+ * DWORD 2.  So this function extracts the primitive type field, bitshifts it
+ * appropriately, and stores it in c->reg.header.
+ */
+static void brw_ff_gs_overwrite_header_dw2_from_r0(struct brw_ff_gs_compile *c)
+{
+   struct brw_compile *p = &c->func;
+   brw_AND(p, get_element_ud(c->reg.header, 2), get_element_ud(c->reg.R0, 2),
+           brw_imm_ud(0x1f));
+   brw_SHL(p, get_element_ud(c->reg.header, 2),
+           get_element_ud(c->reg.header, 2), brw_imm_ud(2));
+}
+
+/**
+ * Apply an additive offset to DWORD 2 of c->reg.header.
+ *
+ * This is used to set/unset the "PrimStart" and "PrimEnd" flags appropriately
+ * for each vertex.
+ */
+static void brw_ff_gs_offset_header_dw2(struct brw_ff_gs_compile *c,
+                                        int offset)
+{
+   struct brw_compile *p = &c->func;
+   brw_ADD(p, get_element_d(c->reg.header, 2), get_element_d(c->reg.header, 2),
+           brw_imm_d(offset));
+}
+
+
+/**
+ * Emit a vertex using the URB_WRITE message.  Use the contents of
+ * c->reg.header for the message header, and the registers starting at \c vert
+ * for the vertex data.
+ *
+ * If \c last is true, then this is the last vertex, so no further URB space
+ * should be allocated, and this message should end the thread.
+ *
+ * If \c last is false, then a new URB entry will be allocated, and its handle
+ * will be stored in DWORD 0 of c->reg.header for use in the next URB_WRITE
+ * message.
+ */
+static void brw_ff_gs_emit_vue(struct brw_ff_gs_compile *c,
+                               struct brw_reg vert,
+                               bool last)
+{
+   struct brw_compile *p = &c->func;
+   int write_offset = 0;
+   bool complete = false;
+
+   do {
+      /* We can't write more than 14 registers at a time to the URB */
+      int write_len = MIN2(c->nr_regs - write_offset, 14);
+      if (write_len == c->nr_regs - write_offset)
+         complete = true;
+
+      /* Copy the vertex from vertn into m1..mN+1:
+       */
+      brw_copy8(p, brw_message_reg(1), offset(vert, write_offset), write_len);
+
+      /* Send the vertex data to the URB.  If this is the last write for this
+       * vertex, then we mark it as complete, and either end the thread or
+       * allocate another vertex URB entry (depending whether this is the last
+       * vertex).
+       */
+      enum brw_urb_write_flags flags;
+      if (!complete)
+         flags = BRW_URB_WRITE_NO_FLAGS;
+      else if (last)
+         flags = BRW_URB_WRITE_EOT_COMPLETE;
+      else
+         flags = BRW_URB_WRITE_ALLOCATE_COMPLETE;
+      brw_urb_WRITE(p,
+                    (flags & BRW_URB_WRITE_ALLOCATE) ? c->reg.temp
+                    : retype(brw_null_reg(), BRW_REGISTER_TYPE_UD),
+                    0,
+                    c->reg.header,
+                    flags,
+                    write_len + 1, /* msg length */
+                    (flags & BRW_URB_WRITE_ALLOCATE) ? 1
+                    : 0, /* response length */
+                    write_offset,  /* urb offset */
+                    BRW_URB_SWIZZLE_NONE);
+      write_offset += write_len;
+   } while (!complete);
+
+   if (!last) {
+      brw_MOV(p, get_element_ud(c->reg.header, 0),
+              get_element_ud(c->reg.temp, 0));
+   }
+}
+
+/**
+ * Send an FF_SYNC message to ensure that all previously spawned GS threads
+ * have finished sending primitives down the pipeline, and to allocate a URB
+ * entry for the first output vertex.  Only needed on Ironlake+.
+ *
+ * This function modifies c->reg.header: in DWORD 1, it stores num_prim (which
+ * is needed by the FF_SYNC message), and in DWORD 0, it stores the handle to
+ * the allocated URB entry (which will be needed by the URB_WRITE meesage that
+ * follows).
+ */
+static void brw_ff_gs_ff_sync(struct brw_ff_gs_compile *c, int num_prim)
+{
+   struct brw_compile *p = &c->func;
+
+   brw_MOV(p, get_element_ud(c->reg.header, 1), brw_imm_ud(num_prim));
+   brw_ff_sync(p,
+               c->reg.temp,
+               0,
+               c->reg.header,
+               1, /* allocate */
+               1, /* response length */
+               0 /* eot */);
+   brw_MOV(p, get_element_ud(c->reg.header, 0),
+           get_element_ud(c->reg.temp, 0));
+}
+
+
+void
+brw_ff_gs_quads(struct brw_ff_gs_compile *c, struct brw_ff_gs_prog_key *key)
+{
+   struct brw_context *brw = c->func.brw;
+
+   brw_ff_gs_alloc_regs(c, 4, false);
+   brw_ff_gs_initialize_header(c);
+   /* Use polygons for correct edgeflag behaviour. Note that vertex 3
+    * is the PV for quads, but vertex 0 for polygons:
+    */
+   if (brw->gen == 5)
+      brw_ff_gs_ff_sync(c, 1);
+   brw_ff_gs_overwrite_header_dw2(
+      c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
+          | URB_WRITE_PRIM_START));
+   if (key->pv_first) {
+      brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
+      brw_ff_gs_overwrite_header_dw2(
+         c, _3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[1], 0);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[2], 0);
+      brw_ff_gs_overwrite_header_dw2(
+         c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
+             | URB_WRITE_PRIM_END));
+      brw_ff_gs_emit_vue(c, c->reg.vertex[3], 1);
+   }
+   else {
+      brw_ff_gs_emit_vue(c, c->reg.vertex[3], 0);
+      brw_ff_gs_overwrite_header_dw2(
+         c, _3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[1], 0);
+      brw_ff_gs_overwrite_header_dw2(
+         c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
+             | URB_WRITE_PRIM_END));
+      brw_ff_gs_emit_vue(c, c->reg.vertex[2], 1);
+   }
+}
+
+void
+brw_ff_gs_quad_strip(struct brw_ff_gs_compile *c,
+                     struct brw_ff_gs_prog_key *key)
+{
+   struct brw_context *brw = c->func.brw;
+
+   brw_ff_gs_alloc_regs(c, 4, false);
+   brw_ff_gs_initialize_header(c);
+
+   if (brw->gen == 5)
+      brw_ff_gs_ff_sync(c, 1);
+   brw_ff_gs_overwrite_header_dw2(
+      c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
+          | URB_WRITE_PRIM_START));
+   if (key->pv_first) {
+      brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
+      brw_ff_gs_overwrite_header_dw2(
+         c, _3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[1], 0);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[2], 0);
+      brw_ff_gs_overwrite_header_dw2(
+         c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
+             | URB_WRITE_PRIM_END));
+      brw_ff_gs_emit_vue(c, c->reg.vertex[3], 1);
+   }
+   else {
+      brw_ff_gs_emit_vue(c, c->reg.vertex[2], 0);
+      brw_ff_gs_overwrite_header_dw2(
+         c, _3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[3], 0);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
+      brw_ff_gs_overwrite_header_dw2(
+         c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
+             | URB_WRITE_PRIM_END));
+      brw_ff_gs_emit_vue(c, c->reg.vertex[1], 1);
+   }
+}
+
+void brw_ff_gs_lines(struct brw_ff_gs_compile *c)
+{
+   struct brw_context *brw = c->func.brw;
+
+   brw_ff_gs_alloc_regs(c, 2, false);
+   brw_ff_gs_initialize_header(c);
+
+   if (brw->gen == 5)
+      brw_ff_gs_ff_sync(c, 1);
+   brw_ff_gs_overwrite_header_dw2(
+      c, ((_3DPRIM_LINESTRIP << URB_WRITE_PRIM_TYPE_SHIFT)
+          | URB_WRITE_PRIM_START));
+   brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
+   brw_ff_gs_overwrite_header_dw2(
+      c, ((_3DPRIM_LINESTRIP << URB_WRITE_PRIM_TYPE_SHIFT)
+          | URB_WRITE_PRIM_END));
+   brw_ff_gs_emit_vue(c, c->reg.vertex[1], 1);
+}
+
+/**
+ * Generate the geometry shader program used on Gen6 to perform stream output
+ * (transform feedback).
+ */
+void
+gen6_sol_program(struct brw_ff_gs_compile *c, struct brw_ff_gs_prog_key *key,
+	         unsigned num_verts, bool check_edge_flags)
+{
+   struct brw_compile *p = &c->func;
+   struct brw_context *brw = p->brw;
+   brw_inst *inst;
+   c->prog_data.svbi_postincrement_value = num_verts;
+
+   brw_ff_gs_alloc_regs(c, num_verts, true);
+   brw_ff_gs_initialize_header(c);
+
+   if (key->num_transform_feedback_bindings > 0) {
+      unsigned vertex, binding;
+      struct brw_reg destination_indices_uw =
+         vec8(retype(c->reg.destination_indices, BRW_REGISTER_TYPE_UW));
+
+      /* Note: since we use the binding table to keep track of buffer offsets
+       * and stride, the GS doesn't need to keep track of a separate pointer
+       * into each buffer; it uses a single pointer which increments by 1 for
+       * each vertex.  So we use SVBI0 for this pointer, regardless of whether
+       * transform feedback is in interleaved or separate attribs mode.
+       *
+       * Make sure that the buffers have enough room for all the vertices.
+       */
+      brw_ADD(p, get_element_ud(c->reg.temp, 0),
+	         get_element_ud(c->reg.SVBI, 0), brw_imm_ud(num_verts));
+      brw_CMP(p, vec1(brw_null_reg()), BRW_CONDITIONAL_LE,
+	         get_element_ud(c->reg.temp, 0),
+	         get_element_ud(c->reg.SVBI, 4));
+      brw_IF(p, BRW_EXECUTE_1);
+
+      /* Compute the destination indices to write to.  Usually we use SVBI[0]
+       * + (0, 1, 2).  However, for odd-numbered triangles in tristrips, the
+       * vertices come down the pipeline in reversed winding order, so we need
+       * to flip the order when writing to the transform feedback buffer.  To
+       * ensure that flatshading accuracy is preserved, we need to write them
+       * in order SVBI[0] + (0, 2, 1) if we're using the first provoking
+       * vertex convention, and in order SVBI[0] + (1, 0, 2) if we're using
+       * the last provoking vertex convention.
+       *
+       * Note: since brw_imm_v can only be used in instructions in
+       * packed-word execution mode, and SVBI is a double-word, we need to
+       * first move the appropriate immediate constant ((0, 1, 2), (0, 2, 1),
+       * or (1, 0, 2)) to the destination_indices register, and then add SVBI
+       * using a separate instruction.  Also, since the immediate constant is
+       * expressed as packed words, and we need to load double-words into
+       * destination_indices, we need to intersperse zeros to fill the upper
+       * halves of each double-word.
+       */
+      brw_MOV(p, destination_indices_uw,
+              brw_imm_v(0x00020100)); /* (0, 1, 2) */
+      if (num_verts == 3) {
+         /* Get primitive type into temp register. */
+         brw_AND(p, get_element_ud(c->reg.temp, 0),
+                 get_element_ud(c->reg.R0, 2), brw_imm_ud(0x1f));
+
+         /* Test if primitive type is TRISTRIP_REVERSE.  We need to do this as
+          * an 8-wide comparison so that the conditional MOV that follows
+          * moves all 8 words correctly.
+          */
+         brw_CMP(p, vec8(brw_null_reg()), BRW_CONDITIONAL_EQ,
+                 get_element_ud(c->reg.temp, 0),
+                 brw_imm_ud(_3DPRIM_TRISTRIP_REVERSE));
+
+         /* If so, then overwrite destination_indices_uw with the appropriate
+          * reordering.
+          */
+         inst = brw_MOV(p, destination_indices_uw,
+                        brw_imm_v(key->pv_first ? 0x00010200    /* (0, 2, 1) */
+                                                : 0x00020001)); /* (1, 0, 2) */
+         brw_inst_set_pred_control(brw, inst, BRW_PREDICATE_NORMAL);
+      }
+      brw_ADD(p, c->reg.destination_indices,
+              c->reg.destination_indices, get_element_ud(c->reg.SVBI, 0));
+
+      /* For each vertex, generate code to output each varying using the
+       * appropriate binding table entry.
+       */
+      for (vertex = 0; vertex < num_verts; ++vertex) {
+         /* Set up the correct destination index for this vertex */
+         brw_MOV(p, get_element_ud(c->reg.header, 5),
+                 get_element_ud(c->reg.destination_indices, vertex));
+
+         for (binding = 0; binding < key->num_transform_feedback_bindings;
+              ++binding) {
+            unsigned char varying =
+               key->transform_feedback_bindings[binding];
+            unsigned char slot = c->vue_map.varying_to_slot[varying];
+            /* From the Sandybridge PRM, Volume 2, Part 1, Section 4.5.1:
+             *
+             *   "Prior to End of Thread with a URB_WRITE, the kernel must
+             *   ensure that all writes are complete by sending the final
+             *   write as a committed write."
+             */
+            bool final_write =
+               binding == key->num_transform_feedback_bindings - 1 &&
+               vertex == num_verts - 1;
+            struct brw_reg vertex_slot = c->reg.vertex[vertex];
+            vertex_slot.nr += slot / 2;
+            vertex_slot.subnr = (slot % 2) * 16;
+            /* gl_PointSize is stored in VARYING_SLOT_PSIZ.w. */
+            vertex_slot.dw1.bits.swizzle = varying == VARYING_SLOT_PSIZ
+               ? BRW_SWIZZLE_WWWW : key->transform_feedback_swizzles[binding];
+            brw_set_default_access_mode(p, BRW_ALIGN_16);
+            brw_MOV(p, stride(c->reg.header, 4, 4, 1),
+                    retype(vertex_slot, BRW_REGISTER_TYPE_UD));
+            brw_set_default_access_mode(p, BRW_ALIGN_1);
+            brw_svb_write(p,
+                          final_write ? c->reg.temp : brw_null_reg(), /* dest */
+                          1, /* msg_reg_nr */
+                          c->reg.header, /* src0 */
+                          SURF_INDEX_GEN6_SOL_BINDING(binding), /* binding_table_index */
+                          final_write); /* send_commit_msg */
+         }
+      }
+      brw_ENDIF(p);
+
+      /* Now, reinitialize the header register from R0 to restore the parts of
+       * the register that we overwrote while streaming out transform feedback
+       * data.
+       */
+      brw_ff_gs_initialize_header(c);
+
+      /* Finally, wait for the write commit to occur so that we can proceed to
+       * other things safely.
+       *
+       * From the Sandybridge PRM, Volume 4, Part 1, Section 3.3:
+       *
+       *   The write commit does not modify the destination register, but
+       *   merely clears the dependency associated with the destination
+       *   register. Thus, a simple “mov” instruction using the register as a
+       *   source is sufficient to wait for the write commit to occur.
+       */
+      brw_MOV(p, c->reg.temp, c->reg.temp);
+   }
+
+   brw_ff_gs_ff_sync(c, 1);
+
+   brw_ff_gs_overwrite_header_dw2_from_r0(c);
+   switch (num_verts) {
+   case 1:
+      brw_ff_gs_offset_header_dw2(c,
+                                  URB_WRITE_PRIM_START | URB_WRITE_PRIM_END);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[0], true);
+      break;
+   case 2:
+      brw_ff_gs_offset_header_dw2(c, URB_WRITE_PRIM_START);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[0], false);
+      brw_ff_gs_offset_header_dw2(c,
+                                  URB_WRITE_PRIM_END - URB_WRITE_PRIM_START);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[1], true);
+      break;
+   case 3:
+      if (check_edge_flags) {
+         /* Only emit vertices 0 and 1 if this is the first triangle of the
+          * polygon.  Otherwise they are redundant.
+          */
+         brw_AND(p, retype(brw_null_reg(), BRW_REGISTER_TYPE_UD),
+                 get_element_ud(c->reg.R0, 2),
+                 brw_imm_ud(BRW_GS_EDGE_INDICATOR_0));
+         brw_inst_set_cond_modifier(brw, brw_last_inst, BRW_CONDITIONAL_NZ);
+         brw_IF(p, BRW_EXECUTE_1);
+      }
+      brw_ff_gs_offset_header_dw2(c, URB_WRITE_PRIM_START);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[0], false);
+      brw_ff_gs_offset_header_dw2(c, -URB_WRITE_PRIM_START);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[1], false);
+      if (check_edge_flags) {
+         brw_ENDIF(p);
+         /* Only emit vertex 2 in PRIM_END mode if this is the last triangle
+          * of the polygon.  Otherwise leave the primitive incomplete because
+          * there are more polygon vertices coming.
+          */
+         brw_AND(p, retype(brw_null_reg(), BRW_REGISTER_TYPE_UD),
+                 get_element_ud(c->reg.R0, 2),
+                 brw_imm_ud(BRW_GS_EDGE_INDICATOR_1));
+         brw_inst_set_cond_modifier(brw, brw_last_inst, BRW_CONDITIONAL_NZ);
+         brw_set_default_predicate_control(p, BRW_PREDICATE_NORMAL);
+      }
+      brw_ff_gs_offset_header_dw2(c, URB_WRITE_PRIM_END);
+      brw_set_default_predicate_control(p, BRW_PREDICATE_NONE);
+      brw_ff_gs_emit_vue(c, c->reg.vertex[2], true);
+      break;
+   }
+}
diff --git a/src/mesa/drivers/dri/i965/brw_fs.cpp b/src/mesa/drivers/dri/i965/brw_fs.cpp
index aa1d8d2..39c6231 100644
--- a/src/mesa/drivers/dri/i965/brw_fs.cpp
+++ b/src/mesa/drivers/dri/i965/brw_fs.cpp
@@ -679,19 +679,18 @@ fs_visitor::get_timestamp()
 {
    assert(brw->gen >= 7);
 
-   fs_reg ts = fs_reg(retype(brw_vec1_reg(BRW_ARCHITECTURE_REGISTER_FILE,
+   fs_reg ts = fs_reg(retype(brw_vec4_reg(BRW_ARCHITECTURE_REGISTER_FILE,
                                           BRW_ARF_TIMESTAMP,
                                           0),
                              BRW_REGISTER_TYPE_UD));
 
-   fs_reg dst = fs_reg(this, glsl_type::uint_type);
+   fs_reg dst = fs_reg(GRF, virtual_grf_alloc(1), BRW_REGISTER_TYPE_UD, 4);
 
    fs_inst *mov = emit(MOV(dst, ts));
-   /* We want to read the 3 fields we care about (mostly field 0, but also 2)
-    * even if it's not enabled in the dispatch.
+   /* We want to read the 3 fields we care about even if it's not enabled in
+    * the dispatch.
     */
    mov->force_writemask_all = true;
-   mov->exec_size = 8;
 
    /* The caller wants the low 32 bits of the timestamp.  Since it's running
     * at the GPU clock rate of ~1.2ghz, it will roll over every ~3 seconds,
@@ -743,10 +742,9 @@ fs_visitor::emit_shader_time_end()
    test->conditional_mod = BRW_CONDITIONAL_Z;
    emit(IF(BRW_PREDICATE_NORMAL));
 
-   push_force_uncompressed();
    fs_reg start = shader_start_time;
    start.negate = true;
-   fs_reg diff = fs_reg(this, glsl_type::uint_type);
+   fs_reg diff = fs_reg(GRF, virtual_grf_alloc(1), BRW_REGISTER_TYPE_UD, 1);
    emit(ADD(diff, start, shader_end_time));
 
    /* If there were no instructions between the two timestamp gets, the diff
@@ -760,8 +758,6 @@ fs_visitor::emit_shader_time_end()
    emit(BRW_OPCODE_ELSE);
    emit_shader_time_write(reset_type, fs_reg(1u));
    emit(BRW_OPCODE_ENDIF);
-
-   pop_force_uncompressed();
 }
 
 void
@@ -883,19 +879,6 @@ fs_visitor::emit(enum opcode opcode, const fs_reg &dst,
    return emit(new(mem_ctx) fs_inst(opcode, dst, src, sources));
 }
 
-void
-fs_visitor::push_force_uncompressed()
-{
-   force_uncompressed_stack++;
-}
-
-void
-fs_visitor::pop_force_uncompressed()
-{
-   force_uncompressed_stack--;
-   assert(force_uncompressed_stack >= 0);
-}
-
 /**
  * Returns true if the instruction has a flag that means it won't
  * update an entire destination register.
@@ -2427,6 +2410,10 @@ fs_visitor::compute_to_mrf()
    bool progress = false;
    int next_ip = 0;
 
+   /* No MRFs on Gen >= 7. */
+   if (brw->gen >= 7)
+      return false;
+
    calculate_live_intervals();
 
    foreach_block_and_inst_safe(block, fs_inst, inst, cfg) {
@@ -3638,7 +3625,6 @@ fs_visitor::run()
          }
       }
    }
-   assert(force_uncompressed_stack == 0);
 
    /* This must come after all optimization and register allocation, since
     * it inserts dead code that happens to have side effects, and it does
diff --git a/src/mesa/drivers/dri/i965/brw_fs.h b/src/mesa/drivers/dri/i965/brw_fs.h
index 67956bc..d9150c3 100644
--- a/src/mesa/drivers/dri/i965/brw_fs.h
+++ b/src/mesa/drivers/dri/i965/brw_fs.h
@@ -453,9 +453,6 @@ public:
    void lower_uniform_pull_constant_loads();
    bool lower_load_payload();
 
-   void push_force_uncompressed();
-   void pop_force_uncompressed();
-
    void emit_dummy_fs();
    void emit_repclear_shader();
    fs_reg *emit_fragcoord_interpolation(ir_variable *ir);
@@ -680,8 +677,6 @@ public:
    bool spilled_any_registers;
 
    const unsigned dispatch_width; /**< 8 or 16 */
-
-   int force_uncompressed_stack;
 };
 
 /**
diff --git a/src/mesa/drivers/dri/i965/brw_fs_cse.cpp b/src/mesa/drivers/dri/i965/brw_fs_cse.cpp
index 8012001..5fdbf46 100644
--- a/src/mesa/drivers/dri/i965/brw_fs_cse.cpp
+++ b/src/mesa/drivers/dri/i965/brw_fs_cse.cpp
@@ -128,7 +128,11 @@ operands_match(fs_inst *a, fs_inst *b)
    fs_reg *xs = a->src;
    fs_reg *ys = b->src;
 
-   if (!is_expression_commutative(a->opcode)) {
+   if (a->opcode == BRW_OPCODE_MAD) {
+      return xs[0].equals(ys[0]) &&
+             ((xs[1].equals(ys[1]) && xs[2].equals(ys[2])) ||
+              (xs[2].equals(ys[1]) && xs[1].equals(ys[2])));
+   } else if (!is_expression_commutative(a->opcode)) {
       bool match = true;
       for (int i = 0; i < a->sources; i++) {
          if (!xs[i].equals(ys[i])) {
diff --git a/src/mesa/drivers/dri/i965/brw_fs_generator.cpp b/src/mesa/drivers/dri/i965/brw_fs_generator.cpp
index c2010c0..c95beb6 100644
--- a/src/mesa/drivers/dri/i965/brw_fs_generator.cpp
+++ b/src/mesa/drivers/dri/i965/brw_fs_generator.cpp
@@ -851,10 +851,10 @@ fs_generator::generate_scratch_write(fs_inst *inst, struct brw_reg src)
    assert(inst->mlen != 0);
 
    brw_MOV(p,
-	   retype(brw_message_reg(inst->base_mrf + 1), BRW_REGISTER_TYPE_UD),
+	   brw_uvec_mrf(inst->exec_size, (inst->base_mrf + 1), 0),
 	   retype(src, BRW_REGISTER_TYPE_UD));
    brw_oword_block_write_scratch(p, brw_message_reg(inst->base_mrf),
-                                 dispatch_width / 8, inst->offset);
+                                 inst->exec_size / 8, inst->offset);
 }
 
 void
@@ -863,13 +863,13 @@ fs_generator::generate_scratch_read(fs_inst *inst, struct brw_reg dst)
    assert(inst->mlen != 0);
 
    brw_oword_block_read_scratch(p, dst, brw_message_reg(inst->base_mrf),
-                                dispatch_width / 8, inst->offset);
+                                inst->exec_size / 8, inst->offset);
 }
 
 void
 fs_generator::generate_scratch_read_gen7(fs_inst *inst, struct brw_reg dst)
 {
-   gen7_block_read_scratch(p, dst, dispatch_width / 8, inst->offset);
+   gen7_block_read_scratch(p, dst, inst->exec_size / 8, inst->offset);
 }
 
 void
diff --git a/src/mesa/drivers/dri/i965/brw_fs_peephole_predicated_break.cpp b/src/mesa/drivers/dri/i965/brw_fs_peephole_predicated_break.cpp
index b7a1d7e..047c2c0 100644
--- a/src/mesa/drivers/dri/i965/brw_fs_peephole_predicated_break.cpp
+++ b/src/mesa/drivers/dri/i965/brw_fs_peephole_predicated_break.cpp
@@ -107,10 +107,14 @@ fs_visitor::opt_peephole_predicated_break()
       }
       endif_inst->remove(endif_block);
 
-      earlier_block->children.make_empty();
-      later_block->parents.make_empty();
+      if (!earlier_block->ends_with_control_flow()) {
+         earlier_block->children.make_empty();
+         earlier_block->add_successor(cfg->mem_ctx, jump_block);
+      }
 
-      earlier_block->add_successor(cfg->mem_ctx, jump_block);
+      if (!later_block->starts_with_control_flow()) {
+         later_block->parents.make_empty();
+      }
       jump_block->add_successor(cfg->mem_ctx, later_block);
 
       if (earlier_block->can_combine_with(jump_block)) {
diff --git a/src/mesa/drivers/dri/i965/brw_fs_reg_allocate.cpp b/src/mesa/drivers/dri/i965/brw_fs_reg_allocate.cpp
index 7ae6c75..44c74a3 100644
--- a/src/mesa/drivers/dri/i965/brw_fs_reg_allocate.cpp
+++ b/src/mesa/drivers/dri/i965/brw_fs_reg_allocate.cpp
@@ -688,8 +688,10 @@ fs_visitor::emit_unspill(bblock_t *block, fs_inst *inst, fs_reg dst,
                          uint32_t spill_offset, int count)
 {
    int reg_size = 1;
-   if (count % 2 == 0)
+   if (dispatch_width == 16 && count % 2 == 0) {
       reg_size = 2;
+      dst.width = 16;
+   }
 
    for (int i = 0; i < count / reg_size; i++) {
       /* The gen7 descriptor-based offset is 12 bits of HWORD units. */
@@ -712,7 +714,7 @@ fs_visitor::emit_unspill(bblock_t *block, fs_inst *inst, fs_reg dst,
       inst->insert_before(block, unspill_inst);
 
       dst.reg_offset += reg_size;
-      spill_offset += reg_size * 8 * sizeof(float);
+      spill_offset += reg_size * REG_SIZE;
    }
 }
 
@@ -722,7 +724,7 @@ fs_visitor::emit_spill(bblock_t *block, fs_inst *inst, fs_reg src,
 {
    int reg_size = 1;
    int spill_base_mrf = 14;
-   if (count % 2 == 0) {
+   if (dispatch_width == 16 && count % 2 == 0) {
       spill_base_mrf = 13;
       reg_size = 2;
    }
@@ -730,9 +732,9 @@ fs_visitor::emit_spill(bblock_t *block, fs_inst *inst, fs_reg src,
    for (int i = 0; i < count / reg_size; i++) {
       fs_inst *spill_inst =
          new(mem_ctx) fs_inst(SHADER_OPCODE_GEN4_SCRATCH_WRITE,
-                              reg_null_f, src);
+                              reg_size * 8, reg_null_f, src);
       src.reg_offset += reg_size;
-      spill_inst->offset = spill_offset + i * reg_size;
+      spill_inst->offset = spill_offset + i * reg_size * REG_SIZE;
       spill_inst->ir = inst->ir;
       spill_inst->annotation = inst->annotation;
       spill_inst->mlen = 1 + reg_size; /* header, value */
@@ -820,7 +822,6 @@ fs_visitor::choose_spill_reg(struct ra_graph *g)
 void
 fs_visitor::spill_reg(int spill_reg)
 {
-   int reg_size = dispatch_width * sizeof(float);
    int size = virtual_grf_sizes[spill_reg];
    unsigned int spill_offset = last_scratch;
    assert(ALIGN(spill_offset, 16) == spill_offset); /* oword read/write req. */
@@ -847,7 +848,7 @@ fs_visitor::spill_reg(int spill_reg)
       spilled_any_registers = true;
    }
 
-   last_scratch += size * reg_size;
+   last_scratch += size * REG_SIZE;
 
    /* Generate spill/unspill instructions for the objects being
     * spilled.  Right now, we spill or unspill the whole thing to a
@@ -860,7 +861,7 @@ fs_visitor::spill_reg(int spill_reg)
 	     inst->src[i].reg == spill_reg) {
             int regs_read = inst->regs_read(this, i);
             int subset_spill_offset = (spill_offset +
-                                       reg_size * inst->src[i].reg_offset);
+                                       REG_SIZE * inst->src[i].reg_offset);
             fs_reg unspill_dst(GRF, virtual_grf_alloc(regs_read));
 
             inst->src[i].reg = unspill_dst.reg;
@@ -874,12 +875,20 @@ fs_visitor::spill_reg(int spill_reg)
       if (inst->dst.file == GRF &&
 	  inst->dst.reg == spill_reg) {
          int subset_spill_offset = (spill_offset +
-                                    reg_size * inst->dst.reg_offset);
+                                    REG_SIZE * inst->dst.reg_offset);
          fs_reg spill_src(GRF, virtual_grf_alloc(inst->regs_written));
 
          inst->dst.reg = spill_src.reg;
          inst->dst.reg_offset = 0;
 
+         /* If we're immediately spilling the register, we should not use
+          * destination dependency hints.  Doing so will cause the GPU do
+          * try to read and write the register at the same time and may
+          * hang the GPU.
+          */
+         inst->no_dd_clear = false;
+         inst->no_dd_check = false;
+
 	 /* If our write is going to affect just part of the
           * inst->regs_written(), then we need to unspill the destination
           * since we write back out all of the regs_written().
diff --git a/src/mesa/drivers/dri/i965/brw_fs_visitor.cpp b/src/mesa/drivers/dri/i965/brw_fs_visitor.cpp
index 3fc9e39..4e1badd 100644
--- a/src/mesa/drivers/dri/i965/brw_fs_visitor.cpp
+++ b/src/mesa/drivers/dri/i965/brw_fs_visitor.cpp
@@ -2921,9 +2921,6 @@ fs_visitor::emit_untyped_surface_read(unsigned surf_index, fs_reg dst,
 fs_inst *
 fs_visitor::emit(fs_inst *inst)
 {
-   if (force_uncompressed_stack > 0)
-      inst->exec_size = 8;
-
    if (dispatch_width == 16 && inst->exec_size == 8)
       inst->force_uncompressed = true;
 
@@ -3469,8 +3466,6 @@ fs_visitor::init()
    this->pull_constant_loc = NULL;
    this->push_constant_loc = NULL;
 
-   this->force_uncompressed_stack = 0;
-
    this->spilled_any_registers = false;
    this->do_dual_src = false;
 
diff --git a/src/mesa/drivers/dri/i965/brw_gs.c b/src/mesa/drivers/dri/i965/brw_gs.c
index c0c4c13..f44ac26 100644
--- a/src/mesa/drivers/dri/i965/brw_gs.c
+++ b/src/mesa/drivers/dri/i965/brw_gs.c
@@ -1,259 +1,428 @@
 /*
- Copyright (C) Intel Corp.  2006.  All Rights Reserved.
- Intel funded Tungsten Graphics to
- develop this 3D driver.
-
- Permission is hereby granted, free of charge, to any person obtaining
- a copy of this software and associated documentation files (the
- "Software"), to deal in the Software without restriction, including
- without limitation the rights to use, copy, modify, merge, publish,
- distribute, sublicense, and/or sell copies of the Software, and to
- permit persons to whom the Software is furnished to do so, subject to
- the following conditions:
-
- The above copyright notice and this permission notice (including the
- next paragraph) shall be included in all copies or substantial
- portions of the Software.
-
- THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
- IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
- LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
- OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
- WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-
- **********************************************************************/
- /*
-  * Authors:
-  *   Keith Whitwell <keithw@vmware.com>
-  */
-
-#include "main/glheader.h"
-#include "main/macros.h"
-#include "main/enums.h"
-#include "main/transformfeedback.h"
-
-#include "intel_batchbuffer.h"
-
-#include "brw_defines.h"
+ * Copyright © 2013 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+/**
+ * \file brw_vec4_gs.c
+ *
+ * State atom for client-programmable geometry shaders, and support code.
+ */
+
+#include "brw_gs.h"
 #include "brw_context.h"
-#include "brw_eu.h"
-#include "brw_util.h"
+#include "brw_vec4_gs_visitor.h"
 #include "brw_state.h"
-#include "brw_gs.h"
+#include "brw_ff_gs.h"
 
-#include "util/ralloc.h"
 
-static void compile_ff_gs_prog(struct brw_context *brw,
-                               struct brw_ff_gs_prog_key *key)
+static bool
+do_gs_prog(struct brw_context *brw,
+           struct gl_shader_program *prog,
+           struct brw_geometry_program *gp,
+           struct brw_gs_prog_key *key)
 {
-   struct brw_ff_gs_compile c;
-   const GLuint *program;
-   void *mem_ctx;
-   GLuint program_size;
-
+   struct brw_stage_state *stage_state = &brw->gs.base;
+   struct brw_gs_compile c;
    memset(&c, 0, sizeof(c));
-
    c.key = *key;
-   c.vue_map = brw->vs.prog_data->base.vue_map;
-   c.nr_regs = (c.vue_map.num_slots + 1)/2;
+   c.gp = gp;
 
-   mem_ctx = ralloc_context(NULL);
+   c.prog_data.include_primitive_id =
+      (gp->program.Base.InputsRead & VARYING_BIT_PRIMITIVE_ID) != 0;
 
-   /* Begin the compilation:
-    */
-   brw_init_compile(brw, &c.func, mem_ctx);
+   c.prog_data.invocations = gp->program.Invocations;
 
-   c.func.single_program_flow = 1;
-
-   /* For some reason the thread is spawned with only 4 channels
-    * unmasked.
+   /* Allocate the references to the uniforms that will end up in the
+    * prog_data associated with the compiled program, and which will be freed
+    * by the state cache.
+    *
+    * Note: param_count needs to be num_uniform_components * 4, since we add
+    * padding around uniform values below vec4 size, so the worst case is that
+    * every uniform is a float which gets padded to the size of a vec4.
+    */
+   struct gl_shader *gs = prog->_LinkedShaders[MESA_SHADER_GEOMETRY];
+   int param_count = gs->num_uniform_components * 4;
+
+   /* We also upload clip plane data as uniforms */
+   param_count += MAX_CLIP_PLANES * 4;
+
+   c.prog_data.base.base.param =
+      rzalloc_array(NULL, const gl_constant_value *, param_count);
+   c.prog_data.base.base.pull_param =
+      rzalloc_array(NULL, const gl_constant_value *, param_count);
+   /* Setting nr_params here NOT to the size of the param and pull_param
+    * arrays, but to the number of uniform components vec4_visitor
+    * needs. vec4_visitor::setup_uniforms() will set it back to a proper value.
     */
-   brw_set_default_mask_control(&c.func, BRW_MASK_DISABLE);
+   c.prog_data.base.base.nr_params = ALIGN(param_count, 4) / 4 + gs->num_samplers;
 
-   if (brw->gen >= 6) {
-      unsigned num_verts;
-      bool check_edge_flag;
-      /* On Sandybridge, we use the GS for implementing transform feedback
-       * (called "Stream Out" in the PRM).
-       */
-      switch (key->primitive) {
-      case _3DPRIM_POINTLIST:
-         num_verts = 1;
-         check_edge_flag = false;
-	 break;
-      case _3DPRIM_LINELIST:
-      case _3DPRIM_LINESTRIP:
-      case _3DPRIM_LINELOOP:
-         num_verts = 2;
-         check_edge_flag = false;
-	 break;
-      case _3DPRIM_TRILIST:
-      case _3DPRIM_TRIFAN:
-      case _3DPRIM_TRISTRIP:
-      case _3DPRIM_RECTLIST:
-	 num_verts = 3;
-         check_edge_flag = false;
-         break;
-      case _3DPRIM_QUADLIST:
-      case _3DPRIM_QUADSTRIP:
-      case _3DPRIM_POLYGON:
-         num_verts = 3;
-         check_edge_flag = true;
-         break;
-      default:
-	 unreachable("Unexpected primitive type in Gen6 SOL program.");
+   if (brw->gen >= 7) {
+      if (gp->program.OutputType == GL_POINTS) {
+         /* When the output type is points, the geometry shader may output data
+          * to multiple streams, and EndPrimitive() has no effect.  So we
+          * configure the hardware to interpret the control data as stream ID.
+          */
+         c.prog_data.control_data_format = GEN7_GS_CONTROL_DATA_FORMAT_GSCTL_SID;
+
+         /* We only have to emit control bits if we are using streams */
+         if (prog->Geom.UsesStreams)
+            c.control_data_bits_per_vertex = 2;
+         else
+            c.control_data_bits_per_vertex = 0;
+      } else {
+         /* When the output type is triangle_strip or line_strip, EndPrimitive()
+          * may be used to terminate the current strip and start a new one
+          * (similar to primitive restart), and outputting data to multiple
+          * streams is not supported.  So we configure the hardware to interpret
+          * the control data as EndPrimitive information (a.k.a. "cut bits").
+          */
+         c.prog_data.control_data_format = GEN7_GS_CONTROL_DATA_FORMAT_GSCTL_CUT;
+
+         /* We only need to output control data if the shader actually calls
+          * EndPrimitive().
+          */
+         c.control_data_bits_per_vertex = gp->program.UsesEndPrimitive ? 1 : 0;
       }
-      gen6_sol_program(&c, key, num_verts, check_edge_flag);
    } else {
-      /* On Gen4-5, we use the GS to decompose certain types of primitives.
-       * Note that primitives which don't require a GS program have already
-       * been weeded out by now.
-       */
-      switch (key->primitive) {
-      case _3DPRIM_QUADLIST:
-	 brw_ff_gs_quads( &c, key );
-	 break;
-      case _3DPRIM_QUADSTRIP:
-	 brw_ff_gs_quad_strip( &c, key );
-	 break;
-      case _3DPRIM_LINELOOP:
-	 brw_ff_gs_lines( &c );
-	 break;
-      default:
-	 ralloc_free(mem_ctx);
-	 return;
-      }
+      /* There are no control data bits in gen6. */
+      c.control_data_bits_per_vertex = 0;
+
+      /* If it is using transform feedback, enable it */
+      if (prog->TransformFeedback.NumVarying)
+         c.prog_data.gen6_xfb_enabled = true;
+      else
+         c.prog_data.gen6_xfb_enabled = false;
    }
+   c.control_data_header_size_bits =
+      gp->program.VerticesOut * c.control_data_bits_per_vertex;
+
+   /* 1 HWORD = 32 bytes = 256 bits */
+   c.prog_data.control_data_header_size_hwords =
+      ALIGN(c.control_data_header_size_bits, 256) / 256;
 
-   brw_compact_instructions(&c.func, 0, 0, NULL);
+   GLbitfield64 outputs_written = gp->program.Base.OutputsWritten;
 
-   /* get the program
+   /* In order for legacy clipping to work, we need to populate the clip
+    * distance varying slots whenever clipping is enabled, even if the vertex
+    * shader doesn't write to gl_ClipDistance.
     */
-   program = brw_get_program(&c.func, &program_size);
-
-   if (unlikely(INTEL_DEBUG & DEBUG_GS)) {
-      fprintf(stderr, "gs:\n");
-      brw_disassemble(brw, c.func.store, 0, program_size, stderr);
-      fprintf(stderr, "\n");
-    }
-
-   brw_upload_cache(&brw->cache, BRW_FF_GS_PROG,
-		    &c.key, sizeof(c.key),
-		    program, program_size,
-		    &c.prog_data, sizeof(c.prog_data),
-		    &brw->ff_gs.prog_offset, &brw->ff_gs.prog_data);
-   ralloc_free(mem_ctx);
-}
+   if (c.key.base.userclip_active) {
+      outputs_written |= BITFIELD64_BIT(VARYING_SLOT_CLIP_DIST0);
+      outputs_written |= BITFIELD64_BIT(VARYING_SLOT_CLIP_DIST1);
+   }
 
-static void populate_key(struct brw_context *brw,
-                         struct brw_ff_gs_prog_key *key)
-{
-   static const unsigned swizzle_for_offset[4] = {
-      BRW_SWIZZLE4(0, 1, 2, 3),
-      BRW_SWIZZLE4(1, 2, 3, 3),
-      BRW_SWIZZLE4(2, 3, 3, 3),
-      BRW_SWIZZLE4(3, 3, 3, 3)
-   };
+   brw_compute_vue_map(brw, &c.prog_data.base.vue_map, outputs_written);
+
+   /* Compute the output vertex size.
+    *
+    * From the Ivy Bridge PRM, Vol2 Part1 7.2.1.1 STATE_GS - Output Vertex
+    * Size (p168):
+    *
+    *     [0,62] indicating [1,63] 16B units
+    *
+    *     Specifies the size of each vertex stored in the GS output entry
+    *     (following any Control Header data) as a number of 128-bit units
+    *     (minus one).
+    *
+    *     Programming Restrictions: The vertex size must be programmed as a
+    *     multiple of 32B units with the following exception: Rendering is
+    *     disabled (as per SOL stage state) and the vertex size output by the
+    *     GS thread is 16B.
+    *
+    *     If rendering is enabled (as per SOL state) the vertex size must be
+    *     programmed as a multiple of 32B units. In other words, the only time
+    *     software can program a vertex size with an odd number of 16B units
+    *     is when rendering is disabled.
+    *
+    * Note: B=bytes in the above text.
+    *
+    * It doesn't seem worth the extra trouble to optimize the case where the
+    * vertex size is 16B (especially since this would require special-casing
+    * the GEN assembly that writes to the URB).  So we just set the vertex
+    * size to a multiple of 32B (2 vec4's) in all cases.
+    *
+    * The maximum output vertex size is 62*16 = 992 bytes (31 hwords).  We
+    * budget that as follows:
+    *
+    *   512 bytes for varyings (a varying component is 4 bytes and
+    *             gl_MaxGeometryOutputComponents = 128)
+    *    16 bytes overhead for VARYING_SLOT_PSIZ (each varying slot is 16
+    *             bytes)
+    *    16 bytes overhead for gl_Position (we allocate it a slot in the VUE
+    *             even if it's not used)
+    *    32 bytes overhead for gl_ClipDistance (we allocate it 2 VUE slots
+    *             whenever clip planes are enabled, even if the shader doesn't
+    *             write to gl_ClipDistance)
+    *    16 bytes overhead since the VUE size must be a multiple of 32 bytes
+    *             (see below)--this causes up to 1 VUE slot to be wasted
+    *   400 bytes available for varying packing overhead
+    *
+    * Worst-case varying packing overhead is 3/4 of a varying slot (12 bytes)
+    * per interpolation type, so this is plenty.
+    *
+    */
+   unsigned output_vertex_size_bytes = c.prog_data.base.vue_map.num_slots * 16;
+   assert(brw->gen == 6 ||
+          output_vertex_size_bytes <= GEN7_MAX_GS_OUTPUT_VERTEX_SIZE_BYTES);
+   c.prog_data.output_vertex_size_hwords =
+      ALIGN(output_vertex_size_bytes, 32) / 32;
+
+   /* Compute URB entry size.  The maximum allowed URB entry size is 32k.
+    * That divides up as follows:
+    *
+    *     64 bytes for the control data header (cut indices or StreamID bits)
+    *   4096 bytes for varyings (a varying component is 4 bytes and
+    *              gl_MaxGeometryTotalOutputComponents = 1024)
+    *   4096 bytes overhead for VARYING_SLOT_PSIZ (each varying slot is 16
+    *              bytes/vertex and gl_MaxGeometryOutputVertices is 256)
+    *   4096 bytes overhead for gl_Position (we allocate it a slot in the VUE
+    *              even if it's not used)
+    *   8192 bytes overhead for gl_ClipDistance (we allocate it 2 VUE slots
+    *              whenever clip planes are enabled, even if the shader doesn't
+    *              write to gl_ClipDistance)
+    *   4096 bytes overhead since the VUE size must be a multiple of 32
+    *              bytes (see above)--this causes up to 1 VUE slot to be wasted
+    *   8128 bytes available for varying packing overhead
+    *
+    * Worst-case varying packing overhead is 3/4 of a varying slot per
+    * interpolation type, which works out to 3072 bytes, so this would allow
+    * us to accommodate 2 interpolation types without any danger of running
+    * out of URB space.
+    *
+    * In practice, the risk of running out of URB space is very small, since
+    * the above figures are all worst-case, and most of them scale with the
+    * number of output vertices.  So we'll just calculate the amount of space
+    * we need, and if it's too large, fail to compile.
+    *
+    * The above is for gen7+ where we have a single URB entry that will hold
+    * all the output. In gen6, we will have to allocate URB entries for every
+    * vertex we emit, so our URB entries only need to be large enough to hold
+    * a single vertex. Also, gen6 does not have a control data header.
+    */
+   unsigned output_size_bytes;
+   if (brw->gen >= 7) {
+      output_size_bytes =
+         c.prog_data.output_vertex_size_hwords * 32 * gp->program.VerticesOut;
+      output_size_bytes += 32 * c.prog_data.control_data_header_size_hwords;
+   } else {
+      output_size_bytes = c.prog_data.output_vertex_size_hwords * 32;
+   }
 
-   struct gl_context *ctx = &brw->ctx;
+   /* Broadwell stores "Vertex Count" as a full 8 DWord (32 byte) URB output,
+    * which comes before the control header.
+    */
+   if (brw->gen >= 8)
+      output_size_bytes += 32;
 
-   memset(key, 0, sizeof(*key));
+   assert(output_size_bytes >= 1);
+   int max_output_size_bytes = GEN7_MAX_GS_URB_ENTRY_SIZE_BYTES;
+   if (brw->gen == 6)
+      max_output_size_bytes = GEN6_MAX_GS_URB_ENTRY_SIZE_BYTES;
+   if (output_size_bytes > max_output_size_bytes)
+      return false;
 
-   /* CACHE_NEW_VS_PROG (part of VUE map) */
-   key->attrs = brw->vs.prog_data->base.vue_map.slots_valid;
 
-   /* BRW_NEW_PRIMITIVE */
-   key->primitive = brw->primitive;
+   /* URB entry sizes are stored as a multiple of 64 bytes in gen7+ and
+    * a multiple of 128 bytes in gen6.
+    */
+   if (brw->gen >= 7)
+      c.prog_data.base.urb_entry_size = ALIGN(output_size_bytes, 64) / 64;
+   else
+      c.prog_data.base.urb_entry_size = ALIGN(output_size_bytes, 128) / 128;
 
-   /* _NEW_LIGHT */
-   key->pv_first = (ctx->Light.ProvokingVertex == GL_FIRST_VERTEX_CONVENTION);
-   if (key->primitive == _3DPRIM_QUADLIST && ctx->Light.ShadeModel != GL_FLAT) {
-      /* Provide consistent primitive order with brw_set_prim's
-       * optimization of single quads to trifans.
-       */
-      key->pv_first = true;
+   c.prog_data.output_topology =
+      get_hw_prim_for_gl_prim(gp->program.OutputType);
+
+   brw_compute_vue_map(brw, &c.input_vue_map, c.key.input_varyings);
+
+   /* GS inputs are read from the VUE 256 bits (2 vec4's) at a time, so we
+    * need to program a URB read length of ceiling(num_slots / 2).
+    */
+   c.prog_data.base.urb_read_length = (c.input_vue_map.num_slots + 1) / 2;
+
+   void *mem_ctx = ralloc_context(NULL);
+   unsigned program_size;
+   const unsigned *program =
+      brw_gs_emit(brw, prog, &c, mem_ctx, &program_size);
+   if (program == NULL) {
+      ralloc_free(mem_ctx);
+      return false;
    }
 
-   if (brw->gen >= 7) {
-      /* On Gen7 and later, we don't use GS (yet). */
-      key->need_gs_prog = false;
-   } else if (brw->gen == 6) {
-      /* On Gen6, GS is used for transform feedback. */
-      /* BRW_NEW_TRANSFORM_FEEDBACK */
-      if (_mesa_is_xfb_active_and_unpaused(ctx)) {
-         const struct gl_shader_program *shaderprog =
-            ctx->_Shader->CurrentProgram[MESA_SHADER_VERTEX];
-         const struct gl_transform_feedback_info *linked_xfb_info =
-            &shaderprog->LinkedTransformFeedback;
-         int i;
-
-         /* Make sure that the VUE slots won't overflow the unsigned chars in
-          * key->transform_feedback_bindings[].
-          */
-         STATIC_ASSERT(BRW_VARYING_SLOT_COUNT <= 256);
+   /* Scratch space is used for register spilling */
+   if (c.base.last_scratch) {
+      perf_debug("Geometry shader triggered register spilling.  "
+                 "Try reducing the number of live vec4 values to "
+                 "improve performance.\n");
 
-         /* Make sure that we don't need more binding table entries than we've
-          * set aside for use in transform feedback.  (We shouldn't, since we
-          * set aside enough binding table entries to have one per component).
-          */
-         assert(linked_xfb_info->NumOutputs <= BRW_MAX_SOL_BINDINGS);
-
-         key->need_gs_prog = true;
-         key->num_transform_feedback_bindings = linked_xfb_info->NumOutputs;
-         for (i = 0; i < key->num_transform_feedback_bindings; ++i) {
-            key->transform_feedback_bindings[i] =
-               linked_xfb_info->Outputs[i].OutputRegister;
-            key->transform_feedback_swizzles[i] =
-               swizzle_for_offset[linked_xfb_info->Outputs[i].ComponentOffset];
-         }
-      }
-   } else {
-      /* Pre-gen6, GS is used to transform QUADLIST, QUADSTRIP, and LINELOOP
-       * into simpler primitives.
-       */
-      key->need_gs_prog = (brw->primitive == _3DPRIM_QUADLIST ||
-                           brw->primitive == _3DPRIM_QUADSTRIP ||
-                           brw->primitive == _3DPRIM_LINELOOP);
+      c.prog_data.base.base.total_scratch
+         = brw_get_scratch_size(c.base.last_scratch*REG_SIZE);
+
+      brw_get_scratch_bo(brw, &stage_state->scratch_bo,
+			 c.prog_data.base.base.total_scratch *
+                         brw->max_gs_threads);
    }
+
+   brw_upload_cache(&brw->cache, BRW_GS_PROG,
+                    &c.key, sizeof(c.key),
+                    program, program_size,
+                    &c.prog_data, sizeof(c.prog_data),
+                    &stage_state->prog_offset, &brw->gs.prog_data);
+   ralloc_free(mem_ctx);
+
+   return true;
 }
 
-/* Calculate interpolants for triangle and line rasterization.
- */
+
 static void
-brw_upload_ff_gs_prog(struct brw_context *brw)
+brw_upload_gs_prog(struct brw_context *brw)
 {
-   struct brw_ff_gs_prog_key key;
-   /* Populate the key:
-    */
-   populate_key(brw, &key);
+   struct gl_context *ctx = &brw->ctx;
+   struct brw_stage_state *stage_state = &brw->gs.base;
+   struct brw_gs_prog_key key;
+   /* BRW_NEW_GEOMETRY_PROGRAM */
+   struct brw_geometry_program *gp =
+      (struct brw_geometry_program *) brw->geometry_program;
+
+   if (gp == NULL) {
+      /* No geometry shader.  Vertex data just passes straight through. */
+      if (brw->state.dirty.brw & BRW_NEW_VUE_MAP_VS) {
+         brw->vue_map_geom_out = brw->vue_map_vs;
+         brw->state.dirty.brw |= BRW_NEW_VUE_MAP_GEOM_OUT;
+      }
 
-   if (brw->ff_gs.prog_active != key.need_gs_prog) {
-      brw->state.dirty.cache |= CACHE_NEW_FF_GS_PROG;
-      brw->ff_gs.prog_active = key.need_gs_prog;
+      if (brw->gen == 6 &&
+          (brw->state.dirty.brw & BRW_NEW_TRANSFORM_FEEDBACK)) {
+         gen6_brw_upload_ff_gs_prog(brw);
+         return;
+      }
+
+      /* Other state atoms had better not try to access prog_data, since
+       * there's no GS program.
+       */
+      brw->gs.prog_data = NULL;
+      brw->gs.base.prog_data = NULL;
+
+      return;
    }
 
-   if (brw->ff_gs.prog_active) {
-      if (!brw_search_cache(&brw->cache, BRW_FF_GS_PROG,
-			    &key, sizeof(key),
-			    &brw->ff_gs.prog_offset, &brw->ff_gs.prog_data)) {
-	 compile_ff_gs_prog( brw, &key );
-      }
+   struct gl_program *prog = &gp->program.Base;
+
+   memset(&key, 0, sizeof(key));
+
+   key.base.program_string_id = gp->id;
+   brw_setup_vec4_key_clip_info(brw, &key.base,
+                                gp->program.Base.UsesClipDistanceOut);
+
+   /* _NEW_LIGHT | _NEW_BUFFERS */
+   key.base.clamp_vertex_color = ctx->Light._ClampVertexColor;
+
+   /* _NEW_TEXTURE */
+   brw_populate_sampler_prog_key_data(ctx, prog, stage_state->sampler_count,
+                                      &key.base.tex);
+
+   /* BRW_NEW_VUE_MAP_VS */
+   key.input_varyings = brw->vue_map_vs.slots_valid;
+
+   if (!brw_search_cache(&brw->cache, BRW_GS_PROG,
+                         &key, sizeof(key),
+                         &stage_state->prog_offset, &brw->gs.prog_data)) {
+      bool success =
+         do_gs_prog(brw, ctx->_Shader->CurrentProgram[MESA_SHADER_GEOMETRY], gp,
+                    &key);
+      assert(success);
+      (void)success;
    }
-}
+   brw->gs.base.prog_data = &brw->gs.prog_data->base.base;
 
-void gen6_brw_upload_ff_gs_prog(struct brw_context *brw)
-{
-   brw_upload_ff_gs_prog(brw);
+   if (memcmp(&brw->vs.prog_data->base.vue_map, &brw->vue_map_geom_out,
+              sizeof(brw->vue_map_geom_out)) != 0) {
+      brw->vue_map_geom_out = brw->gs.prog_data->base.vue_map;
+      brw->state.dirty.brw |= BRW_NEW_VUE_MAP_GEOM_OUT;
+   }
 }
 
-const struct brw_tracked_state brw_ff_gs_prog = {
+
+const struct brw_tracked_state brw_gs_prog = {
    .dirty = {
-      .mesa  = (_NEW_LIGHT),
-      .brw   = (BRW_NEW_PRIMITIVE |
+      .mesa  = (_NEW_LIGHT | _NEW_BUFFERS | _NEW_TEXTURE),
+      .brw   = (BRW_NEW_GEOMETRY_PROGRAM |
+                BRW_NEW_VUE_MAP_VS |
                 BRW_NEW_TRANSFORM_FEEDBACK),
-      .cache = CACHE_NEW_VS_PROG
    },
-   .emit = brw_upload_ff_gs_prog
+   .emit = brw_upload_gs_prog
 };
+
+
+bool
+brw_gs_precompile(struct gl_context *ctx, struct gl_shader_program *prog)
+{
+   struct brw_context *brw = brw_context(ctx);
+   struct brw_gs_prog_key key;
+   uint32_t old_prog_offset = brw->gs.base.prog_offset;
+   struct brw_gs_prog_data *old_prog_data = brw->gs.prog_data;
+   bool success;
+
+   if (!prog->_LinkedShaders[MESA_SHADER_GEOMETRY])
+      return true;
+
+   struct gl_geometry_program *gp = (struct gl_geometry_program *)
+      prog->_LinkedShaders[MESA_SHADER_GEOMETRY]->Program;
+   struct brw_geometry_program *bgp = brw_geometry_program(gp);
+
+   memset(&key, 0, sizeof(key));
+
+   brw_vec4_setup_prog_key_for_precompile(ctx, &key.base, bgp->id, &gp->Base);
+
+   /* Assume that the set of varyings coming in from the vertex shader exactly
+    * matches what the geometry shader requires.
+    */
+   key.input_varyings = gp->Base.InputsRead;
+
+   success = do_gs_prog(brw, prog, bgp, &key);
+
+   brw->gs.base.prog_offset = old_prog_offset;
+   brw->gs.prog_data = old_prog_data;
+
+   return success;
+}
+
+
+bool
+brw_gs_prog_data_compare(const void *in_a, const void *in_b)
+{
+   const struct brw_gs_prog_data *a = in_a;
+   const struct brw_gs_prog_data *b = in_b;
+
+   /* Compare the base structure. */
+   if (!brw_stage_prog_data_compare(&a->base.base, &b->base.base))
+      return false;
+
+   /* Compare the rest of the struct. */
+   const unsigned offset = sizeof(struct brw_stage_prog_data);
+   if (memcmp(((char *) a) + offset, ((char *) b) + offset,
+              sizeof(struct brw_gs_prog_data) - offset)) {
+      return false;
+   }
+
+   return true;
+}
diff --git a/src/mesa/drivers/dri/i965/brw_gs.h b/src/mesa/drivers/dri/i965/brw_gs.h
index a538948..5d4244e 100644
--- a/src/mesa/drivers/dri/i965/brw_gs.h
+++ b/src/mesa/drivers/dri/i965/brw_gs.h
@@ -1,115 +1,43 @@
 /*
- Copyright (C) Intel Corp.  2006.  All Rights Reserved.
- Intel funded Tungsten Graphics to
- develop this 3D driver.
-
- Permission is hereby granted, free of charge, to any person obtaining
- a copy of this software and associated documentation files (the
- "Software"), to deal in the Software without restriction, including
- without limitation the rights to use, copy, modify, merge, publish,
- distribute, sublicense, and/or sell copies of the Software, and to
- permit persons to whom the Software is furnished to do so, subject to
- the following conditions:
-
- The above copyright notice and this permission notice (including the
- next paragraph) shall be included in all copies or substantial
- portions of the Software.
-
- THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
- IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
- LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
- OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
- WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-
- **********************************************************************/
- /*
-  * Authors:
-  *   Keith Whitwell <keithw@vmware.com>
-  */
-
-
-#ifndef BRW_GS_H
-#define BRW_GS_H
-
-
-#include "brw_context.h"
-#include "brw_eu.h"
-
-#define MAX_GS_VERTS (4)	
-
-struct brw_ff_gs_prog_key {
-   GLbitfield64 attrs;
-
-   /**
-    * Hardware primitive type being drawn, e.g. _3DPRIM_TRILIST.
-    */
-   GLuint primitive:8;
-
-   GLuint pv_first:1;
-   GLuint need_gs_prog:1;
-
-   /**
-    * Number of varyings that are output to transform feedback.
-    */
-   GLuint num_transform_feedback_bindings:7; /* 0-BRW_MAX_SOL_BINDINGS */
-
-   /**
-    * Map from the index of a transform feedback binding table entry to the
-    * gl_varying_slot that should be streamed out through that binding table
-    * entry.
-    */
-   unsigned char transform_feedback_bindings[BRW_MAX_SOL_BINDINGS];
-
-   /**
-    * Map from the index of a transform feedback binding table entry to the
-    * swizzles that should be used when streaming out data through that
-    * binding table entry.
-    */
-   unsigned char transform_feedback_swizzles[BRW_MAX_SOL_BINDINGS];
-};
-
-struct brw_ff_gs_compile {
-   struct brw_compile func;
-   struct brw_ff_gs_prog_key key;
-   struct brw_ff_gs_prog_data prog_data;
-
-   struct {
-      struct brw_reg R0;
-
-      /**
-       * Register holding streamed vertex buffer pointers -- see the Sandy
-       * Bridge PRM, volume 2 part 1, section 4.4.2 (GS Thread Payload
-       * [DevSNB]).  These pointers are delivered in GRF 1.
-       */
-      struct brw_reg SVBI;
-
-      struct brw_reg vertex[MAX_GS_VERTS];
-      struct brw_reg header;
-      struct brw_reg temp;
-
-      /**
-       * Register holding destination indices for streamed buffer writes.
-       * Only used for SOL programs.
-       */
-      struct brw_reg destination_indices;
-   } reg;
-
-   /* Number of registers used to store vertex data */
-   GLuint nr_regs;
+ * Copyright © 2013 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef BRW_VEC4_GS_H
+#define BRW_VEC4_GS_H
+
+#include <stdbool.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
 
-   struct brw_vue_map vue_map;
-};
+struct gl_context;
+struct gl_shader_program;
 
-void brw_ff_gs_quads(struct brw_ff_gs_compile *c,
-                     struct brw_ff_gs_prog_key *key);
-void brw_ff_gs_quad_strip(struct brw_ff_gs_compile *c,
-                          struct brw_ff_gs_prog_key *key);
-void brw_ff_gs_lines(struct brw_ff_gs_compile *c);
-void gen6_sol_program(struct brw_ff_gs_compile *c,
-                      struct brw_ff_gs_prog_key *key,
-                      unsigned num_verts, bool check_edge_flag);
-void gen6_brw_upload_ff_gs_prog(struct brw_context *brw);
+bool brw_gs_precompile(struct gl_context *ctx, struct gl_shader_program *prog);
+bool brw_gs_prog_data_compare(const void *a, const void *b);
 
+#ifdef __cplusplus
+} /* extern "C" */
 #endif
+
+#endif /* BRW_VEC4_GS_H */
diff --git a/src/mesa/drivers/dri/i965/brw_gs_emit.c b/src/mesa/drivers/dri/i965/brw_gs_emit.c
deleted file mode 100644
index 91986c3..0000000
--- a/src/mesa/drivers/dri/i965/brw_gs_emit.c
+++ /dev/null
@@ -1,529 +0,0 @@
-/*
- Copyright (C) Intel Corp.  2006.  All Rights Reserved.
- Intel funded Tungsten Graphics to
- develop this 3D driver.
-
- Permission is hereby granted, free of charge, to any person obtaining
- a copy of this software and associated documentation files (the
- "Software"), to deal in the Software without restriction, including
- without limitation the rights to use, copy, modify, merge, publish,
- distribute, sublicense, and/or sell copies of the Software, and to
- permit persons to whom the Software is furnished to do so, subject to
- the following conditions:
-
- The above copyright notice and this permission notice (including the
- next paragraph) shall be included in all copies or substantial
- portions of the Software.
-
- THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
- IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
- LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
- OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
- WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-
- **********************************************************************/
- /*
-  * Authors:
-  *   Keith Whitwell <keithw@vmware.com>
-  */
-
-
-#include "main/glheader.h"
-#include "main/macros.h"
-#include "main/enums.h"
-
-#include "program/program.h"
-#include "intel_batchbuffer.h"
-
-#include "brw_defines.h"
-#include "brw_context.h"
-#include "brw_eu.h"
-#include "brw_gs.h"
-
-/**
- * Allocate registers for GS.
- *
- * If sol_program is true, then:
- *
- * - The thread will be spawned with the "SVBI Payload Enable" bit set, so GRF
- *   1 needs to be set aside to hold the streamed vertex buffer indices.
- *
- * - The thread will need to use the destination_indices register.
- */
-static void brw_ff_gs_alloc_regs(struct brw_ff_gs_compile *c,
-                                 GLuint nr_verts,
-                                 bool sol_program)
-{
-   GLuint i = 0,j;
-
-   /* Register usage is static, precompute here:
-    */
-   c->reg.R0 = retype(brw_vec8_grf(i, 0), BRW_REGISTER_TYPE_UD); i++;
-
-   /* Streamed vertex buffer indices */
-   if (sol_program)
-      c->reg.SVBI = retype(brw_vec8_grf(i++, 0), BRW_REGISTER_TYPE_UD);
-
-   /* Payload vertices plus space for more generated vertices:
-    */
-   for (j = 0; j < nr_verts; j++) {
-      c->reg.vertex[j] = brw_vec4_grf(i, 0);
-      i += c->nr_regs;
-   }
-
-   c->reg.header = retype(brw_vec8_grf(i++, 0), BRW_REGISTER_TYPE_UD);
-   c->reg.temp = retype(brw_vec8_grf(i++, 0), BRW_REGISTER_TYPE_UD);
-
-   if (sol_program) {
-      c->reg.destination_indices =
-         retype(brw_vec4_grf(i++, 0), BRW_REGISTER_TYPE_UD);
-   }
-
-   c->prog_data.urb_read_length = c->nr_regs;
-   c->prog_data.total_grf = i;
-}
-
-
-/**
- * Set up the initial value of c->reg.header register based on c->reg.R0.
- *
- * The following information is passed to the GS thread in R0, and needs to be
- * included in the first URB_WRITE or FF_SYNC message sent by the GS:
- *
- * - DWORD 0 [31:0] handle info (Gen4 only)
- * - DWORD 5 [7:0] FFTID
- * - DWORD 6 [31:0] Debug info
- * - DWORD 7 [31:0] Debug info
- *
- * This function sets up the above data by copying by copying the contents of
- * R0 to the header register.
- */
-static void brw_ff_gs_initialize_header(struct brw_ff_gs_compile *c)
-{
-   struct brw_compile *p = &c->func;
-   brw_MOV(p, c->reg.header, c->reg.R0);
-}
-
-/**
- * Overwrite DWORD 2 of c->reg.header with the given immediate unsigned value.
- *
- * In URB_WRITE messages, DWORD 2 contains the fields PrimType, PrimStart,
- * PrimEnd, Increment CL_INVOCATIONS, and SONumPrimsWritten, many of which we
- * need to be able to update on a per-vertex basis.
- */
-static void brw_ff_gs_overwrite_header_dw2(struct brw_ff_gs_compile *c,
-                                           unsigned dw2)
-{
-   struct brw_compile *p = &c->func;
-   brw_MOV(p, get_element_ud(c->reg.header, 2), brw_imm_ud(dw2));
-}
-
-/**
- * Overwrite DWORD 2 of c->reg.header with the primitive type from c->reg.R0.
- *
- * When the thread is spawned, GRF 0 contains the primitive type in bits 4:0
- * of DWORD 2.  URB_WRITE messages need the primitive type in bits 6:2 of
- * DWORD 2.  So this function extracts the primitive type field, bitshifts it
- * appropriately, and stores it in c->reg.header.
- */
-static void brw_ff_gs_overwrite_header_dw2_from_r0(struct brw_ff_gs_compile *c)
-{
-   struct brw_compile *p = &c->func;
-   brw_AND(p, get_element_ud(c->reg.header, 2), get_element_ud(c->reg.R0, 2),
-           brw_imm_ud(0x1f));
-   brw_SHL(p, get_element_ud(c->reg.header, 2),
-           get_element_ud(c->reg.header, 2), brw_imm_ud(2));
-}
-
-/**
- * Apply an additive offset to DWORD 2 of c->reg.header.
- *
- * This is used to set/unset the "PrimStart" and "PrimEnd" flags appropriately
- * for each vertex.
- */
-static void brw_ff_gs_offset_header_dw2(struct brw_ff_gs_compile *c,
-                                        int offset)
-{
-   struct brw_compile *p = &c->func;
-   brw_ADD(p, get_element_d(c->reg.header, 2), get_element_d(c->reg.header, 2),
-           brw_imm_d(offset));
-}
-
-
-/**
- * Emit a vertex using the URB_WRITE message.  Use the contents of
- * c->reg.header for the message header, and the registers starting at \c vert
- * for the vertex data.
- *
- * If \c last is true, then this is the last vertex, so no further URB space
- * should be allocated, and this message should end the thread.
- *
- * If \c last is false, then a new URB entry will be allocated, and its handle
- * will be stored in DWORD 0 of c->reg.header for use in the next URB_WRITE
- * message.
- */
-static void brw_ff_gs_emit_vue(struct brw_ff_gs_compile *c,
-                               struct brw_reg vert,
-                               bool last)
-{
-   struct brw_compile *p = &c->func;
-   int write_offset = 0;
-   bool complete = false;
-
-   do {
-      /* We can't write more than 14 registers at a time to the URB */
-      int write_len = MIN2(c->nr_regs - write_offset, 14);
-      if (write_len == c->nr_regs - write_offset)
-         complete = true;
-
-      /* Copy the vertex from vertn into m1..mN+1:
-       */
-      brw_copy8(p, brw_message_reg(1), offset(vert, write_offset), write_len);
-
-      /* Send the vertex data to the URB.  If this is the last write for this
-       * vertex, then we mark it as complete, and either end the thread or
-       * allocate another vertex URB entry (depending whether this is the last
-       * vertex).
-       */
-      enum brw_urb_write_flags flags;
-      if (!complete)
-         flags = BRW_URB_WRITE_NO_FLAGS;
-      else if (last)
-         flags = BRW_URB_WRITE_EOT_COMPLETE;
-      else
-         flags = BRW_URB_WRITE_ALLOCATE_COMPLETE;
-      brw_urb_WRITE(p,
-                    (flags & BRW_URB_WRITE_ALLOCATE) ? c->reg.temp
-                    : retype(brw_null_reg(), BRW_REGISTER_TYPE_UD),
-                    0,
-                    c->reg.header,
-                    flags,
-                    write_len + 1, /* msg length */
-                    (flags & BRW_URB_WRITE_ALLOCATE) ? 1
-                    : 0, /* response length */
-                    write_offset,  /* urb offset */
-                    BRW_URB_SWIZZLE_NONE);
-      write_offset += write_len;
-   } while (!complete);
-
-   if (!last) {
-      brw_MOV(p, get_element_ud(c->reg.header, 0),
-              get_element_ud(c->reg.temp, 0));
-   }
-}
-
-/**
- * Send an FF_SYNC message to ensure that all previously spawned GS threads
- * have finished sending primitives down the pipeline, and to allocate a URB
- * entry for the first output vertex.  Only needed on Ironlake+.
- *
- * This function modifies c->reg.header: in DWORD 1, it stores num_prim (which
- * is needed by the FF_SYNC message), and in DWORD 0, it stores the handle to
- * the allocated URB entry (which will be needed by the URB_WRITE meesage that
- * follows).
- */
-static void brw_ff_gs_ff_sync(struct brw_ff_gs_compile *c, int num_prim)
-{
-   struct brw_compile *p = &c->func;
-
-   brw_MOV(p, get_element_ud(c->reg.header, 1), brw_imm_ud(num_prim));
-   brw_ff_sync(p,
-               c->reg.temp,
-               0,
-               c->reg.header,
-               1, /* allocate */
-               1, /* response length */
-               0 /* eot */);
-   brw_MOV(p, get_element_ud(c->reg.header, 0),
-           get_element_ud(c->reg.temp, 0));
-}
-
-
-void
-brw_ff_gs_quads(struct brw_ff_gs_compile *c, struct brw_ff_gs_prog_key *key)
-{
-   struct brw_context *brw = c->func.brw;
-
-   brw_ff_gs_alloc_regs(c, 4, false);
-   brw_ff_gs_initialize_header(c);
-   /* Use polygons for correct edgeflag behaviour. Note that vertex 3
-    * is the PV for quads, but vertex 0 for polygons:
-    */
-   if (brw->gen == 5)
-      brw_ff_gs_ff_sync(c, 1);
-   brw_ff_gs_overwrite_header_dw2(
-      c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
-          | URB_WRITE_PRIM_START));
-   if (key->pv_first) {
-      brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
-      brw_ff_gs_overwrite_header_dw2(
-         c, _3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[1], 0);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[2], 0);
-      brw_ff_gs_overwrite_header_dw2(
-         c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
-             | URB_WRITE_PRIM_END));
-      brw_ff_gs_emit_vue(c, c->reg.vertex[3], 1);
-   }
-   else {
-      brw_ff_gs_emit_vue(c, c->reg.vertex[3], 0);
-      brw_ff_gs_overwrite_header_dw2(
-         c, _3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[1], 0);
-      brw_ff_gs_overwrite_header_dw2(
-         c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
-             | URB_WRITE_PRIM_END));
-      brw_ff_gs_emit_vue(c, c->reg.vertex[2], 1);
-   }
-}
-
-void
-brw_ff_gs_quad_strip(struct brw_ff_gs_compile *c,
-                     struct brw_ff_gs_prog_key *key)
-{
-   struct brw_context *brw = c->func.brw;
-
-   brw_ff_gs_alloc_regs(c, 4, false);
-   brw_ff_gs_initialize_header(c);
-
-   if (brw->gen == 5)
-      brw_ff_gs_ff_sync(c, 1);
-   brw_ff_gs_overwrite_header_dw2(
-      c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
-          | URB_WRITE_PRIM_START));
-   if (key->pv_first) {
-      brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
-      brw_ff_gs_overwrite_header_dw2(
-         c, _3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[1], 0);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[2], 0);
-      brw_ff_gs_overwrite_header_dw2(
-         c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
-             | URB_WRITE_PRIM_END));
-      brw_ff_gs_emit_vue(c, c->reg.vertex[3], 1);
-   }
-   else {
-      brw_ff_gs_emit_vue(c, c->reg.vertex[2], 0);
-      brw_ff_gs_overwrite_header_dw2(
-         c, _3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[3], 0);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
-      brw_ff_gs_overwrite_header_dw2(
-         c, ((_3DPRIM_POLYGON << URB_WRITE_PRIM_TYPE_SHIFT)
-             | URB_WRITE_PRIM_END));
-      brw_ff_gs_emit_vue(c, c->reg.vertex[1], 1);
-   }
-}
-
-void brw_ff_gs_lines(struct brw_ff_gs_compile *c)
-{
-   struct brw_context *brw = c->func.brw;
-
-   brw_ff_gs_alloc_regs(c, 2, false);
-   brw_ff_gs_initialize_header(c);
-
-   if (brw->gen == 5)
-      brw_ff_gs_ff_sync(c, 1);
-   brw_ff_gs_overwrite_header_dw2(
-      c, ((_3DPRIM_LINESTRIP << URB_WRITE_PRIM_TYPE_SHIFT)
-          | URB_WRITE_PRIM_START));
-   brw_ff_gs_emit_vue(c, c->reg.vertex[0], 0);
-   brw_ff_gs_overwrite_header_dw2(
-      c, ((_3DPRIM_LINESTRIP << URB_WRITE_PRIM_TYPE_SHIFT)
-          | URB_WRITE_PRIM_END));
-   brw_ff_gs_emit_vue(c, c->reg.vertex[1], 1);
-}
-
-/**
- * Generate the geometry shader program used on Gen6 to perform stream output
- * (transform feedback).
- */
-void
-gen6_sol_program(struct brw_ff_gs_compile *c, struct brw_ff_gs_prog_key *key,
-	         unsigned num_verts, bool check_edge_flags)
-{
-   struct brw_compile *p = &c->func;
-   struct brw_context *brw = p->brw;
-   brw_inst *inst;
-   c->prog_data.svbi_postincrement_value = num_verts;
-
-   brw_ff_gs_alloc_regs(c, num_verts, true);
-   brw_ff_gs_initialize_header(c);
-
-   if (key->num_transform_feedback_bindings > 0) {
-      unsigned vertex, binding;
-      struct brw_reg destination_indices_uw =
-         vec8(retype(c->reg.destination_indices, BRW_REGISTER_TYPE_UW));
-
-      /* Note: since we use the binding table to keep track of buffer offsets
-       * and stride, the GS doesn't need to keep track of a separate pointer
-       * into each buffer; it uses a single pointer which increments by 1 for
-       * each vertex.  So we use SVBI0 for this pointer, regardless of whether
-       * transform feedback is in interleaved or separate attribs mode.
-       *
-       * Make sure that the buffers have enough room for all the vertices.
-       */
-      brw_ADD(p, get_element_ud(c->reg.temp, 0),
-	         get_element_ud(c->reg.SVBI, 0), brw_imm_ud(num_verts));
-      brw_CMP(p, vec1(brw_null_reg()), BRW_CONDITIONAL_LE,
-	         get_element_ud(c->reg.temp, 0),
-	         get_element_ud(c->reg.SVBI, 4));
-      brw_IF(p, BRW_EXECUTE_1);
-
-      /* Compute the destination indices to write to.  Usually we use SVBI[0]
-       * + (0, 1, 2).  However, for odd-numbered triangles in tristrips, the
-       * vertices come down the pipeline in reversed winding order, so we need
-       * to flip the order when writing to the transform feedback buffer.  To
-       * ensure that flatshading accuracy is preserved, we need to write them
-       * in order SVBI[0] + (0, 2, 1) if we're using the first provoking
-       * vertex convention, and in order SVBI[0] + (1, 0, 2) if we're using
-       * the last provoking vertex convention.
-       *
-       * Note: since brw_imm_v can only be used in instructions in
-       * packed-word execution mode, and SVBI is a double-word, we need to
-       * first move the appropriate immediate constant ((0, 1, 2), (0, 2, 1),
-       * or (1, 0, 2)) to the destination_indices register, and then add SVBI
-       * using a separate instruction.  Also, since the immediate constant is
-       * expressed as packed words, and we need to load double-words into
-       * destination_indices, we need to intersperse zeros to fill the upper
-       * halves of each double-word.
-       */
-      brw_MOV(p, destination_indices_uw,
-              brw_imm_v(0x00020100)); /* (0, 1, 2) */
-      if (num_verts == 3) {
-         /* Get primitive type into temp register. */
-         brw_AND(p, get_element_ud(c->reg.temp, 0),
-                 get_element_ud(c->reg.R0, 2), brw_imm_ud(0x1f));
-
-         /* Test if primitive type is TRISTRIP_REVERSE.  We need to do this as
-          * an 8-wide comparison so that the conditional MOV that follows
-          * moves all 8 words correctly.
-          */
-         brw_CMP(p, vec8(brw_null_reg()), BRW_CONDITIONAL_EQ,
-                 get_element_ud(c->reg.temp, 0),
-                 brw_imm_ud(_3DPRIM_TRISTRIP_REVERSE));
-
-         /* If so, then overwrite destination_indices_uw with the appropriate
-          * reordering.
-          */
-         inst = brw_MOV(p, destination_indices_uw,
-                        brw_imm_v(key->pv_first ? 0x00010200    /* (0, 2, 1) */
-                                                : 0x00020001)); /* (1, 0, 2) */
-         brw_inst_set_pred_control(brw, inst, BRW_PREDICATE_NORMAL);
-      }
-      brw_ADD(p, c->reg.destination_indices,
-              c->reg.destination_indices, get_element_ud(c->reg.SVBI, 0));
-
-      /* For each vertex, generate code to output each varying using the
-       * appropriate binding table entry.
-       */
-      for (vertex = 0; vertex < num_verts; ++vertex) {
-         /* Set up the correct destination index for this vertex */
-         brw_MOV(p, get_element_ud(c->reg.header, 5),
-                 get_element_ud(c->reg.destination_indices, vertex));
-
-         for (binding = 0; binding < key->num_transform_feedback_bindings;
-              ++binding) {
-            unsigned char varying =
-               key->transform_feedback_bindings[binding];
-            unsigned char slot = c->vue_map.varying_to_slot[varying];
-            /* From the Sandybridge PRM, Volume 2, Part 1, Section 4.5.1:
-             *
-             *   "Prior to End of Thread with a URB_WRITE, the kernel must
-             *   ensure that all writes are complete by sending the final
-             *   write as a committed write."
-             */
-            bool final_write =
-               binding == key->num_transform_feedback_bindings - 1 &&
-               vertex == num_verts - 1;
-            struct brw_reg vertex_slot = c->reg.vertex[vertex];
-            vertex_slot.nr += slot / 2;
-            vertex_slot.subnr = (slot % 2) * 16;
-            /* gl_PointSize is stored in VARYING_SLOT_PSIZ.w. */
-            vertex_slot.dw1.bits.swizzle = varying == VARYING_SLOT_PSIZ
-               ? BRW_SWIZZLE_WWWW : key->transform_feedback_swizzles[binding];
-            brw_set_default_access_mode(p, BRW_ALIGN_16);
-            brw_MOV(p, stride(c->reg.header, 4, 4, 1),
-                    retype(vertex_slot, BRW_REGISTER_TYPE_UD));
-            brw_set_default_access_mode(p, BRW_ALIGN_1);
-            brw_svb_write(p,
-                          final_write ? c->reg.temp : brw_null_reg(), /* dest */
-                          1, /* msg_reg_nr */
-                          c->reg.header, /* src0 */
-                          SURF_INDEX_GEN6_SOL_BINDING(binding), /* binding_table_index */
-                          final_write); /* send_commit_msg */
-         }
-      }
-      brw_ENDIF(p);
-
-      /* Now, reinitialize the header register from R0 to restore the parts of
-       * the register that we overwrote while streaming out transform feedback
-       * data.
-       */
-      brw_ff_gs_initialize_header(c);
-
-      /* Finally, wait for the write commit to occur so that we can proceed to
-       * other things safely.
-       *
-       * From the Sandybridge PRM, Volume 4, Part 1, Section 3.3:
-       *
-       *   The write commit does not modify the destination register, but
-       *   merely clears the dependency associated with the destination
-       *   register. Thus, a simple “mov” instruction using the register as a
-       *   source is sufficient to wait for the write commit to occur.
-       */
-      brw_MOV(p, c->reg.temp, c->reg.temp);
-   }
-
-   brw_ff_gs_ff_sync(c, 1);
-
-   brw_ff_gs_overwrite_header_dw2_from_r0(c);
-   switch (num_verts) {
-   case 1:
-      brw_ff_gs_offset_header_dw2(c,
-                                  URB_WRITE_PRIM_START | URB_WRITE_PRIM_END);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[0], true);
-      break;
-   case 2:
-      brw_ff_gs_offset_header_dw2(c, URB_WRITE_PRIM_START);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[0], false);
-      brw_ff_gs_offset_header_dw2(c,
-                                  URB_WRITE_PRIM_END - URB_WRITE_PRIM_START);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[1], true);
-      break;
-   case 3:
-      if (check_edge_flags) {
-         /* Only emit vertices 0 and 1 if this is the first triangle of the
-          * polygon.  Otherwise they are redundant.
-          */
-         brw_AND(p, retype(brw_null_reg(), BRW_REGISTER_TYPE_UD),
-                 get_element_ud(c->reg.R0, 2),
-                 brw_imm_ud(BRW_GS_EDGE_INDICATOR_0));
-         brw_inst_set_cond_modifier(brw, brw_last_inst, BRW_CONDITIONAL_NZ);
-         brw_IF(p, BRW_EXECUTE_1);
-      }
-      brw_ff_gs_offset_header_dw2(c, URB_WRITE_PRIM_START);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[0], false);
-      brw_ff_gs_offset_header_dw2(c, -URB_WRITE_PRIM_START);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[1], false);
-      if (check_edge_flags) {
-         brw_ENDIF(p);
-         /* Only emit vertex 2 in PRIM_END mode if this is the last triangle
-          * of the polygon.  Otherwise leave the primitive incomplete because
-          * there are more polygon vertices coming.
-          */
-         brw_AND(p, retype(brw_null_reg(), BRW_REGISTER_TYPE_UD),
-                 get_element_ud(c->reg.R0, 2),
-                 brw_imm_ud(BRW_GS_EDGE_INDICATOR_1));
-         brw_inst_set_cond_modifier(brw, brw_last_inst, BRW_CONDITIONAL_NZ);
-         brw_set_default_predicate_control(p, BRW_PREDICATE_NORMAL);
-      }
-      brw_ff_gs_offset_header_dw2(c, URB_WRITE_PRIM_END);
-      brw_set_default_predicate_control(p, BRW_PREDICATE_NONE);
-      brw_ff_gs_emit_vue(c, c->reg.vertex[2], true);
-      break;
-   }
-}
diff --git a/src/mesa/drivers/dri/i965/brw_meta_fast_clear.c b/src/mesa/drivers/dri/i965/brw_meta_fast_clear.c
index b4e75a7..c8f2a14 100644
--- a/src/mesa/drivers/dri/i965/brw_meta_fast_clear.c
+++ b/src/mesa/drivers/dri/i965/brw_meta_fast_clear.c
@@ -643,11 +643,14 @@ get_resolve_rect(struct brw_context *brw,
     * The scaledown factors in the table that follows are related to the
     * alignment size returned by intel_get_non_msrt_mcs_alignment() by a
     * multiplier.  For IVB and HSW, we divide by two, for BDW we multiply
-    * by 8 and 16.
+    * by 8 and 16 and 8 and 8 for SKL.
     */
 
    intel_get_non_msrt_mcs_alignment(brw, mt, &x_align, &y_align);
-   if (brw->gen >= 8) {
+   if (brw->gen >= 9) {
+      x_scaledown = x_align * 8;
+      y_scaledown = y_align * 8;
+   } else if (brw->gen >= 8) {
       x_scaledown = x_align * 8;
       y_scaledown = y_align * 16;
    } else {
diff --git a/src/mesa/drivers/dri/i965/brw_misc_state.c b/src/mesa/drivers/dri/i965/brw_misc_state.c
index e3980fc..99fcddc 100644
--- a/src/mesa/drivers/dri/i965/brw_misc_state.c
+++ b/src/mesa/drivers/dri/i965/brw_misc_state.c
@@ -902,7 +902,7 @@ brw_upload_invariant_state(struct brw_context *brw)
    const uint32_t _3DSTATE_PIPELINE_SELECT =
       is_965 ? CMD_PIPELINE_SELECT_965 : CMD_PIPELINE_SELECT_GM45;
    BEGIN_BATCH(1);
-   OUT_BATCH(_3DSTATE_PIPELINE_SELECT << 16 | 0);
+   OUT_BATCH(_3DSTATE_PIPELINE_SELECT << 16 | (brw->gen >= 9 ? (3 << 8) : 0));
    ADVANCE_BATCH();
 
    if (brw->gen < 6) {
diff --git a/src/mesa/drivers/dri/i965/brw_shader.cpp b/src/mesa/drivers/dri/i965/brw_shader.cpp
index 21dcf2d..10f8db7 100644
--- a/src/mesa/drivers/dri/i965/brw_shader.cpp
+++ b/src/mesa/drivers/dri/i965/brw_shader.cpp
@@ -26,7 +26,7 @@ extern "C" {
 #include "brw_context.h"
 }
 #include "brw_vs.h"
-#include "brw_vec4_gs.h"
+#include "brw_gs.h"
 #include "brw_fs.h"
 #include "brw_cfg.h"
 #include "glsl/ir_optimization.h"
diff --git a/src/mesa/drivers/dri/i965/brw_state.h b/src/mesa/drivers/dri/i965/brw_state.h
index 2efe56e..209fab1 100644
--- a/src/mesa/drivers/dri/i965/brw_state.h
+++ b/src/mesa/drivers/dri/i965/brw_state.h
@@ -137,6 +137,7 @@ extern const struct brw_tracked_state gen8_disable_stages;
 extern const struct brw_tracked_state gen8_gs_state;
 extern const struct brw_tracked_state gen8_index_buffer;
 extern const struct brw_tracked_state gen8_multisample_state;
+extern const struct brw_tracked_state gen8_pma_fix;
 extern const struct brw_tracked_state gen8_ps_blend;
 extern const struct brw_tracked_state gen8_ps_extra;
 extern const struct brw_tracked_state gen8_ps_state;
diff --git a/src/mesa/drivers/dri/i965/brw_state_cache.c b/src/mesa/drivers/dri/i965/brw_state_cache.c
index eb7452ec..cf42ada 100644
--- a/src/mesa/drivers/dri/i965/brw_state_cache.c
+++ b/src/mesa/drivers/dri/i965/brw_state_cache.c
@@ -49,8 +49,7 @@
 #include "brw_state.h"
 #include "brw_vs.h"
 #include "brw_wm.h"
-#include "brw_vs.h"
-#include "brw_vec4_gs.h"
+#include "brw_gs.h"
 
 #define FILE_DEBUG_FLAG DEBUG_STATE
 
diff --git a/src/mesa/drivers/dri/i965/brw_state_upload.c b/src/mesa/drivers/dri/i965/brw_state_upload.c
index a691319..1c53e5b 100644
--- a/src/mesa/drivers/dri/i965/brw_state_upload.c
+++ b/src/mesa/drivers/dri/i965/brw_state_upload.c
@@ -333,6 +333,7 @@ static const struct brw_tracked_state *gen8_atoms[] =
    &gen8_vertices,
 
    &haswell_cut_index,
+   &gen8_pma_fix,
 };
 
 static void
@@ -390,6 +391,11 @@ void brw_init_state( struct brw_context *brw )
    brw->state.dirty.mesa = ~0;
    brw->state.dirty.brw = ~0ull;
 
+   /* ~0 is a nonsensical value which won't match anything we program, so
+    * the programming will take effect on the first time around.
+    */
+   brw->pma_stall_bits = ~0;
+
    /* Make sure that brw->state.dirty.brw has enough bits to hold all possible
     * dirty flags.
     */
diff --git a/src/mesa/drivers/dri/i965/brw_surface_formats.c b/src/mesa/drivers/dri/i965/brw_surface_formats.c
index 5407ef6..2841f81 100644
--- a/src/mesa/drivers/dri/i965/brw_surface_formats.c
+++ b/src/mesa/drivers/dri/i965/brw_surface_formats.c
@@ -619,6 +619,8 @@ brw_init_surface_formats(struct brw_context *brw)
    brw->format_supported_as_render_target[MESA_FORMAT_S_UINT8] = true;
    brw->format_supported_as_render_target[MESA_FORMAT_Z_FLOAT32] = true;
    brw->format_supported_as_render_target[MESA_FORMAT_Z32_FLOAT_S8X24_UINT] = true;
+   if (brw->gen >= 8)
+      brw->format_supported_as_render_target[MESA_FORMAT_Z_UNORM16] = true;
 
    /* We remap depth formats to a supported texturing format in
     * translate_tex_format().
@@ -638,7 +640,12 @@ brw_init_surface_formats(struct brw_context *brw)
     *
     * Other speculation is that we may be hitting increased fragment shader
     * execution from GL_LEQUAL/GL_EQUAL depth tests at reduced precision.
+    *
+    * With the PMA stall workaround in place, Z16 is faster than Z24, as it
+    * should be.
     */
+   if (brw->gen >= 8)
+      ctx->TextureFormatSupported[MESA_FORMAT_Z_UNORM16] = true;
 
    /* On hardware that lacks support for ETC1, we map ETC1 to RGBX
     * during glCompressedTexImage2D(). See intel_mipmap_tree::wraps_etc1.
diff --git a/src/mesa/drivers/dri/i965/brw_vec4_cse.cpp b/src/mesa/drivers/dri/i965/brw_vec4_cse.cpp
index 28c69ca..630d335 100644
--- a/src/mesa/drivers/dri/i965/brw_vec4_cse.cpp
+++ b/src/mesa/drivers/dri/i965/brw_vec4_cse.cpp
@@ -104,7 +104,11 @@ is_expression_commutative(enum opcode op)
 static bool
 operands_match(enum opcode op, src_reg *xs, src_reg *ys)
 {
-   if (!is_expression_commutative(op)) {
+   if (op == BRW_OPCODE_MAD) {
+      return xs[0].equals(ys[0]) &&
+             ((xs[1].equals(ys[1]) && xs[2].equals(ys[2])) ||
+              (xs[2].equals(ys[1]) && xs[1].equals(ys[2])));
+   } else if (!is_expression_commutative(op)) {
       return xs[0].equals(ys[0]) && xs[1].equals(ys[1]) && xs[2].equals(ys[2]);
    } else {
       return (xs[0].equals(ys[0]) && xs[1].equals(ys[1])) ||
diff --git a/src/mesa/drivers/dri/i965/brw_vec4_gs.c b/src/mesa/drivers/dri/i965/brw_vec4_gs.c
deleted file mode 100644
index c8814fe..0000000
--- a/src/mesa/drivers/dri/i965/brw_vec4_gs.c
+++ /dev/null
@@ -1,428 +0,0 @@
-/*
- * Copyright © 2013 Intel Corporation
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation
- * the rights to use, copy, modify, merge, publish, distribute, sublicense,
- * and/or sell copies of the Software, and to permit persons to whom the
- * Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice (including the next
- * paragraph) shall be included in all copies or substantial portions of the
- * Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
- * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
- * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
- * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
- * DEALINGS IN THE SOFTWARE.
- */
-
-/**
- * \file brw_vec4_gs.c
- *
- * State atom for client-programmable geometry shaders, and support code.
- */
-
-#include "brw_vec4_gs.h"
-#include "brw_context.h"
-#include "brw_vec4_gs_visitor.h"
-#include "brw_state.h"
-#include "brw_gs.h"
-
-
-static bool
-do_gs_prog(struct brw_context *brw,
-           struct gl_shader_program *prog,
-           struct brw_geometry_program *gp,
-           struct brw_gs_prog_key *key)
-{
-   struct brw_stage_state *stage_state = &brw->gs.base;
-   struct brw_gs_compile c;
-   memset(&c, 0, sizeof(c));
-   c.key = *key;
-   c.gp = gp;
-
-   c.prog_data.include_primitive_id =
-      (gp->program.Base.InputsRead & VARYING_BIT_PRIMITIVE_ID) != 0;
-
-   c.prog_data.invocations = gp->program.Invocations;
-
-   /* Allocate the references to the uniforms that will end up in the
-    * prog_data associated with the compiled program, and which will be freed
-    * by the state cache.
-    *
-    * Note: param_count needs to be num_uniform_components * 4, since we add
-    * padding around uniform values below vec4 size, so the worst case is that
-    * every uniform is a float which gets padded to the size of a vec4.
-    */
-   struct gl_shader *gs = prog->_LinkedShaders[MESA_SHADER_GEOMETRY];
-   int param_count = gs->num_uniform_components * 4;
-
-   /* We also upload clip plane data as uniforms */
-   param_count += MAX_CLIP_PLANES * 4;
-
-   c.prog_data.base.base.param =
-      rzalloc_array(NULL, const gl_constant_value *, param_count);
-   c.prog_data.base.base.pull_param =
-      rzalloc_array(NULL, const gl_constant_value *, param_count);
-   /* Setting nr_params here NOT to the size of the param and pull_param
-    * arrays, but to the number of uniform components vec4_visitor
-    * needs. vec4_visitor::setup_uniforms() will set it back to a proper value.
-    */
-   c.prog_data.base.base.nr_params = ALIGN(param_count, 4) / 4 + gs->num_samplers;
-
-   if (brw->gen >= 7) {
-      if (gp->program.OutputType == GL_POINTS) {
-         /* When the output type is points, the geometry shader may output data
-          * to multiple streams, and EndPrimitive() has no effect.  So we
-          * configure the hardware to interpret the control data as stream ID.
-          */
-         c.prog_data.control_data_format = GEN7_GS_CONTROL_DATA_FORMAT_GSCTL_SID;
-
-         /* We only have to emit control bits if we are using streams */
-         if (prog->Geom.UsesStreams)
-            c.control_data_bits_per_vertex = 2;
-         else
-            c.control_data_bits_per_vertex = 0;
-      } else {
-         /* When the output type is triangle_strip or line_strip, EndPrimitive()
-          * may be used to terminate the current strip and start a new one
-          * (similar to primitive restart), and outputting data to multiple
-          * streams is not supported.  So we configure the hardware to interpret
-          * the control data as EndPrimitive information (a.k.a. "cut bits").
-          */
-         c.prog_data.control_data_format = GEN7_GS_CONTROL_DATA_FORMAT_GSCTL_CUT;
-
-         /* We only need to output control data if the shader actually calls
-          * EndPrimitive().
-          */
-         c.control_data_bits_per_vertex = gp->program.UsesEndPrimitive ? 1 : 0;
-      }
-   } else {
-      /* There are no control data bits in gen6. */
-      c.control_data_bits_per_vertex = 0;
-
-      /* If it is using transform feedback, enable it */
-      if (prog->TransformFeedback.NumVarying)
-         c.prog_data.gen6_xfb_enabled = true;
-      else
-         c.prog_data.gen6_xfb_enabled = false;
-   }
-   c.control_data_header_size_bits =
-      gp->program.VerticesOut * c.control_data_bits_per_vertex;
-
-   /* 1 HWORD = 32 bytes = 256 bits */
-   c.prog_data.control_data_header_size_hwords =
-      ALIGN(c.control_data_header_size_bits, 256) / 256;
-
-   GLbitfield64 outputs_written = gp->program.Base.OutputsWritten;
-
-   /* In order for legacy clipping to work, we need to populate the clip
-    * distance varying slots whenever clipping is enabled, even if the vertex
-    * shader doesn't write to gl_ClipDistance.
-    */
-   if (c.key.base.userclip_active) {
-      outputs_written |= BITFIELD64_BIT(VARYING_SLOT_CLIP_DIST0);
-      outputs_written |= BITFIELD64_BIT(VARYING_SLOT_CLIP_DIST1);
-   }
-
-   brw_compute_vue_map(brw, &c.prog_data.base.vue_map, outputs_written);
-
-   /* Compute the output vertex size.
-    *
-    * From the Ivy Bridge PRM, Vol2 Part1 7.2.1.1 STATE_GS - Output Vertex
-    * Size (p168):
-    *
-    *     [0,62] indicating [1,63] 16B units
-    *
-    *     Specifies the size of each vertex stored in the GS output entry
-    *     (following any Control Header data) as a number of 128-bit units
-    *     (minus one).
-    *
-    *     Programming Restrictions: The vertex size must be programmed as a
-    *     multiple of 32B units with the following exception: Rendering is
-    *     disabled (as per SOL stage state) and the vertex size output by the
-    *     GS thread is 16B.
-    *
-    *     If rendering is enabled (as per SOL state) the vertex size must be
-    *     programmed as a multiple of 32B units. In other words, the only time
-    *     software can program a vertex size with an odd number of 16B units
-    *     is when rendering is disabled.
-    *
-    * Note: B=bytes in the above text.
-    *
-    * It doesn't seem worth the extra trouble to optimize the case where the
-    * vertex size is 16B (especially since this would require special-casing
-    * the GEN assembly that writes to the URB).  So we just set the vertex
-    * size to a multiple of 32B (2 vec4's) in all cases.
-    *
-    * The maximum output vertex size is 62*16 = 992 bytes (31 hwords).  We
-    * budget that as follows:
-    *
-    *   512 bytes for varyings (a varying component is 4 bytes and
-    *             gl_MaxGeometryOutputComponents = 128)
-    *    16 bytes overhead for VARYING_SLOT_PSIZ (each varying slot is 16
-    *             bytes)
-    *    16 bytes overhead for gl_Position (we allocate it a slot in the VUE
-    *             even if it's not used)
-    *    32 bytes overhead for gl_ClipDistance (we allocate it 2 VUE slots
-    *             whenever clip planes are enabled, even if the shader doesn't
-    *             write to gl_ClipDistance)
-    *    16 bytes overhead since the VUE size must be a multiple of 32 bytes
-    *             (see below)--this causes up to 1 VUE slot to be wasted
-    *   400 bytes available for varying packing overhead
-    *
-    * Worst-case varying packing overhead is 3/4 of a varying slot (12 bytes)
-    * per interpolation type, so this is plenty.
-    *
-    */
-   unsigned output_vertex_size_bytes = c.prog_data.base.vue_map.num_slots * 16;
-   assert(brw->gen == 6 ||
-          output_vertex_size_bytes <= GEN7_MAX_GS_OUTPUT_VERTEX_SIZE_BYTES);
-   c.prog_data.output_vertex_size_hwords =
-      ALIGN(output_vertex_size_bytes, 32) / 32;
-
-   /* Compute URB entry size.  The maximum allowed URB entry size is 32k.
-    * That divides up as follows:
-    *
-    *     64 bytes for the control data header (cut indices or StreamID bits)
-    *   4096 bytes for varyings (a varying component is 4 bytes and
-    *              gl_MaxGeometryTotalOutputComponents = 1024)
-    *   4096 bytes overhead for VARYING_SLOT_PSIZ (each varying slot is 16
-    *              bytes/vertex and gl_MaxGeometryOutputVertices is 256)
-    *   4096 bytes overhead for gl_Position (we allocate it a slot in the VUE
-    *              even if it's not used)
-    *   8192 bytes overhead for gl_ClipDistance (we allocate it 2 VUE slots
-    *              whenever clip planes are enabled, even if the shader doesn't
-    *              write to gl_ClipDistance)
-    *   4096 bytes overhead since the VUE size must be a multiple of 32
-    *              bytes (see above)--this causes up to 1 VUE slot to be wasted
-    *   8128 bytes available for varying packing overhead
-    *
-    * Worst-case varying packing overhead is 3/4 of a varying slot per
-    * interpolation type, which works out to 3072 bytes, so this would allow
-    * us to accommodate 2 interpolation types without any danger of running
-    * out of URB space.
-    *
-    * In practice, the risk of running out of URB space is very small, since
-    * the above figures are all worst-case, and most of them scale with the
-    * number of output vertices.  So we'll just calculate the amount of space
-    * we need, and if it's too large, fail to compile.
-    *
-    * The above is for gen7+ where we have a single URB entry that will hold
-    * all the output. In gen6, we will have to allocate URB entries for every
-    * vertex we emit, so our URB entries only need to be large enough to hold
-    * a single vertex. Also, gen6 does not have a control data header.
-    */
-   unsigned output_size_bytes;
-   if (brw->gen >= 7) {
-      output_size_bytes =
-         c.prog_data.output_vertex_size_hwords * 32 * gp->program.VerticesOut;
-      output_size_bytes += 32 * c.prog_data.control_data_header_size_hwords;
-   } else {
-      output_size_bytes = c.prog_data.output_vertex_size_hwords * 32;
-   }
-
-   /* Broadwell stores "Vertex Count" as a full 8 DWord (32 byte) URB output,
-    * which comes before the control header.
-    */
-   if (brw->gen >= 8)
-      output_size_bytes += 32;
-
-   assert(output_size_bytes >= 1);
-   int max_output_size_bytes = GEN7_MAX_GS_URB_ENTRY_SIZE_BYTES;
-   if (brw->gen == 6)
-      max_output_size_bytes = GEN6_MAX_GS_URB_ENTRY_SIZE_BYTES;
-   if (output_size_bytes > max_output_size_bytes)
-      return false;
-
-
-   /* URB entry sizes are stored as a multiple of 64 bytes in gen7+ and
-    * a multiple of 128 bytes in gen6.
-    */
-   if (brw->gen >= 7)
-      c.prog_data.base.urb_entry_size = ALIGN(output_size_bytes, 64) / 64;
-   else
-      c.prog_data.base.urb_entry_size = ALIGN(output_size_bytes, 128) / 128;
-
-   c.prog_data.output_topology =
-      get_hw_prim_for_gl_prim(gp->program.OutputType);
-
-   brw_compute_vue_map(brw, &c.input_vue_map, c.key.input_varyings);
-
-   /* GS inputs are read from the VUE 256 bits (2 vec4's) at a time, so we
-    * need to program a URB read length of ceiling(num_slots / 2).
-    */
-   c.prog_data.base.urb_read_length = (c.input_vue_map.num_slots + 1) / 2;
-
-   void *mem_ctx = ralloc_context(NULL);
-   unsigned program_size;
-   const unsigned *program =
-      brw_gs_emit(brw, prog, &c, mem_ctx, &program_size);
-   if (program == NULL) {
-      ralloc_free(mem_ctx);
-      return false;
-   }
-
-   /* Scratch space is used for register spilling */
-   if (c.base.last_scratch) {
-      perf_debug("Geometry shader triggered register spilling.  "
-                 "Try reducing the number of live vec4 values to "
-                 "improve performance.\n");
-
-      c.prog_data.base.base.total_scratch
-         = brw_get_scratch_size(c.base.last_scratch*REG_SIZE);
-
-      brw_get_scratch_bo(brw, &stage_state->scratch_bo,
-			 c.prog_data.base.base.total_scratch *
-                         brw->max_gs_threads);
-   }
-
-   brw_upload_cache(&brw->cache, BRW_GS_PROG,
-                    &c.key, sizeof(c.key),
-                    program, program_size,
-                    &c.prog_data, sizeof(c.prog_data),
-                    &stage_state->prog_offset, &brw->gs.prog_data);
-   ralloc_free(mem_ctx);
-
-   return true;
-}
-
-
-static void
-brw_upload_gs_prog(struct brw_context *brw)
-{
-   struct gl_context *ctx = &brw->ctx;
-   struct brw_stage_state *stage_state = &brw->gs.base;
-   struct brw_gs_prog_key key;
-   /* BRW_NEW_GEOMETRY_PROGRAM */
-   struct brw_geometry_program *gp =
-      (struct brw_geometry_program *) brw->geometry_program;
-
-   if (gp == NULL) {
-      /* No geometry shader.  Vertex data just passes straight through. */
-      if (brw->state.dirty.brw & BRW_NEW_VUE_MAP_VS) {
-         brw->vue_map_geom_out = brw->vue_map_vs;
-         brw->state.dirty.brw |= BRW_NEW_VUE_MAP_GEOM_OUT;
-      }
-
-      if (brw->gen == 6 &&
-          (brw->state.dirty.brw & BRW_NEW_TRANSFORM_FEEDBACK)) {
-         gen6_brw_upload_ff_gs_prog(brw);
-         return;
-      }
-
-      /* Other state atoms had better not try to access prog_data, since
-       * there's no GS program.
-       */
-      brw->gs.prog_data = NULL;
-      brw->gs.base.prog_data = NULL;
-
-      return;
-   }
-
-   struct gl_program *prog = &gp->program.Base;
-
-   memset(&key, 0, sizeof(key));
-
-   key.base.program_string_id = gp->id;
-   brw_setup_vec4_key_clip_info(brw, &key.base,
-                                gp->program.Base.UsesClipDistanceOut);
-
-   /* _NEW_LIGHT | _NEW_BUFFERS */
-   key.base.clamp_vertex_color = ctx->Light._ClampVertexColor;
-
-   /* _NEW_TEXTURE */
-   brw_populate_sampler_prog_key_data(ctx, prog, stage_state->sampler_count,
-                                      &key.base.tex);
-
-   /* BRW_NEW_VUE_MAP_VS */
-   key.input_varyings = brw->vue_map_vs.slots_valid;
-
-   if (!brw_search_cache(&brw->cache, BRW_GS_PROG,
-                         &key, sizeof(key),
-                         &stage_state->prog_offset, &brw->gs.prog_data)) {
-      bool success =
-         do_gs_prog(brw, ctx->_Shader->CurrentProgram[MESA_SHADER_GEOMETRY], gp,
-                    &key);
-      assert(success);
-      (void)success;
-   }
-   brw->gs.base.prog_data = &brw->gs.prog_data->base.base;
-
-   if (memcmp(&brw->vs.prog_data->base.vue_map, &brw->vue_map_geom_out,
-              sizeof(brw->vue_map_geom_out)) != 0) {
-      brw->vue_map_geom_out = brw->gs.prog_data->base.vue_map;
-      brw->state.dirty.brw |= BRW_NEW_VUE_MAP_GEOM_OUT;
-   }
-}
-
-
-const struct brw_tracked_state brw_gs_prog = {
-   .dirty = {
-      .mesa  = (_NEW_LIGHT | _NEW_BUFFERS | _NEW_TEXTURE),
-      .brw   = (BRW_NEW_GEOMETRY_PROGRAM |
-                BRW_NEW_VUE_MAP_VS |
-                BRW_NEW_TRANSFORM_FEEDBACK),
-   },
-   .emit = brw_upload_gs_prog
-};
-
-
-bool
-brw_gs_precompile(struct gl_context *ctx, struct gl_shader_program *prog)
-{
-   struct brw_context *brw = brw_context(ctx);
-   struct brw_gs_prog_key key;
-   uint32_t old_prog_offset = brw->gs.base.prog_offset;
-   struct brw_gs_prog_data *old_prog_data = brw->gs.prog_data;
-   bool success;
-
-   if (!prog->_LinkedShaders[MESA_SHADER_GEOMETRY])
-      return true;
-
-   struct gl_geometry_program *gp = (struct gl_geometry_program *)
-      prog->_LinkedShaders[MESA_SHADER_GEOMETRY]->Program;
-   struct brw_geometry_program *bgp = brw_geometry_program(gp);
-
-   memset(&key, 0, sizeof(key));
-
-   brw_vec4_setup_prog_key_for_precompile(ctx, &key.base, bgp->id, &gp->Base);
-
-   /* Assume that the set of varyings coming in from the vertex shader exactly
-    * matches what the geometry shader requires.
-    */
-   key.input_varyings = gp->Base.InputsRead;
-
-   success = do_gs_prog(brw, prog, bgp, &key);
-
-   brw->gs.base.prog_offset = old_prog_offset;
-   brw->gs.prog_data = old_prog_data;
-
-   return success;
-}
-
-
-bool
-brw_gs_prog_data_compare(const void *in_a, const void *in_b)
-{
-   const struct brw_gs_prog_data *a = in_a;
-   const struct brw_gs_prog_data *b = in_b;
-
-   /* Compare the base structure. */
-   if (!brw_stage_prog_data_compare(&a->base.base, &b->base.base))
-      return false;
-
-   /* Compare the rest of the struct. */
-   const unsigned offset = sizeof(struct brw_stage_prog_data);
-   if (memcmp(((char *) a) + offset, ((char *) b) + offset,
-              sizeof(struct brw_gs_prog_data) - offset)) {
-      return false;
-   }
-
-   return true;
-}
diff --git a/src/mesa/drivers/dri/i965/brw_vec4_gs.h b/src/mesa/drivers/dri/i965/brw_vec4_gs.h
deleted file mode 100644
index 5d4244e..0000000
--- a/src/mesa/drivers/dri/i965/brw_vec4_gs.h
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Copyright © 2013 Intel Corporation
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation
- * the rights to use, copy, modify, merge, publish, distribute, sublicense,
- * and/or sell copies of the Software, and to permit persons to whom the
- * Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice (including the next
- * paragraph) shall be included in all copies or substantial portions of the
- * Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
- * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
- * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
- * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
- * DEALINGS IN THE SOFTWARE.
- */
-
-#ifndef BRW_VEC4_GS_H
-#define BRW_VEC4_GS_H
-
-#include <stdbool.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-struct gl_context;
-struct gl_shader_program;
-
-bool brw_gs_precompile(struct gl_context *ctx, struct gl_shader_program *prog);
-bool brw_gs_prog_data_compare(const void *a, const void *b);
-
-#ifdef __cplusplus
-} /* extern "C" */
-#endif
-
-#endif /* BRW_VEC4_GS_H */
diff --git a/src/mesa/drivers/dri/i965/gen6_cc.c b/src/mesa/drivers/dri/i965/gen6_cc.c
index 45c926c..4770063 100644
--- a/src/mesa/drivers/dri/i965/gen6_cc.c
+++ b/src/mesa/drivers/dri/i965/gen6_cc.c
@@ -264,9 +264,12 @@ gen6_upload_color_calc_state(struct brw_context *brw)
    cc->cc0.alpha_test_format = BRW_ALPHATEST_FORMAT_UNORM8;
    UNCLAMPED_FLOAT_TO_UBYTE(cc->cc1.alpha_ref_fi.ui, ctx->Color.AlphaRef);
 
-   /* _NEW_STENCIL */
-   cc->cc0.stencil_ref = _mesa_get_stencil_ref(ctx, 0);
-   cc->cc0.bf_stencil_ref = _mesa_get_stencil_ref(ctx, ctx->Stencil._BackFace);
+   if (brw->gen < 9) {
+      /* _NEW_STENCIL */
+      cc->cc0.stencil_ref = _mesa_get_stencil_ref(ctx, 0);
+      cc->cc0.bf_stencil_ref =
+         _mesa_get_stencil_ref(ctx, ctx->Stencil._BackFace);
+   }
 
    /* _NEW_COLOR */
    cc->constant_r = ctx->Color.BlendColorUnclamped[0];
diff --git a/src/mesa/drivers/dri/i965/gen8_depth_state.c b/src/mesa/drivers/dri/i965/gen8_depth_state.c
index 7c3bfe0..e716141 100644
--- a/src/mesa/drivers/dri/i965/gen8_depth_state.c
+++ b/src/mesa/drivers/dri/i965/gen8_depth_state.c
@@ -28,6 +28,7 @@
 #include "brw_context.h"
 #include "brw_state.h"
 #include "brw_defines.h"
+#include "brw_wm.h"
 
 /**
  * Helper function to emit depth related command packets.
@@ -48,6 +49,8 @@ emit_depth_packets(struct brw_context *brw,
                    uint32_t lod,
                    uint32_t min_array_element)
 {
+   uint32_t mocs_wb = brw->gen >= 9 ? SKL_MOCS_WB : BDW_MOCS_WB;
+
    /* Skip repeated NULL depth/stencil emits (think 2D rendering). */
    if (!depth_mt && !stencil_mt && brw->no_depth_or_stencil) {
       assert(brw->hw_ctx);
@@ -73,7 +76,7 @@ emit_depth_packets(struct brw_context *brw,
       OUT_BATCH(0);
    }
    OUT_BATCH(((width - 1) << 4) | ((height - 1) << 18) | lod);
-   OUT_BATCH(((depth - 1) << 21) | (min_array_element << 10) | BDW_MOCS_WB);
+   OUT_BATCH(((depth - 1) << 21) | (min_array_element << 10) | mocs_wb);
    OUT_BATCH(0);
    OUT_BATCH(((depth - 1) << 21) | (depth_mt ? depth_mt->qpitch >> 2 : 0));
    ADVANCE_BATCH();
@@ -89,7 +92,7 @@ emit_depth_packets(struct brw_context *brw,
    } else {
       BEGIN_BATCH(5);
       OUT_BATCH(GEN7_3DSTATE_HIER_DEPTH_BUFFER << 16 | (5 - 2));
-      OUT_BATCH((depth_mt->hiz_mt->pitch - 1) | BDW_MOCS_WB << 25);
+      OUT_BATCH((depth_mt->hiz_mt->pitch - 1) | mocs_wb << 25);
       OUT_RELOC64(depth_mt->hiz_mt->bo,
                   I915_GEM_DOMAIN_RENDER, I915_GEM_DOMAIN_RENDER, 0);
       OUT_BATCH(depth_mt->hiz_mt->qpitch >> 2);
@@ -97,7 +100,7 @@ emit_depth_packets(struct brw_context *brw,
    }
 
    if (stencil_mt == NULL) {
-      BEGIN_BATCH(5);
+     BEGIN_BATCH(5);
       OUT_BATCH(GEN7_3DSTATE_STENCIL_BUFFER << 16 | (5 - 2));
       OUT_BATCH(0);
       OUT_BATCH(0);
@@ -121,7 +124,7 @@ emit_depth_packets(struct brw_context *brw,
        * page (which would imply that it does).  Experiments with the hardware
        * indicate that it does.
        */
-      OUT_BATCH(HSW_STENCIL_ENABLED | BDW_MOCS_WB << 22 |
+      OUT_BATCH(HSW_STENCIL_ENABLED | mocs_wb << 22 |
                 (2 * stencil_mt->pitch - 1));
       OUT_RELOC64(stencil_mt->bo,
                   I915_GEM_DOMAIN_RENDER, I915_GEM_DOMAIN_RENDER,
@@ -210,6 +213,172 @@ gen8_emit_depth_stencil_hiz(struct brw_context *brw,
 }
 
 /**
+ * Should we set the PMA FIX ENABLE bit?
+ *
+ * To avoid unnecessary depth related stalls, we need to set this bit.
+ * However, there is a very complicated formula which governs when it
+ * is legal to do so.  This function computes that.
+ *
+ * See the documenation for the CACHE_MODE_1 register, bit 11.
+ */
+static bool
+pma_fix_enable(const struct brw_context *brw)
+{
+   const struct gl_context *ctx = &brw->ctx;
+   /* BRW_NEW_FRAGMENT_PROGRAM */
+   const struct gl_fragment_program *fp = brw->fragment_program;
+   /* _NEW_BUFFERS */
+   struct intel_renderbuffer *depth_irb =
+      intel_get_renderbuffer(ctx->DrawBuffer, BUFFER_DEPTH);
+
+   /* 3DSTATE_WM::ForceThreadDispatch is never used. */
+   const bool wm_force_thread_dispatch = false;
+
+   /* 3DSTATE_RASTER::ForceSampleCount is never used. */
+   const bool raster_force_sample_count_nonzero = false;
+
+   /* _NEW_BUFFERS:
+    * 3DSTATE_DEPTH_BUFFER::SURFACE_TYPE != NULL &&
+    * 3DSTATE_DEPTH_BUFFER::HIZ Enable
+    */
+   const bool hiz_enabled = depth_irb && intel_renderbuffer_has_hiz(depth_irb);
+
+   /* 3DSTATE_WM::Early Depth/Stencil Control != EDSC_PREPS (2).
+    * We always leave this set to EDSC_NORMAL (0).
+    */
+   const bool edsc_not_preps = true;
+
+   /* 3DSTATE_PS_EXTRA::PixelShaderValid is always true. */
+   const bool pixel_shader_valid = true;
+
+   /* !(3DSTATE_WM_HZ_OP::DepthBufferClear ||
+    *   3DSTATE_WM_HZ_OP::DepthBufferResolve ||
+    *   3DSTATE_WM_HZ_OP::Hierarchical Depth Buffer Resolve Enable ||
+    *   3DSTATE_WM_HZ_OP::StencilBufferClear)
+    *
+    * HiZ operations are done outside of the normal state upload, so they're
+    * definitely not happening now.
+    */
+   const bool in_hiz_op = false;
+
+   /* _NEW_DEPTH:
+    * DEPTH_STENCIL_STATE::DepthTestEnable
+    */
+   const bool depth_test_enabled = depth_irb && ctx->Depth.Test;
+
+   /* _NEW_DEPTH:
+    * 3DSTATE_WM_DEPTH_STENCIL::DepthWriteEnable &&
+    * 3DSTATE_DEPTH_BUFFER::DEPTH_WRITE_ENABLE.
+    */
+   const bool depth_writes_enabled = ctx->Depth.Mask;
+
+   /* _NEW_STENCIL:
+    * !DEPTH_STENCIL_STATE::Stencil Buffer Write Enable ||
+    * !3DSTATE_DEPTH_BUFFER::Stencil Buffer Enable ||
+    * !3DSTATE_STENCIL_BUFFER::Stencil Buffer Enable
+    */
+   const bool stencil_writes_enabled = ctx->Stencil._WriteEnabled;
+
+   /* BRW_NEW_FRAGMENT_PROGRAM:
+    * 3DSTATE_PS_EXTRA::Pixel Shader Computed Depth Mode == PSCDEPTH_OFF
+    */
+   const bool ps_computes_depth =
+      (fp->Base.OutputsWritten & BITFIELD64_BIT(FRAG_RESULT_DEPTH)) &&
+      fp->FragDepthLayout != FRAG_DEPTH_LAYOUT_UNCHANGED;
+
+   /* BRW_NEW_FRAGMENT_PROGRAM: 3DSTATE_PS_EXTRA::PixelShaderKillsPixels
+    * CACHE_NEW_WM_PROG:        3DSTATE_PS_EXTRA::oMask Present to RenderTarget
+    * _NEW_MULTISAMPLE:         3DSTATE_PS_BLEND::AlphaToCoverageEnable
+    * _NEW_COLOR:               3DSTATE_PS_BLEND::AlphaTestEnable
+    *
+    * 3DSTATE_WM_CHROMAKEY::ChromaKeyKillEnable is always false.
+    * 3DSTATE_WM::ForceKillPix != ForceOff is always true.
+    */
+   const bool kill_pixel =
+      fp->UsesKill ||
+      brw->wm.prog_data->uses_omask ||
+      (ctx->Multisample._Enabled && ctx->Multisample.SampleAlphaToCoverage) ||
+      ctx->Color.AlphaEnabled;
+
+   /* The big formula in CACHE_MODE_1::NP PMA FIX ENABLE. */
+   return !wm_force_thread_dispatch &&
+          !raster_force_sample_count_nonzero &&
+          hiz_enabled &&
+          edsc_not_preps &&
+          pixel_shader_valid &&
+          !in_hiz_op &&
+          depth_test_enabled &&
+          (ps_computes_depth ||
+           (kill_pixel && (depth_writes_enabled || stencil_writes_enabled)));
+}
+
+static void
+write_pma_stall_bits(struct brw_context *brw, uint32_t pma_stall_bits)
+{
+   struct gl_context *ctx = &brw->ctx;
+
+   /* If we haven't actually changed the value, bail now to avoid unnecessary
+    * pipeline stalls and register writes.
+    */
+   if (brw->pma_stall_bits == pma_stall_bits)
+      return;
+
+   brw->pma_stall_bits = pma_stall_bits;
+
+   /* According to the PIPE_CONTROL documentation, software should emit a
+    * PIPE_CONTROL with the CS Stall and Depth Cache Flush bits set prior
+    * to the LRI.  If stencil buffer writes are enabled, then a Render Cache
+    * Flush is also necessary.
+    */
+   const uint32_t render_cache_flush =
+      ctx->Stencil._WriteEnabled ? PIPE_CONTROL_WRITE_FLUSH : 0;
+   brw_emit_pipe_control_flush(brw,
+                               PIPE_CONTROL_CS_STALL |
+                               PIPE_CONTROL_DEPTH_CACHE_FLUSH |
+                               render_cache_flush);
+
+   /* CACHE_MODE_1 is a non-privileged register. */
+   BEGIN_BATCH(3);
+   OUT_BATCH(MI_LOAD_REGISTER_IMM | (3 - 2));
+   OUT_BATCH(GEN7_CACHE_MODE_1);
+   OUT_BATCH(GEN8_HIZ_PMA_MASK_BITS | pma_stall_bits);
+   ADVANCE_BATCH();
+
+   /* After the LRI, a PIPE_CONTROL with both the Depth Stall and Depth Cache
+    * Flush bits is often necessary.  We do it regardless because it's easier.
+    * The render cache flush is also necessary if stencil writes are enabled.
+    */
+   brw_emit_pipe_control_flush(brw,
+                               PIPE_CONTROL_DEPTH_STALL |
+                               PIPE_CONTROL_DEPTH_CACHE_FLUSH |
+                               render_cache_flush);
+
+}
+
+static void
+gen8_emit_pma_stall_workaround(struct brw_context *brw)
+{
+   uint32_t bits = 0;
+   if (pma_fix_enable(brw))
+      bits |= GEN8_HIZ_NP_PMA_FIX_ENABLE | GEN8_HIZ_NP_EARLY_Z_FAILS_DISABLE;
+
+   write_pma_stall_bits(brw, bits);
+}
+
+const struct brw_tracked_state gen8_pma_fix = {
+   .dirty = {
+      .mesa = _NEW_BUFFERS |
+              _NEW_COLOR |
+              _NEW_DEPTH |
+              _NEW_MULTISAMPLE |
+              _NEW_STENCIL,
+      .brw = BRW_NEW_FRAGMENT_PROGRAM,
+      .cache = CACHE_NEW_WM_PROG,
+   },
+   .emit = gen8_emit_pma_stall_workaround
+};
+
+/**
  * Emit packets to perform a depth/HiZ resolve or fast depth/stencil clear.
  *
  * See the "Optimized Depth Buffer Clear and/or Stencil Buffer Clear" section
@@ -222,6 +391,9 @@ gen8_hiz_exec(struct brw_context *brw, struct intel_mipmap_tree *mt,
    if (op == GEN6_HIZ_OP_NONE)
       return;
 
+   /* Disable the PMA stall fix since we're about to do a HiZ operation. */
+   write_pma_stall_bits(brw, 0);
+
    assert(mt->first_level == 0);
    assert(mt->logical_depth0 >= 1);
 
diff --git a/src/mesa/drivers/dri/i965/gen8_disable.c b/src/mesa/drivers/dri/i965/gen8_disable.c
index 276bd2e..0839a49 100644
--- a/src/mesa/drivers/dri/i965/gen8_disable.c
+++ b/src/mesa/drivers/dri/i965/gen8_disable.c
@@ -92,16 +92,11 @@ disable_stages(struct brw_context *brw)
    OUT_BATCH(0);
    ADVANCE_BATCH();
 
-   BEGIN_BATCH(9);
-   OUT_BATCH(_3DSTATE_DS << 16 | (9 - 2));
-   OUT_BATCH(0);
-   OUT_BATCH(0);
-   OUT_BATCH(0);
-   OUT_BATCH(0);
-   OUT_BATCH(0);
-   OUT_BATCH(0);
-   OUT_BATCH(0);
-   OUT_BATCH(0);
+   int ds_pkt_len = brw->gen >= 9 ? 11 : 9;
+   BEGIN_BATCH(ds_pkt_len);
+   OUT_BATCH(_3DSTATE_DS << 16 | (ds_pkt_len - 2));
+   for (int i = 0; i < ds_pkt_len - 1; i++)
+      OUT_BATCH(0);
    ADVANCE_BATCH();
 
    BEGIN_BATCH(2);
diff --git a/src/mesa/drivers/dri/i965/gen8_draw_upload.c b/src/mesa/drivers/dri/i965/gen8_draw_upload.c
index 8f0e515..3189a3e 100644
--- a/src/mesa/drivers/dri/i965/gen8_draw_upload.c
+++ b/src/mesa/drivers/dri/i965/gen8_draw_upload.c
@@ -39,6 +39,7 @@ static void
 gen8_emit_vertices(struct brw_context *brw)
 {
    struct gl_context *ctx = &brw->ctx;
+   uint32_t mocs_wb = brw->gen >= 9 ? SKL_MOCS_WB : BDW_MOCS_WB;
 
    brw_prepare_vertices(brw);
    brw_prepare_shader_draw_parameters(brw);
@@ -119,7 +120,7 @@ gen8_emit_vertices(struct brw_context *brw)
          dw0 |= i << GEN6_VB0_INDEX_SHIFT;
          dw0 |= GEN7_VB0_ADDRESS_MODIFYENABLE;
          dw0 |= buffer->stride << BRW_VB0_PITCH_SHIFT;
-         dw0 |= BDW_MOCS_WB << 16;
+         dw0 |= mocs_wb << 16;
 
          OUT_BATCH(dw0);
          OUT_RELOC64(buffer->bo, I915_GEM_DOMAIN_VERTEX, 0, buffer->offset);
@@ -129,7 +130,7 @@ gen8_emit_vertices(struct brw_context *brw)
       if (brw->vs.prog_data->uses_vertexid) {
          OUT_BATCH(brw->vb.nr_buffers << GEN6_VB0_INDEX_SHIFT |
                    GEN7_VB0_ADDRESS_MODIFYENABLE |
-                   BDW_MOCS_WB << 16);
+                   mocs_wb << 16);
          OUT_RELOC64(brw->draw.draw_params_bo, I915_GEM_DOMAIN_VERTEX, 0,
                      brw->draw.draw_params_offset);
          OUT_BATCH(brw->draw.draw_params_bo->size);
@@ -242,13 +243,14 @@ static void
 gen8_emit_index_buffer(struct brw_context *brw)
 {
    const struct _mesa_index_buffer *index_buffer = brw->ib.ib;
+   uint32_t mocs_wb = brw->gen >= 9 ? SKL_MOCS_WB : BDW_MOCS_WB;
 
    if (index_buffer == NULL)
       return;
 
    BEGIN_BATCH(5);
    OUT_BATCH(CMD_INDEX_BUFFER << 16 | (5 - 2));
-   OUT_BATCH(brw_get_index_type(index_buffer->type) << 8 | BDW_MOCS_WB);
+   OUT_BATCH(brw_get_index_type(index_buffer->type) << 8 | mocs_wb);
    OUT_RELOC64(brw->ib.bo, I915_GEM_DOMAIN_VERTEX, 0, 0);
    OUT_BATCH(brw->ib.bo->size);
    ADVANCE_BATCH();
diff --git a/src/mesa/drivers/dri/i965/gen8_misc_state.c b/src/mesa/drivers/dri/i965/gen8_misc_state.c
index 3c27c1a..723d227 100644
--- a/src/mesa/drivers/dri/i965/gen8_misc_state.c
+++ b/src/mesa/drivers/dri/i965/gen8_misc_state.c
@@ -31,25 +31,31 @@
  */
 static void upload_state_base_address(struct brw_context *brw)
 {
-   BEGIN_BATCH(16);
-   OUT_BATCH(CMD_STATE_BASE_ADDRESS << 16 | (16 - 2));
+   uint32_t mocs_wb = brw->gen >= 9 ? SKL_MOCS_WB : BDW_MOCS_WB;
+
+   perf_debug("Missing MOCS setup for STATE_BASE_ADDRESS.");
+
+   int pkt_len = brw->gen >= 9 ? 19 : 16;
+
+   BEGIN_BATCH(pkt_len);
+   OUT_BATCH(CMD_STATE_BASE_ADDRESS << 16 | (pkt_len - 2));
    /* General state base address: stateless DP read/write requests */
-   OUT_BATCH(BDW_MOCS_WB << 4 | 1);
+   OUT_BATCH(mocs_wb << 4 | 1);
    OUT_BATCH(0);
-   OUT_BATCH(BDW_MOCS_WB << 16);
+   OUT_BATCH(mocs_wb << 16);
    /* Surface state base address: */
    OUT_RELOC64(brw->batch.bo, I915_GEM_DOMAIN_SAMPLER, 0,
-               BDW_MOCS_WB << 4 | 1);
+               mocs_wb << 4 | 1);
    /* Dynamic state base address: */
    OUT_RELOC64(brw->batch.bo,
                I915_GEM_DOMAIN_RENDER | I915_GEM_DOMAIN_INSTRUCTION, 0,
-               BDW_MOCS_WB << 4 | 1);
+               mocs_wb << 4 | 1);
    /* Indirect object base address: MEDIA_OBJECT data */
-   OUT_BATCH(BDW_MOCS_WB << 4 | 1);
+   OUT_BATCH(mocs_wb << 4 | 1);
    OUT_BATCH(0);
    /* Instruction base address: shader kernels (incl. SIP) */
    OUT_RELOC64(brw->cache.bo, I915_GEM_DOMAIN_INSTRUCTION, 0,
-               BDW_MOCS_WB << 4 | 1);
+               mocs_wb << 4 | 1);
 
    /* General state buffer size */
    OUT_BATCH(0xfffff001);
@@ -59,6 +65,11 @@ static void upload_state_base_address(struct brw_context *brw)
    OUT_BATCH(0xfffff001);
    /* Instruction access upper bound */
    OUT_BATCH(ALIGN(brw->cache.bo->size, 4096) | 1);
+   if (brw->gen >= 9) {
+      OUT_BATCH(1);
+      OUT_BATCH(0);
+      OUT_BATCH(0);
+   }
    ADVANCE_BATCH();
 
    brw->state.dirty.brw |= BRW_NEW_STATE_BASE_ADDRESS;
diff --git a/src/mesa/drivers/dri/i965/gen8_sf_state.c b/src/mesa/drivers/dri/i965/gen8_sf_state.c
index 555e6a8..1d7b932 100644
--- a/src/mesa/drivers/dri/i965/gen8_sf_state.c
+++ b/src/mesa/drivers/dri/i965/gen8_sf_state.c
@@ -39,10 +39,13 @@ upload_sbe(struct brw_context *brw)
    uint32_t urb_entry_read_length;
    uint32_t point_sprite_enables;
    uint32_t flat_enables;
+   int sbe_cmd_length;
 
    uint32_t dw1 =
       GEN7_SBE_SWIZZLE_ENABLE |
       num_outputs << GEN7_SBE_NUM_OUTPUTS_SHIFT;
+   uint32_t dw4 = 0;
+   uint32_t dw5 = 0;
 
    /* _NEW_BUFFERS */
    bool render_to_fbo = _mesa_is_user_fbo(ctx->DrawBuffer);
@@ -79,11 +82,34 @@ upload_sbe(struct brw_context *brw)
       GEN8_SBE_FORCE_URB_ENTRY_READ_LENGTH |
       GEN8_SBE_FORCE_URB_ENTRY_READ_OFFSET;
 
-   BEGIN_BATCH(4);
-   OUT_BATCH(_3DSTATE_SBE << 16 | (4 - 2));
+   if (brw->gen == 8) {
+      sbe_cmd_length = 4;
+   } else {
+      sbe_cmd_length = 6;
+
+      /* prepare the active component dwords */
+      int input_index = 0;
+      for (int attr = 0; attr < VARYING_SLOT_MAX; attr++) {
+         if (!(brw->fragment_program->Base.InputsRead & BITFIELD64_BIT(attr)))
+            continue;
+
+         if (input_index < 16)
+            dw4 |= (GEN9_SBE_ACTIVE_COMPONENT_XYZW << (input_index << 1));
+         else
+            dw5 |= (GEN9_SBE_ACTIVE_COMPONENT_XYZW << (input_index << 1));
+
+         ++input_index;
+      }
+   }
+   BEGIN_BATCH(sbe_cmd_length);
+   OUT_BATCH(_3DSTATE_SBE << 16 | (sbe_cmd_length - 2));
    OUT_BATCH(dw1);
    OUT_BATCH(point_sprite_enables);
    OUT_BATCH(flat_enables);
+   if (sbe_cmd_length >= 6) {
+      OUT_BATCH(dw4);
+      OUT_BATCH(dw5);
+   }
    ADVANCE_BATCH();
 
    BEGIN_BATCH(11);
@@ -265,8 +291,14 @@ upload_raster(struct brw_context *brw)
       dw1 |= GEN8_RASTER_SCISSOR_ENABLE;
 
    /* _NEW_TRANSFORM */
-   if (!ctx->Transform.DepthClamp)
-      dw1 |= GEN8_RASTER_VIEWPORT_Z_CLIP_TEST_ENABLE;
+   if (!ctx->Transform.DepthClamp) {
+      if (brw->gen >= 9) {
+         dw1 |= GEN9_RASTER_VIEWPORT_Z_NEAR_CLIP_TEST_ENABLE |
+                GEN9_RASTER_VIEWPORT_Z_FAR_CLIP_TEST_ENABLE;
+      } else {
+         dw1 |= GEN8_RASTER_VIEWPORT_Z_CLIP_TEST_ENABLE;
+      }
+   }
 
    BEGIN_BATCH(5);
    OUT_BATCH(_3DSTATE_RASTER << 16 | (5 - 2));
diff --git a/src/mesa/drivers/dri/i965/gen8_sol_state.c b/src/mesa/drivers/dri/i965/gen8_sol_state.c
index ebcdaf8..555adcb 100644
--- a/src/mesa/drivers/dri/i965/gen8_sol_state.c
+++ b/src/mesa/drivers/dri/i965/gen8_sol_state.c
@@ -44,6 +44,7 @@ gen8_upload_3dstate_so_buffers(struct brw_context *brw)
       ctx->TransformFeedback.CurrentObject;
    struct brw_transform_feedback_object *brw_obj =
       (struct brw_transform_feedback_object *) xfb_obj;
+   uint32_t mocs_wb = brw->gen >= 9 ? SKL_MOCS_WB : BDW_MOCS_WB;
 
    /* Set up the up to 4 output buffers.  These are the ranges defined in the
     * gl_transform_feedback_object.
@@ -80,7 +81,7 @@ gen8_upload_3dstate_so_buffers(struct brw_context *brw)
       OUT_BATCH(GEN8_SO_BUFFER_ENABLE | (i << SO_BUFFER_INDEX_SHIFT) |
                 GEN8_SO_BUFFER_OFFSET_WRITE_ENABLE |
                 GEN8_SO_BUFFER_OFFSET_ADDRESS_ENABLE |
-                (BDW_MOCS_WB << 22));
+                (mocs_wb << 22));
       OUT_RELOC64(bo, I915_GEM_DOMAIN_RENDER, I915_GEM_DOMAIN_RENDER, start);
       OUT_BATCH(xfb_obj->Size[i] / 4 - 1);
       OUT_RELOC64(brw_obj->offset_bo,
diff --git a/src/mesa/drivers/dri/i965/gen8_surface_state.c b/src/mesa/drivers/dri/i965/gen8_surface_state.c
index 6dd343f..56c46b0 100644
--- a/src/mesa/drivers/dri/i965/gen8_surface_state.c
+++ b/src/mesa/drivers/dri/i965/gen8_surface_state.c
@@ -81,6 +81,16 @@ horizontal_alignment(struct intel_mipmap_tree *mt)
    }
 }
 
+static uint32_t *
+allocate_surface_state(struct brw_context *brw, uint32_t *out_offset)
+{
+   int dwords = brw->gen >= 9 ? 16 : 13;
+   uint32_t *surf = brw_state_batch(brw, AUB_TRACE_SURFACE_STATE,
+                                    dwords * 4, 64, out_offset);
+   memset(surf, 0, dwords * 4);
+   return surf;
+}
+
 static void
 gen8_emit_buffer_surface_state(struct brw_context *brw,
                                uint32_t *out_offset,
@@ -92,9 +102,7 @@ gen8_emit_buffer_surface_state(struct brw_context *brw,
                                unsigned mocs,
                                bool rw)
 {
-   uint32_t *surf = brw_state_batch(brw, AUB_TRACE_SURFACE_STATE,
-                                    13 * 4, 64, out_offset);
-   memset(surf, 0, 13 * 4);
+   uint32_t *surf = allocate_surface_state(brw, out_offset);
 
    surf[0] = BRW_SURFACE_BUFFER << BRW_SURFACE_TYPE_SHIFT |
              surface_format << BRW_SURFACE_FORMAT_SHIFT |
@@ -135,6 +143,7 @@ gen8_update_texture_surface(struct gl_context *ctx,
    struct intel_mipmap_tree *aux_mt = NULL;
    uint32_t aux_mode = 0;
    mesa_format format = intelObj->_Format;
+   uint32_t mocs_wb = brw->gen >= 9 ? SKL_MOCS_WB : BDW_MOCS_WB;
 
    if (tObj->Target == GL_TEXTURE_BUFFER) {
       brw_update_buffer_texture_surface(ctx, unit, surf_offset);
@@ -169,8 +178,7 @@ gen8_update_texture_surface(struct gl_context *ctx,
 
    uint32_t tex_format = translate_tex_format(brw, format, sampler->sRGBDecode);
 
-   uint32_t *surf = brw_state_batch(brw, AUB_TRACE_SURFACE_STATE,
-                                    13 * 4, 64, surf_offset);
+   uint32_t *surf = allocate_surface_state(brw, surf_offset);
 
    surf[0] = translate_tex_target(tObj->Target) << BRW_SURFACE_TYPE_SHIFT |
              tex_format << BRW_SURFACE_FORMAT_SHIFT |
@@ -186,7 +194,7 @@ gen8_update_texture_surface(struct gl_context *ctx,
    if (mt->logical_depth0 > 1 && tObj->Target != GL_TEXTURE_3D)
       surf[0] |= GEN8_SURFACE_IS_ARRAY;
 
-   surf[1] = SET_FIELD(BDW_MOCS_WB, GEN8_SURFACE_MOCS) | mt->qpitch >> 2;
+   surf[1] = SET_FIELD(mocs_wb, GEN8_SURFACE_MOCS) | mt->qpitch >> 2;
 
    surf[2] = SET_FIELD(mt->logical_width0 - 1, GEN7_SURFACE_WIDTH) |
              SET_FIELD(mt->logical_height0 - 1, GEN7_SURFACE_HEIGHT);
@@ -283,9 +291,8 @@ gen8_update_null_renderbuffer_surface(struct brw_context *brw, unsigned unit)
    uint32_t surf_index =
       brw->wm.prog_data->binding_table.render_target_start + unit;
 
-   uint32_t *surf = brw_state_batch(brw, AUB_TRACE_SURFACE_STATE, 13 * 4, 64,
-                                    &brw->wm.base.surf_offset[surf_index]);
-   memset(surf, 0, 13 * 4);
+   uint32_t *surf =
+      allocate_surface_state(brw, &brw->wm.base.surf_offset[surf_index]);
 
    surf[0] = BRW_SURFACE_NULL << BRW_SURFACE_TYPE_SHIFT |
              BRW_SURFACEFORMAT_B8G8R8A8_UNORM << BRW_SURFACE_FORMAT_SHIFT |
@@ -322,9 +329,10 @@ gen8_update_renderbuffer_surface(struct brw_context *brw,
       irb->mt_layer : (irb->mt_layer / MAX2(mt->num_samples, 1));
    GLenum gl_target =
       rb->TexImage ? rb->TexImage->TexObject->Target : GL_TEXTURE_2D;
-
    uint32_t surf_index =
       brw->wm.prog_data->binding_table.render_target_start + unit;
+   /* FINISHME: Use PTE MOCS on Skylake. */
+   uint32_t mocs = brw->gen >= 9 ? SKL_MOCS_WT : BDW_MOCS_PTE;
 
    intel_miptree_used_for_rendering(mt);
 
@@ -367,8 +375,8 @@ gen8_update_renderbuffer_surface(struct brw_context *brw,
       aux_mode = GEN8_SURFACE_AUX_MODE_MCS;
    }
 
-   uint32_t *surf = brw_state_batch(brw, AUB_TRACE_SURFACE_STATE, 13 * 4, 64,
-                                    &brw->wm.base.surf_offset[surf_index]);
+   uint32_t *surf =
+      allocate_surface_state(brw, &brw->wm.base.surf_offset[surf_index]);
 
    surf[0] = (surf_type << BRW_SURFACE_TYPE_SHIFT) |
              (is_array ? GEN7_SURFACE_IS_ARRAY : 0) |
@@ -377,7 +385,7 @@ gen8_update_renderbuffer_surface(struct brw_context *brw,
              horizontal_alignment(mt) |
              surface_tiling_mode(tiling);
 
-   surf[1] = SET_FIELD(BDW_MOCS_PTE, GEN8_SURFACE_MOCS) | mt->qpitch >> 2;
+   surf[1] = SET_FIELD(mocs, GEN8_SURFACE_MOCS) | mt->qpitch >> 2;
 
    surf[2] = SET_FIELD(width - 1, GEN7_SURFACE_WIDTH) |
              SET_FIELD(height - 1, GEN7_SURFACE_HEIGHT);
diff --git a/src/mesa/drivers/dri/i965/gen8_wm_depth_stencil.c b/src/mesa/drivers/dri/i965/gen8_wm_depth_stencil.c
index 8f5728f..38212cd 100644
--- a/src/mesa/drivers/dri/i965/gen8_wm_depth_stencil.c
+++ b/src/mesa/drivers/dri/i965/gen8_wm_depth_stencil.c
@@ -26,12 +26,13 @@
 #include "brw_context.h"
 #include "brw_defines.h"
 #include "brw_state.h"
+#include "main/stencil.h"
 
 static void
 gen8_upload_wm_depth_stencil(struct brw_context *brw)
 {
    struct gl_context *ctx = &brw->ctx;
-   uint32_t dw1 = 0, dw2 = 0;
+   uint32_t dw1 = 0, dw2 = 0, dw3 = 0;
 
    /* _NEW_BUFFERS */
    struct intel_renderbuffer *depth_irb =
@@ -73,6 +74,14 @@ gen8_upload_wm_depth_stencil(struct brw_context *brw)
                 SET_FIELD(stencil->ValueMask[b] & 0xff,
                           GEN8_WM_DS_BF_STENCIL_TEST_MASK);
       }
+
+      if (brw->gen >= 9) {
+         int stencil_ref  = _mesa_get_stencil_ref(ctx, 0);
+         int backface_ref = _mesa_get_stencil_ref(ctx, ctx->Stencil._BackFace);
+
+         dw3 = SET_FIELD(stencil_ref, GEN9_WM_DS_STENCIL_REF) |
+               SET_FIELD(backface_ref, GEN9_WM_DS_BF_STENCIL_REF);
+      }
    }
 
    /* _NEW_DEPTH */
@@ -85,10 +94,15 @@ gen8_upload_wm_depth_stencil(struct brw_context *brw)
          dw1 |= GEN8_WM_DS_DEPTH_BUFFER_WRITE_ENABLE;
    }
 
-   BEGIN_BATCH(3);
-   OUT_BATCH(_3DSTATE_WM_DEPTH_STENCIL << 16 | (3 - 2));
+   int pkt_len = brw->gen >= 9 ? 4 : 3;
+
+   BEGIN_BATCH(pkt_len);
+   OUT_BATCH(_3DSTATE_WM_DEPTH_STENCIL << 16 | (pkt_len - 2));
    OUT_BATCH(dw1);
    OUT_BATCH(dw2);
+   if (pkt_len > 3) {
+      OUT_BATCH(dw3);
+   }
    ADVANCE_BATCH();
 }
 
diff --git a/src/mesa/drivers/dri/i965/intel_batchbuffer.c b/src/mesa/drivers/dri/i965/intel_batchbuffer.c
index 71dc268..cd45af6 100644
--- a/src/mesa/drivers/dri/i965/intel_batchbuffer.c
+++ b/src/mesa/drivers/dri/i965/intel_batchbuffer.c
@@ -648,6 +648,15 @@ intel_batchbuffer_emit_mi_flush(struct brw_context *brw)
    } else {
       int flags = PIPE_CONTROL_NO_WRITE | PIPE_CONTROL_WRITE_FLUSH;
       if (brw->gen >= 6) {
+         if (brw->gen == 9) {
+            /* Hardware workaround: SKL
+             *
+             * Emit Pipe Control with all bits set to zero before emitting
+             * a Pipe Control with VF Cache Invalidate set.
+             */
+            brw_emit_pipe_control_flush(brw, 0);
+         }
+
          flags |= PIPE_CONTROL_INSTRUCTION_FLUSH |
                   PIPE_CONTROL_DEPTH_CACHE_FLUSH |
                   PIPE_CONTROL_VF_CACHE_INVALIDATE |
diff --git a/src/mesa/drivers/dri/i965/intel_buffer_objects.c b/src/mesa/drivers/dri/i965/intel_buffer_objects.c
index a7242b0..f2d2bcb 100644
--- a/src/mesa/drivers/dri/i965/intel_buffer_objects.c
+++ b/src/mesa/drivers/dri/i965/intel_buffer_objects.c
@@ -81,12 +81,8 @@ brw_bo_map_gtt(struct brw_context *brw, drm_intel_bo *bo, const char *bo_name)
    return ret;
 }
 
-static GLboolean
-intel_bufferobj_unmap(struct gl_context * ctx, struct gl_buffer_object *obj,
-                      gl_map_buffer_index index);
-
 static void
-intel_bufferobj_mark_gpu_usage(struct intel_buffer_object *intel_obj,
+mark_buffer_gpu_usage(struct intel_buffer_object *intel_obj,
                                uint32_t offset, uint32_t size)
 {
    intel_obj->gpu_active_start = MIN2(intel_obj->gpu_active_start, offset);
@@ -94,7 +90,7 @@ intel_bufferobj_mark_gpu_usage(struct intel_buffer_object *intel_obj,
 }
 
 static void
-intel_bufferobj_mark_inactive(struct intel_buffer_object *intel_obj)
+mark_buffer_inactive(struct intel_buffer_object *intel_obj)
 {
    intel_obj->gpu_active_start = ~0;
    intel_obj->gpu_active_end = 0;
@@ -102,8 +98,8 @@ intel_bufferobj_mark_inactive(struct intel_buffer_object *intel_obj)
 
 /** Allocates a new drm_intel_bo to store the data for the buffer object. */
 static void
-intel_bufferobj_alloc_buffer(struct brw_context *brw,
-			     struct intel_buffer_object *intel_obj)
+alloc_buffer_object(struct brw_context *brw,
+                    struct intel_buffer_object *intel_obj)
 {
    intel_obj->buffer = drm_intel_bo_alloc(brw->bufmgr, "bufferobj",
 					  intel_obj->Base.Size, 64);
@@ -117,7 +113,7 @@ intel_bufferobj_alloc_buffer(struct brw_context *brw,
    if (intel_obj->Base.UsageHistory & USAGE_ATOMIC_COUNTER_BUFFER)
       brw->state.dirty.brw |= BRW_NEW_ATOMIC_BUFFER;
 
-   intel_bufferobj_mark_inactive(intel_obj);
+   mark_buffer_inactive(intel_obj);
 }
 
 static void
@@ -138,7 +134,7 @@ release_buffer(struct intel_buffer_object *intel_obj)
  * internal structure where somehow shared.
  */
 static struct gl_buffer_object *
-intel_bufferobj_alloc(struct gl_context * ctx, GLuint name)
+brw_new_buffer_object(struct gl_context * ctx, GLuint name)
 {
    struct intel_buffer_object *obj = CALLOC_STRUCT(intel_buffer_object);
    if (!obj) {
@@ -158,7 +154,7 @@ intel_bufferobj_alloc(struct gl_context * ctx, GLuint name)
  * Deletes a single OpenGL buffer object.  Used by glDeleteBuffers().
  */
 static void
-intel_bufferobj_free(struct gl_context * ctx, struct gl_buffer_object *obj)
+brw_delete_buffer(struct gl_context * ctx, struct gl_buffer_object *obj)
 {
    struct intel_buffer_object *intel_obj = intel_buffer_object(obj);
 
@@ -186,13 +182,13 @@ intel_bufferobj_free(struct gl_context * ctx, struct gl_buffer_object *obj)
  * \return true for success, false if out of memory
  */
 static GLboolean
-intel_bufferobj_data(struct gl_context * ctx,
-                     GLenum target,
-                     GLsizeiptrARB size,
-                     const GLvoid * data,
-                     GLenum usage,
-                     GLbitfield storageFlags,
-                     struct gl_buffer_object *obj)
+brw_buffer_data(struct gl_context *ctx,
+                GLenum target,
+                GLsizeiptrARB size,
+                const GLvoid *data,
+                GLenum usage,
+                GLbitfield storageFlags,
+                struct gl_buffer_object *obj)
 {
    struct brw_context *brw = brw_context(ctx);
    struct intel_buffer_object *intel_obj = intel_buffer_object(obj);
@@ -212,7 +208,7 @@ intel_bufferobj_data(struct gl_context * ctx,
       release_buffer(intel_obj);
 
    if (size != 0) {
-      intel_bufferobj_alloc_buffer(brw, intel_obj);
+      alloc_buffer_object(brw, intel_obj);
       if (!intel_obj->buffer)
          return false;
 
@@ -234,10 +230,11 @@ intel_bufferobj_data(struct gl_context * ctx,
  * the buffer or if data is NULL, no copy is performed.
  */
 static void
-intel_bufferobj_subdata(struct gl_context * ctx,
-                        GLintptrARB offset,
-                        GLsizeiptrARB size,
-                        const GLvoid * data, struct gl_buffer_object *obj)
+brw_buffer_subdata(struct gl_context *ctx,
+                   GLintptrARB offset,
+                   GLsizeiptrARB size,
+                   const GLvoid *data,
+                   struct gl_buffer_object *obj)
 {
    struct brw_context *brw = brw_context(ctx);
    struct intel_buffer_object *intel_obj = intel_buffer_object(obj);
@@ -278,7 +275,7 @@ intel_bufferobj_subdata(struct gl_context * ctx,
       if (size == intel_obj->Base.Size) {
 	 /* Replace the current busy bo so the subdata doesn't stall. */
 	 drm_intel_bo_unreference(intel_obj->buffer);
-	 intel_bufferobj_alloc_buffer(brw, intel_obj);
+	 alloc_buffer_object(brw, intel_obj);
       } else if (!intel_obj->prefer_stall_to_blit) {
          perf_debug("Using a blit copy to avoid stalling on "
                     "glBufferSubData(%ld, %ld) (%ldkb) to a busy "
@@ -310,7 +307,7 @@ intel_bufferobj_subdata(struct gl_context * ctx,
    }
 
    drm_intel_bo_subdata(intel_obj->buffer, offset, size, data);
-   intel_bufferobj_mark_inactive(intel_obj);
+   mark_buffer_inactive(intel_obj);
 }
 
 
@@ -321,10 +318,11 @@ intel_bufferobj_subdata(struct gl_context * ctx,
  * object into user memory.
  */
 static void
-intel_bufferobj_get_subdata(struct gl_context * ctx,
-                            GLintptrARB offset,
-                            GLsizeiptrARB size,
-                            GLvoid * data, struct gl_buffer_object *obj)
+brw_get_buffer_subdata(struct gl_context *ctx,
+                       GLintptrARB offset,
+                       GLsizeiptrARB size,
+                       GLvoid *data,
+                       struct gl_buffer_object *obj)
 {
    struct intel_buffer_object *intel_obj = intel_buffer_object(obj);
    struct brw_context *brw = brw_context(ctx);
@@ -335,7 +333,7 @@ intel_bufferobj_get_subdata(struct gl_context * ctx,
    }
    drm_intel_bo_get_subdata(intel_obj->buffer, offset, size, data);
 
-   intel_bufferobj_mark_inactive(intel_obj);
+   mark_buffer_inactive(intel_obj);
 }
 
 
@@ -358,10 +356,10 @@ intel_bufferobj_get_subdata(struct gl_context * ctx,
  * and blit it into the real BO at unmap time.
  */
 static void *
-intel_bufferobj_map_range(struct gl_context * ctx,
-			  GLintptr offset, GLsizeiptr length,
-			  GLbitfield access, struct gl_buffer_object *obj,
-                          gl_map_buffer_index index)
+brw_map_buffer_range(struct gl_context *ctx,
+                     GLintptr offset, GLsizeiptr length,
+                     GLbitfield access, struct gl_buffer_object *obj,
+                     gl_map_buffer_index index)
 {
    struct brw_context *brw = brw_context(ctx);
    struct intel_buffer_object *intel_obj = intel_buffer_object(obj);
@@ -392,7 +390,7 @@ intel_bufferobj_map_range(struct gl_context * ctx,
       if (drm_intel_bo_references(brw->batch.bo, intel_obj->buffer)) {
 	 if (access & GL_MAP_INVALIDATE_BUFFER_BIT) {
 	    drm_intel_bo_unreference(intel_obj->buffer);
-	    intel_bufferobj_alloc_buffer(brw, intel_obj);
+	    alloc_buffer_object(brw, intel_obj);
 	 } else {
             perf_debug("Stalling on the GPU for mapping a busy buffer "
                        "object\n");
@@ -401,7 +399,7 @@ intel_bufferobj_map_range(struct gl_context * ctx,
       } else if (drm_intel_bo_busy(intel_obj->buffer) &&
 		 (access & GL_MAP_INVALIDATE_BUFFER_BIT)) {
 	 drm_intel_bo_unreference(intel_obj->buffer);
-	 intel_bufferobj_alloc_buffer(brw, intel_obj);
+	 alloc_buffer_object(brw, intel_obj);
       }
    }
 
@@ -444,11 +442,11 @@ intel_bufferobj_map_range(struct gl_context * ctx,
    else if (!brw->has_llc && (!(access & GL_MAP_READ_BIT) ||
                               (access & GL_MAP_PERSISTENT_BIT))) {
       drm_intel_gem_bo_map_gtt(intel_obj->buffer);
-      intel_bufferobj_mark_inactive(intel_obj);
+      mark_buffer_inactive(intel_obj);
    } else {
       brw_bo_map(brw, intel_obj->buffer, (access & GL_MAP_WRITE_BIT) != 0,
                  "MapBufferRange");
-      intel_bufferobj_mark_inactive(intel_obj);
+      mark_buffer_inactive(intel_obj);
    }
 
    obj->Mappings[index].Pointer = intel_obj->buffer->virtual + offset;
@@ -469,10 +467,10 @@ intel_bufferobj_map_range(struct gl_context * ctx,
  * would defeat the point.
  */
 static void
-intel_bufferobj_flush_mapped_range(struct gl_context *ctx,
-				   GLintptr offset, GLsizeiptr length,
-				   struct gl_buffer_object *obj,
-                                   gl_map_buffer_index index)
+brw_flush_mapped_buffer_range(struct gl_context *ctx,
+                              GLintptr offset, GLsizeiptr length,
+                              struct gl_buffer_object *obj,
+                              gl_map_buffer_index index)
 {
    struct brw_context *brw = brw_context(ctx);
    struct intel_buffer_object *intel_obj = intel_buffer_object(obj);
@@ -517,9 +515,9 @@ intel_bufferobj_flush_mapped_range(struct gl_context *ctx,
 			  intel_obj->range_map_bo[index],
                           intel_obj->map_extra[index] + offset,
 			  length);
-   intel_bufferobj_mark_gpu_usage(intel_obj,
-                                  obj->Mappings[index].Offset + offset,
-                                  length);
+   mark_buffer_gpu_usage(intel_obj,
+                         obj->Mappings[index].Offset + offset,
+                         length);
 }
 
 
@@ -529,8 +527,9 @@ intel_bufferobj_flush_mapped_range(struct gl_context *ctx,
  * Implements glUnmapBuffer().
  */
 static GLboolean
-intel_bufferobj_unmap(struct gl_context * ctx, struct gl_buffer_object *obj,
-                      gl_map_buffer_index index)
+brw_unmap_buffer(struct gl_context *ctx,
+                 struct gl_buffer_object *obj,
+                 gl_map_buffer_index index)
 {
    struct brw_context *brw = brw_context(ctx);
    struct intel_buffer_object *intel_obj = intel_buffer_object(obj);
@@ -546,8 +545,8 @@ intel_bufferobj_unmap(struct gl_context * ctx, struct gl_buffer_object *obj,
                                 intel_obj->range_map_bo[index],
                                 intel_obj->map_extra[index],
                                 obj->Mappings[index].Length);
-         intel_bufferobj_mark_gpu_usage(intel_obj, obj->Mappings[index].Offset,
-                                        obj->Mappings[index].Length);
+         mark_buffer_gpu_usage(intel_obj, obj->Mappings[index].Offset,
+                               obj->Mappings[index].Length);
       }
 
       /* Since we've emitted some blits to buffers that will (likely) be used
@@ -586,9 +585,9 @@ intel_bufferobj_buffer(struct brw_context *brw,
     * draw-time validation can just always get a BO from a GL buffer object.
     */
    if (intel_obj->buffer == NULL)
-      intel_bufferobj_alloc_buffer(brw, intel_obj);
+      alloc_buffer_object(brw, intel_obj);
 
-   intel_bufferobj_mark_gpu_usage(intel_obj, offset, size);
+   mark_buffer_gpu_usage(intel_obj, offset, size);
 
    return intel_obj->buffer;
 }
@@ -601,11 +600,11 @@ intel_bufferobj_buffer(struct brw_context *brw,
  * are allowed.
  */
 static void
-intel_bufferobj_copy_subdata(struct gl_context *ctx,
-			     struct gl_buffer_object *src,
-			     struct gl_buffer_object *dst,
-			     GLintptr read_offset, GLintptr write_offset,
-			     GLsizeiptr size)
+brw_copy_buffer_subdata(struct gl_context *ctx,
+                        struct gl_buffer_object *src,
+                        struct gl_buffer_object *dst,
+                        GLintptr read_offset, GLintptr write_offset,
+                        GLsizeiptr size)
 {
    struct brw_context *brw = brw_context(ctx);
    struct intel_buffer_object *intel_src = intel_buffer_object(src);
@@ -633,13 +632,13 @@ intel_bufferobj_copy_subdata(struct gl_context *ctx,
 void
 intelInitBufferObjectFuncs(struct dd_function_table *functions)
 {
-   functions->NewBufferObject = intel_bufferobj_alloc;
-   functions->DeleteBuffer = intel_bufferobj_free;
-   functions->BufferData = intel_bufferobj_data;
-   functions->BufferSubData = intel_bufferobj_subdata;
-   functions->GetBufferSubData = intel_bufferobj_get_subdata;
-   functions->MapBufferRange = intel_bufferobj_map_range;
-   functions->FlushMappedBufferRange = intel_bufferobj_flush_mapped_range;
-   functions->UnmapBuffer = intel_bufferobj_unmap;
-   functions->CopyBufferSubData = intel_bufferobj_copy_subdata;
+   functions->NewBufferObject = brw_new_buffer_object;
+   functions->DeleteBuffer = brw_delete_buffer;
+   functions->BufferData = brw_buffer_data;
+   functions->BufferSubData = brw_buffer_subdata;
+   functions->GetBufferSubData = brw_get_buffer_subdata;
+   functions->MapBufferRange = brw_map_buffer_range;
+   functions->FlushMappedBufferRange = brw_flush_mapped_buffer_range;
+   functions->UnmapBuffer = brw_unmap_buffer;
+   functions->CopyBufferSubData = brw_copy_buffer_subdata;
 }
diff --git a/src/mesa/drivers/dri/i965/intel_reg.h b/src/mesa/drivers/dri/i965/intel_reg.h
index 45b82ad..5ac0180 100644
--- a/src/mesa/drivers/dri/i965/intel_reg.h
+++ b/src/mesa/drivers/dri/i965/intel_reg.h
@@ -138,3 +138,9 @@
 #define GEN7_3DPRIM_INSTANCE_COUNT      0x2438
 #define GEN7_3DPRIM_START_INSTANCE      0x243C
 #define GEN7_3DPRIM_BASE_VERTEX         0x2440
+
+#define GEN7_CACHE_MODE_1               0x7004
+# define GEN8_HIZ_NP_PMA_FIX_ENABLE        (1 << 11)
+# define GEN8_HIZ_NP_EARLY_Z_FAILS_DISABLE (1 << 13)
+# define GEN8_HIZ_PMA_MASK_BITS \
+   ((GEN8_HIZ_NP_PMA_FIX_ENABLE | GEN8_HIZ_NP_EARLY_Z_FAILS_DISABLE) << 16)
diff --git a/src/mesa/drivers/dri/i965/intel_screen.c b/src/mesa/drivers/dri/i965/intel_screen.c
index 88b5b13..6618c1a 100644
--- a/src/mesa/drivers/dri/i965/intel_screen.c
+++ b/src/mesa/drivers/dri/i965/intel_screen.c
@@ -1266,6 +1266,7 @@ set_max_gl_versions(struct intel_screen *screen)
    __DRIscreen *psp = screen->driScrnPriv;
 
    switch (screen->devinfo->gen) {
+   case 9:
    case 8:
    case 7:
    case 6:
diff --git a/src/mesa/main/api_validate.c b/src/mesa/main/api_validate.c
index 9b80600..a3a2d25 100644
--- a/src/mesa/main/api_validate.c
+++ b/src/mesa/main/api_validate.c
@@ -749,17 +749,17 @@ _mesa_validate_DrawTransformFeedback(struct gl_context *ctx,
       return GL_FALSE;
    }
 
-   if (!obj->EndedAnytime) {
-      _mesa_error(ctx, GL_INVALID_OPERATION, "glDrawTransformFeedback*");
-      return GL_FALSE;
-   }
-
    if (stream >= ctx->Const.MaxVertexStreams) {
       _mesa_error(ctx, GL_INVALID_VALUE,
                   "glDrawTransformFeedbackStream*(index>=MaxVertexStream)");
       return GL_FALSE;
    }
 
+   if (!obj->EndedAnytime) {
+      _mesa_error(ctx, GL_INVALID_OPERATION, "glDrawTransformFeedback*");
+      return GL_FALSE;
+   }
+
    if (numInstances <= 0) {
       if (numInstances < 0)
          _mesa_error(ctx, GL_INVALID_VALUE,
diff --git a/src/mesa/main/attrib.c b/src/mesa/main/attrib.c
index 5345339..4684615 100644
--- a/src/mesa/main/attrib.c
+++ b/src/mesa/main/attrib.c
@@ -1345,7 +1345,8 @@ _mesa_PopAttrib(void)
                if (xform->DepthClamp != ctx->Transform.DepthClamp)
                   _mesa_set_enable(ctx, GL_DEPTH_CLAMP,
                                    ctx->Transform.DepthClamp);
-               _mesa_ClipControl(xform->ClipOrigin, xform->ClipDepthMode);
+               if (ctx->Extensions.ARB_clip_control)
+                  _mesa_ClipControl(xform->ClipOrigin, xform->ClipDepthMode);
             }
             break;
          case GL_TEXTURE_BIT:
diff --git a/src/mesa/main/context.c b/src/mesa/main/context.c
index 25b9bfc..400c158 100644
--- a/src/mesa/main/context.c
+++ b/src/mesa/main/context.c
@@ -719,6 +719,9 @@ _mesa_init_constants(struct gl_constants *consts, gl_api api)
    /** GL_ARB_gpu_shader5 */
    consts->MinFragmentInterpolationOffset = MIN_FRAGMENT_INTERPOLATION_OFFSET;
    consts->MaxFragmentInterpolationOffset = MAX_FRAGMENT_INTERPOLATION_OFFSET;
+
+   /** GL_KHR_context_flush_control */
+   consts->ContextReleaseBehavior = GL_CONTEXT_RELEASE_BEHAVIOR_FLUSH;
 }
 
 
@@ -729,6 +732,8 @@ _mesa_init_constants(struct gl_constants *consts, gl_api api)
 static void
 check_context_limits(struct gl_context *ctx)
 {
+   (void) ctx;
+
    /* check that we don't exceed the size of various bitfields */
    assert(VARYING_SLOT_MAX <=
 	  (8 * sizeof(ctx->VertexProgram._Current->Base.OutputsWritten)));
@@ -1622,9 +1627,11 @@ _mesa_make_current( struct gl_context *newCtx,
    }
 
    if (curCtx && 
-      (curCtx->WinSysDrawBuffer || curCtx->WinSysReadBuffer) &&
+       (curCtx->WinSysDrawBuffer || curCtx->WinSysReadBuffer) &&
        /* make sure this context is valid for flushing */
-      curCtx != newCtx)
+       curCtx != newCtx &&
+       curCtx->Const.ContextReleaseBehavior ==
+       GL_CONTEXT_RELEASE_BEHAVIOR_FLUSH)
       _mesa_flush(curCtx);
 
    /* We used to call _glapi_check_multithread() here.  Now do it in drivers */
diff --git a/src/mesa/main/errors.c b/src/mesa/main/errors.c
index 25171f0..7d622bb 100644
--- a/src/mesa/main/errors.c
+++ b/src/mesa/main/errors.c
@@ -676,22 +676,41 @@ debug_pop_group(struct gl_debug_state *debug)
 
 
 /**
- * Return debug state for the context.  The debug state will be allocated
- * and initialized upon the first call.
+ * Lock and return debug state for the context.  The debug state will be
+ * allocated and initialized upon the first call.  When NULL is returned, the
+ * debug state is not locked.
  */
 static struct gl_debug_state *
-_mesa_get_debug_state(struct gl_context *ctx)
+_mesa_lock_debug_state(struct gl_context *ctx)
 {
+   mtx_lock(&ctx->DebugMutex);
+
    if (!ctx->Debug) {
       ctx->Debug = debug_create();
       if (!ctx->Debug) {
-         _mesa_error(ctx, GL_OUT_OF_MEMORY, "allocating debug state");
+         GET_CURRENT_CONTEXT(cur);
+         mtx_unlock(&ctx->DebugMutex);
+
+         /*
+          * This function may be called from other threads.  When that is the
+          * case, we cannot record this OOM error.
+          */
+         if (ctx == cur)
+            _mesa_error(ctx, GL_OUT_OF_MEMORY, "allocating debug state");
+
+         return NULL;
       }
    }
 
    return ctx->Debug;
 }
 
+static void
+_mesa_unlock_debug_state(struct gl_context *ctx)
+{
+   mtx_unlock(&ctx->DebugMutex);
+}
+
 /**
  * Set the integer debug state specified by \p pname.  This can be called from
  * _mesa_set_enable for example.
@@ -699,7 +718,7 @@ _mesa_get_debug_state(struct gl_context *ctx)
 bool
 _mesa_set_debug_state_int(struct gl_context *ctx, GLenum pname, GLint val)
 {
-   struct gl_debug_state *debug = _mesa_get_debug_state(ctx);
+   struct gl_debug_state *debug = _mesa_lock_debug_state(ctx);
 
    if (!debug)
       return false;
@@ -716,6 +735,8 @@ _mesa_set_debug_state_int(struct gl_context *ctx, GLenum pname, GLint val)
       break;
    }
 
+   _mesa_unlock_debug_state(ctx);
+
    return true;
 }
 
@@ -729,9 +750,12 @@ _mesa_get_debug_state_int(struct gl_context *ctx, GLenum pname)
    struct gl_debug_state *debug;
    GLint val;
 
+   mtx_lock(&ctx->DebugMutex);
    debug = ctx->Debug;
-   if (!debug)
+   if (!debug) {
+      mtx_unlock(&ctx->DebugMutex);
       return 0;
+   }
 
    switch (pname) {
    case GL_DEBUG_OUTPUT:
@@ -756,6 +780,8 @@ _mesa_get_debug_state_int(struct gl_context *ctx, GLenum pname)
       break;
    }
 
+   mtx_unlock(&ctx->DebugMutex);
+
    return val;
 }
 
@@ -769,9 +795,12 @@ _mesa_get_debug_state_ptr(struct gl_context *ctx, GLenum pname)
    struct gl_debug_state *debug;
    void *val;
 
+   mtx_lock(&ctx->DebugMutex);
    debug = ctx->Debug;
-   if (!debug)
+   if (!debug) {
+      mtx_unlock(&ctx->DebugMutex);
       return NULL;
+   }
 
    switch (pname) {
    case GL_DEBUG_CALLBACK_FUNCTION_ARB:
@@ -786,9 +815,49 @@ _mesa_get_debug_state_ptr(struct gl_context *ctx, GLenum pname)
       break;
    }
 
+   mtx_unlock(&ctx->DebugMutex);
+
    return val;
 }
 
+/**
+ * Insert a debug message.  The mutex is assumed to be locked, and will be
+ * unlocked by this call.
+ */
+static void
+log_msg_locked_and_unlock(struct gl_context *ctx,
+                          enum mesa_debug_source source,
+                          enum mesa_debug_type type, GLuint id,
+                          enum mesa_debug_severity severity,
+                          GLint len, const char *buf)
+{
+   struct gl_debug_state *debug = ctx->Debug;
+
+   if (!debug_is_message_enabled(debug, source, type, id, severity)) {
+      _mesa_unlock_debug_state(ctx);
+      return;
+   }
+
+   if (ctx->Debug->Callback) {
+      GLenum gl_source = debug_source_enums[source];
+      GLenum gl_type = debug_type_enums[type];
+      GLenum gl_severity = debug_severity_enums[severity];
+      GLDEBUGPROC callback = ctx->Debug->Callback;
+      const void *data = ctx->Debug->CallbackData;
+
+      /*
+       * When ctx->Debug->SyncOutput is GL_FALSE, the client is prepared for
+       * unsynchronous calls.  When it is GL_TRUE, we will not spawn threads.
+       * In either case, we can call the callback unlocked.
+       */
+      _mesa_unlock_debug_state(ctx);
+      callback(gl_source, gl_type, id, gl_severity, len, buf, data);
+   }
+   else {
+      debug_log_message(ctx->Debug, source, type, id, severity, len, buf);
+      _mesa_unlock_debug_state(ctx);
+   }
+}
 
 /**
  * Log a client or driver debug message.
@@ -798,24 +867,12 @@ log_msg(struct gl_context *ctx, enum mesa_debug_source source,
         enum mesa_debug_type type, GLuint id,
         enum mesa_debug_severity severity, GLint len, const char *buf)
 {
-   struct gl_debug_state *debug = _mesa_get_debug_state(ctx);
+   struct gl_debug_state *debug = _mesa_lock_debug_state(ctx);
 
    if (!debug)
       return;
 
-   if (!debug_is_message_enabled(debug, source, type, id, severity))
-      return;
-
-   if (debug->Callback) {
-       GLenum gl_type = debug_type_enums[type];
-       GLenum gl_severity = debug_severity_enums[severity];
-
-      debug->Callback(debug_source_enums[source], gl_type, id, gl_severity,
-                      len, buf, debug->CallbackData);
-      return;
-   }
-
-   debug_log_message(debug, source, type, id, severity, len, buf);
+   log_msg_locked_and_unlock(ctx, source, type, id, severity, len, buf);
 }
 
 
@@ -956,7 +1013,7 @@ _mesa_GetDebugMessageLog(GLuint count, GLsizei logSize, GLenum *sources,
       return 0;
    }
 
-   debug = _mesa_get_debug_state(ctx);
+   debug = _mesa_lock_debug_state(ctx);
    if (!debug)
       return 0;
 
@@ -991,6 +1048,8 @@ _mesa_GetDebugMessageLog(GLuint count, GLsizei logSize, GLenum *sources,
       debug_delete_messages(debug, 1);
    }
 
+   _mesa_unlock_debug_state(ctx);
+
    return ret;
 }
 
@@ -1027,7 +1086,7 @@ _mesa_DebugMessageControl(GLenum gl_source, GLenum gl_type,
       return;
    }
 
-   debug = _mesa_get_debug_state(ctx);
+   debug = _mesa_lock_debug_state(ctx);
    if (!debug)
       return;
 
@@ -1039,6 +1098,8 @@ _mesa_DebugMessageControl(GLenum gl_source, GLenum gl_type,
    else {
       debug_set_message_enable_all(debug, source, type, severity, enabled);
    }
+
+   _mesa_unlock_debug_state(ctx);
 }
 
 
@@ -1046,10 +1107,11 @@ void GLAPIENTRY
 _mesa_DebugMessageCallback(GLDEBUGPROC callback, const void *userParam)
 {
    GET_CURRENT_CONTEXT(ctx);
-   struct gl_debug_state *debug = _mesa_get_debug_state(ctx);
+   struct gl_debug_state *debug = _mesa_lock_debug_state(ctx);
    if (debug) {
       debug->Callback = callback;
       debug->CallbackData = userParam;
+      _mesa_unlock_debug_state(ctx);
    }
 }
 
@@ -1059,18 +1121,10 @@ _mesa_PushDebugGroup(GLenum source, GLuint id, GLsizei length,
                      const GLchar *message)
 {
    GET_CURRENT_CONTEXT(ctx);
-   struct gl_debug_state *debug = _mesa_get_debug_state(ctx);
    const char *callerstr = "glPushDebugGroup";
+   struct gl_debug_state *debug;
    struct gl_debug_message *emptySlot;
 
-   if (!debug)
-      return;
-
-   if (debug->GroupStackDepth >= MAX_DEBUG_GROUP_STACK_DEPTH-1) {
-      _mesa_error(ctx, GL_STACK_OVERFLOW, "%s", callerstr);
-      return;
-   }
-
    switch(source) {
    case GL_DEBUG_SOURCE_APPLICATION:
    case GL_DEBUG_SOURCE_THIRD_PARTY:
@@ -1086,10 +1140,15 @@ _mesa_PushDebugGroup(GLenum source, GLuint id, GLsizei length,
    if (!validate_length(ctx, callerstr, length))
       return; /* GL_INVALID_VALUE */
 
-   log_msg(ctx, gl_enum_to_debug_source(source),
-           MESA_DEBUG_TYPE_PUSH_GROUP, id,
-           MESA_DEBUG_SEVERITY_NOTIFICATION, length,
-           message);
+   debug = _mesa_lock_debug_state(ctx);
+   if (!debug)
+      return;
+
+   if (debug->GroupStackDepth >= MAX_DEBUG_GROUP_STACK_DEPTH-1) {
+      _mesa_unlock_debug_state(ctx);
+      _mesa_error(ctx, GL_STACK_OVERFLOW, "%s", callerstr);
+      return;
+   }
 
    /* pop reuses the message details from push so we store this */
    emptySlot = debug_get_group_message(debug);
@@ -1101,6 +1160,12 @@ _mesa_PushDebugGroup(GLenum source, GLuint id, GLsizei length,
                        length, message);
 
    debug_push_group(debug);
+
+   log_msg_locked_and_unlock(ctx,
+         gl_enum_to_debug_source(source),
+         MESA_DEBUG_TYPE_PUSH_GROUP, id,
+         MESA_DEBUG_SEVERITY_NOTIFICATION, length,
+         message);
 }
 
 
@@ -1108,35 +1173,43 @@ void GLAPIENTRY
 _mesa_PopDebugGroup(void)
 {
    GET_CURRENT_CONTEXT(ctx);
-   struct gl_debug_state *debug = _mesa_get_debug_state(ctx);
    const char *callerstr = "glPopDebugGroup";
-   struct gl_debug_message *gdmessage;
+   struct gl_debug_state *debug;
+   struct gl_debug_message *gdmessage, msg;
 
+   debug = _mesa_lock_debug_state(ctx);
    if (!debug)
       return;
 
    if (debug->GroupStackDepth <= 0) {
+      _mesa_unlock_debug_state(ctx);
       _mesa_error(ctx, GL_STACK_UNDERFLOW, "%s", callerstr);
       return;
    }
 
    debug_pop_group(debug);
 
+   /* make a shallow copy */
    gdmessage = debug_get_group_message(debug);
-   log_msg(ctx, gdmessage->source,
-           gl_enum_to_debug_type(GL_DEBUG_TYPE_POP_GROUP),
-           gdmessage->id,
-           gl_enum_to_debug_severity(GL_DEBUG_SEVERITY_NOTIFICATION),
-           gdmessage->length, gdmessage->message);
-
-   debug_message_clear(gdmessage);
+   msg = *gdmessage;
+   gdmessage->message = NULL;
+   gdmessage->length = 0;
+
+   log_msg_locked_and_unlock(ctx,
+         msg.source,
+         gl_enum_to_debug_type(GL_DEBUG_TYPE_POP_GROUP),
+         msg.id,
+         gl_enum_to_debug_severity(GL_DEBUG_SEVERITY_NOTIFICATION),
+         msg.length, msg.message);
+
+   debug_message_clear(&msg);
 }
 
 
 void
 _mesa_init_errors(struct gl_context *ctx)
 {
-   /* no-op */
+   mtx_init(&ctx->DebugMutex, mtx_plain);
 }
 
 
@@ -1148,6 +1221,8 @@ _mesa_free_errors_data(struct gl_context *ctx)
       /* set to NULL just in case it is used before context is completely gone. */
       ctx->Debug = NULL;
    }
+
+   mtx_destroy(&ctx->DebugMutex);
 }
 
 
@@ -1362,6 +1437,8 @@ _mesa_error( struct gl_context *ctx, GLenum error, const char *fmtString, ... )
    debug_get_id(&error_msg_id);
 
    do_output = should_output(ctx, error, fmtString);
+
+   mtx_lock(&ctx->DebugMutex);
    if (ctx->Debug) {
       do_log = debug_is_message_enabled(ctx->Debug,
                                         MESA_DEBUG_SOURCE_API,
@@ -1372,6 +1449,7 @@ _mesa_error( struct gl_context *ctx, GLenum error, const char *fmtString, ... )
    else {
       do_log = GL_FALSE;
    }
+   mtx_unlock(&ctx->DebugMutex);
 
    if (do_output || do_log) {
       char s[MAX_DEBUG_MESSAGE_LENGTH], s2[MAX_DEBUG_MESSAGE_LENGTH];
diff --git a/src/mesa/main/extensions.c b/src/mesa/main/extensions.c
index 15d66a7..0df04c2 100644
--- a/src/mesa/main/extensions.c
+++ b/src/mesa/main/extensions.c
@@ -320,6 +320,7 @@ static const struct extension extension_table[] = {
 
    /* KHR extensions */
    { "GL_KHR_debug",                               o(dummy_true),                              GL,             2012 },
+   { "GL_KHR_context_flush_control",               o(dummy_true),                              GL       | ES2, 2014 },
 
    /* Vendor extensions */
    { "GL_3DFX_texture_compression_FXT1",           o(TDFX_texture_compression_FXT1),           GL,             1999 },
diff --git a/src/mesa/main/get_hash_params.py b/src/mesa/main/get_hash_params.py
index aa9f282..a931d9d 100644
--- a/src/mesa/main/get_hash_params.py
+++ b/src/mesa/main/get_hash_params.py
@@ -318,6 +318,9 @@ descriptor=[
   [ "PERFQUERY_COUNTER_NAME_LENGTH_MAX_INTEL", "CONST(MAX_PERFQUERY_COUNTER_NAME_LENGTH), extra_INTEL_performance_query" ],
   [ "PERFQUERY_COUNTER_DESC_LENGTH_MAX_INTEL", "CONST(MAX_PERFQUERY_COUNTER_DESC_LENGTH), extra_INTEL_performance_query" ],
   [ "PERFQUERY_GPA_EXTENDED_COUNTERS_INTEL", "CONST(PERFQUERY_HAVE_GPA_EXTENDED_COUNTERS), extra_INTEL_performance_query" ],
+
+# GL_KHR_context_flush_control
+  [ "CONTEXT_RELEASE_BEHAVIOR", "CONTEXT_ENUM(Const.ContextReleaseBehavior), NO_EXTRA" ],
 ]},
 
 # GLES3 is not a typo.
diff --git a/src/mesa/main/imports.c b/src/mesa/main/imports.c
index b8c7548..4f5a2d1 100644
--- a/src/mesa/main/imports.c
+++ b/src/mesa/main/imports.c
@@ -499,25 +499,6 @@ _mesa_strdup( const char *s )
    }
 }
 
-/** Wrapper around strtof() */
-float
-_mesa_strtof( const char *s, char **end )
-{
-#if defined(_GNU_SOURCE) && !defined(__CYGWIN__) && !defined(__FreeBSD__) && \
-   !defined(ANDROID) && !defined(__HAIKU__) && !defined(__UCLIBC__) && \
-   !defined(__NetBSD__)
-   static locale_t loc = NULL;
-   if (!loc) {
-      loc = newlocale(LC_CTYPE_MASK, "C", NULL);
-   }
-   return strtof_l(s, end, loc);
-#elif defined(_ISOC99_SOURCE) || (defined(_XOPEN_SOURCE) && _XOPEN_SOURCE >= 600)
-   return strtof(s, end);
-#else
-   return (float)strtod(s, end);
-#endif
-}
-
 /** Compute simple checksum/hash for a string */
 unsigned int
 _mesa_str_checksum(const char *str)
diff --git a/src/mesa/main/imports.h b/src/mesa/main/imports.h
index 436d165..0fcba4f 100644
--- a/src/mesa/main/imports.h
+++ b/src/mesa/main/imports.h
@@ -540,9 +540,6 @@ _mesa_half_is_negative(GLhalfARB h)
 extern char *
 _mesa_strdup( const char *s );
 
-extern float
-_mesa_strtof( const char *s, char **end );
-
 extern unsigned int
 _mesa_str_checksum(const char *str);
 
diff --git a/src/mesa/main/mtypes.h b/src/mesa/main/mtypes.h
index e1f1f1d..7389baa 100644
--- a/src/mesa/main/mtypes.h
+++ b/src/mesa/main/mtypes.h
@@ -2843,6 +2843,7 @@ struct gl_shader_program
 
    /* post-link info: */
    unsigned NumUserUniformStorage;
+   unsigned NumHiddenUniforms;
    struct gl_uniform_storage *UniformStorage;
 
    /**
@@ -3680,6 +3681,9 @@ struct gl_constants
 
    GLboolean FakeSWMSAA;
 
+   /** GL_KHR_context_flush_control */
+   GLenum ContextReleaseBehavior;
+
    struct gl_shader_compiler_options ShaderCompilerOptions[MESA_SHADER_STAGES];
 };
 
@@ -4390,6 +4394,7 @@ struct gl_context
    GLuint ErrorDebugCount;
 
    /* GL_ARB_debug_output/GL_KHR_debug */
+   mtx_t DebugMutex;
    struct gl_debug_state *Debug;
 
    GLenum RenderMode;        /**< either GL_RENDER, GL_SELECT, GL_FEEDBACK */
diff --git a/src/mesa/main/shaderapi.c b/src/mesa/main/shaderapi.c
index 2be9092..6657820 100644
--- a/src/mesa/main/shaderapi.c
+++ b/src/mesa/main/shaderapi.c
@@ -565,13 +565,15 @@ get_programiv(struct gl_context *ctx, GLuint program, GLenum pname, GLint *param
       *params = _mesa_longest_attribute_name_length(shProg);
       return;
    case GL_ACTIVE_UNIFORMS:
-      *params = shProg->NumUserUniformStorage;
+      *params = shProg->NumUserUniformStorage - shProg->NumHiddenUniforms;
       return;
    case GL_ACTIVE_UNIFORM_MAX_LENGTH: {
       unsigned i;
       GLint max_len = 0;
+      const unsigned num_uniforms =
+         shProg->NumUserUniformStorage - shProg->NumHiddenUniforms;
 
-      for (i = 0; i < shProg->NumUserUniformStorage; i++) {
+      for (i = 0; i < num_uniforms; i++) {
 	 /* Add one for the terminating NUL character for a non-array, and
 	  * 4 for the "[0]" and the NUL for an array.
 	  */
diff --git a/src/mesa/main/sse_minmax.c b/src/mesa/main/sse_minmax.c
new file mode 100644
index 0000000..222ac14
--- /dev/null
+++ b/src/mesa/main/sse_minmax.c
@@ -0,0 +1,97 @@
+/*
+ * Copyright © 2014 Timothy Arceri
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ *
+ * Author:
+ *    Timothy Arceri <t_arceri@yahoo.com.au>
+ *
+ */
+
+#ifdef __SSE4_1__
+#include "main/sse_minmax.h"
+#include <smmintrin.h>
+#include <stdint.h>
+
+void
+_mesa_uint_array_min_max(const unsigned *ui_indices, unsigned *min_index,
+                         unsigned *max_index, const unsigned count)
+{
+   unsigned max_ui = 0;
+   unsigned min_ui = ~0U;
+   unsigned i = 0;
+   unsigned aligned_count = count;
+
+   /* handle the first few values without SSE until the pointer is aligned */
+   while (((uintptr_t)ui_indices & 15) && aligned_count) {
+      if (*ui_indices > max_ui)
+         max_ui = *ui_indices;
+      if (*ui_indices < min_ui)
+         min_ui = *ui_indices;
+
+      aligned_count--;
+      ui_indices++;
+   }
+
+   /* TODO: The actual threshold for SSE begin useful may be higher than 8.
+    * Some careful microbenchmarks and measurement are required to
+    * find the actual tipping point.
+    */
+   if (aligned_count >= 8) {
+      unsigned max_arr[4] __attribute__ ((aligned (16)));
+      unsigned min_arr[4] __attribute__ ((aligned (16)));
+      unsigned vec_count;
+      __m128i max_ui4 = _mm_setzero_si128();
+      __m128i min_ui4 = _mm_set1_epi32(~0U);
+      __m128i ui_indices4;
+      __m128i *ui_indices_ptr;
+
+      vec_count = aligned_count & ~0x3;
+      ui_indices_ptr = (__m128i *)ui_indices;
+      for (i = 0; i < vec_count / 4; i++) {
+         ui_indices4 = _mm_load_si128(&ui_indices_ptr[i]);
+         max_ui4 = _mm_max_epu32(ui_indices4, max_ui4);
+         min_ui4 = _mm_min_epu32(ui_indices4, min_ui4);
+      }
+
+      _mm_store_si128((__m128i *)max_arr, max_ui4);
+      _mm_store_si128((__m128i *)min_arr, min_ui4);
+
+      for (i = 0; i < 4; i++) {
+         if (max_arr[i] > max_ui)
+            max_ui = max_arr[i];
+         if (min_arr[i] < min_ui)
+            min_ui = min_arr[i];
+      }
+      i = vec_count;
+   }
+
+   for (; i < aligned_count; i++) {
+      if (ui_indices[i] > max_ui)
+         max_ui = ui_indices[i];
+      if (ui_indices[i] < min_ui)
+         min_ui = ui_indices[i];
+   }
+
+   *min_index = min_ui;
+   *max_index = max_ui;
+}
+
+#endif
diff --git a/src/mesa/main/sse_minmax.h b/src/mesa/main/sse_minmax.h
new file mode 100644
index 0000000..953c4e9
--- /dev/null
+++ b/src/mesa/main/sse_minmax.h
@@ -0,0 +1,30 @@
+/*
+ * Copyright © 2014 Timothy Arceri
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ *
+ * Author:
+ *    Timothy Arceri <t_arceri@yahoo.com.au>
+ *
+ */
+
+void
+_mesa_uint_array_min_max(const unsigned *ui_indices, unsigned *min_index,
+                         unsigned *max_index, const unsigned count);
diff --git a/src/mesa/main/viewport.c b/src/mesa/main/viewport.c
index d6a9e29..0adce9c 100644
--- a/src/mesa/main/viewport.c
+++ b/src/mesa/main/viewport.c
@@ -459,15 +459,14 @@ _mesa_ClipControl(GLenum origin, GLenum depth)
        ctx->Transform.ClipDepthMode == depth)
       return;
 
-   FLUSH_VERTICES(ctx, 0);
+   /* Affects transform state and the viewport transform */
+   FLUSH_VERTICES(ctx, _NEW_TRANSFORM | _NEW_VIEWPORT);
 
    if (ctx->Transform.ClipOrigin != origin) {
       ctx->Transform.ClipOrigin = origin;
 
       /* Affects the winding order of the front face. */
       ctx->NewState |= _NEW_POLYGON;
-      /* Affects the y component of the viewport transform. */
-      ctx->NewState |= _NEW_VIEWPORT;
 
       if (ctx->Driver.FrontFace)
          ctx->Driver.FrontFace(ctx, ctx->Polygon.FrontFace);
@@ -476,9 +475,6 @@ _mesa_ClipControl(GLenum origin, GLenum depth)
    if (ctx->Transform.ClipDepthMode != depth) {
       ctx->Transform.ClipDepthMode = depth;
 
-      /* Affects the z part of the viewpoint transform. */
-      ctx->NewState |= _NEW_VIEWPORT;
-
       if (ctx->Driver.DepthRange)
          ctx->Driver.DepthRange(ctx);
    }
diff --git a/src/mesa/program/program_lexer.l b/src/mesa/program/program_lexer.l
index d5dbcf3..e363912 100644
--- a/src/mesa/program/program_lexer.l
+++ b/src/mesa/program/program_lexer.l
@@ -28,6 +28,7 @@
 #include "program/symbol_table.h"
 #include "program/program_parser.h"
 #include "program/program_parse.tab.h"
+#include "util/strtod.h"
 
 #define require_ARB_vp (yyextra->mode == ARB_vertex)
 #define require_ARB_fp (yyextra->mode == ARB_fragment)
diff --git a/src/mesa/state_tracker/st_atom_rasterizer.c b/src/mesa/state_tracker/st_atom_rasterizer.c
index 5020978..606f19a 100644
--- a/src/mesa/state_tracker/st_atom_rasterizer.c
+++ b/src/mesa/state_tracker/st_atom_rasterizer.c
@@ -72,7 +72,7 @@ static void update_raster_state( struct st_context *st )
    {
       raster->front_ccw = (ctx->Polygon.FrontFace == GL_CCW);
 
-      /* _NEW_VIEWPORT */
+      /* _NEW_TRANSFORM */
       if (ctx->Transform.ClipOrigin == GL_UPPER_LEFT) {
          raster->front_ccw ^= 1;
       }
@@ -246,13 +246,10 @@ static void update_raster_state( struct st_context *st )
    raster->half_pixel_center = 1;
    if (st_fb_orientation(ctx->DrawBuffer) == Y_0_TOP)
       raster->bottom_edge_rule = 1;
-   /* _NEW_VIEWPORT */
+   /* _NEW_TRANSFORM */
    if (ctx->Transform.ClipOrigin == GL_UPPER_LEFT)
       raster->bottom_edge_rule ^= 1;
 
-   /* _NEW_VIEWPORT */
-   raster->clip_halfz = (ctx->Transform.ClipDepthMode == GL_ZERO_TO_ONE);
-
    /* ST_NEW_RASTERIZER */
    raster->rasterizer_discard = ctx->RasterDiscard;
 
@@ -267,6 +264,7 @@ static void update_raster_state( struct st_context *st )
    /* _NEW_TRANSFORM */
    raster->depth_clip = !ctx->Transform.DepthClamp;
    raster->clip_plane_enable = ctx->Transform.ClipPlanesEnabled;
+   raster->clip_halfz = (ctx->Transform.ClipDepthMode == GL_ZERO_TO_ONE);
 
    cso_set_rasterizer(st->cso_context, raster);
 }
@@ -283,8 +281,7 @@ const struct st_tracked_state st_update_rasterizer = {
        _NEW_PROGRAM |
        _NEW_SCISSOR |
        _NEW_FRAG_CLAMP |
-       _NEW_TRANSFORM |
-       _NEW_VIEWPORT),      /* mesa state dependencies*/
+       _NEW_TRANSFORM),     /* mesa state dependencies*/
       (ST_NEW_VERTEX_PROGRAM |
        ST_NEW_RASTERIZER),  /* state tracker dependencies */
    },
diff --git a/src/mesa/state_tracker/st_extensions.c b/src/mesa/state_tracker/st_extensions.c
index aff3dde..bdfab8b 100644
--- a/src/mesa/state_tracker/st_extensions.c
+++ b/src/mesa/state_tracker/st_extensions.c
@@ -241,8 +241,7 @@ void st_init_limits(struct pipe_screen *screen,
 
       if (options->EmitNoLoops)
          options->MaxUnrollIterations = MIN2(screen->get_shader_param(screen, sh, PIPE_SHADER_CAP_MAX_INSTRUCTIONS), 65536);
-      else
-         options->MaxUnrollIterations = 255; /* SM3 limit */
+
       options->LowerClipDistance = true;
    }
 
diff --git a/src/mesa/state_tracker/st_manager.c b/src/mesa/state_tracker/st_manager.c
index df6de73..606d678 100644
--- a/src/mesa/state_tracker/st_manager.c
+++ b/src/mesa/state_tracker/st_manager.c
@@ -452,7 +452,8 @@ st_framebuffer_create(struct st_context *st,
           st_pipe_format_to_mesa_format(srgb_format) != MESA_FORMAT_NONE &&
           screen->is_format_supported(screen, srgb_format,
                                       PIPE_TEXTURE_2D, stfbi->visual->samples,
-                                      PIPE_BIND_RENDER_TARGET))
+                                      (PIPE_BIND_DISPLAY_TARGET |
+                                       PIPE_BIND_RENDER_TARGET)))
          mode.sRGBCapable = GL_TRUE;
    }
 
diff --git a/src/mesa/vbo/vbo_exec_array.c b/src/mesa/vbo/vbo_exec_array.c
index 045dbb5..e623b36 100644
--- a/src/mesa/vbo/vbo_exec_array.c
+++ b/src/mesa/vbo/vbo_exec_array.c
@@ -36,6 +36,8 @@
 #include "main/enums.h"
 #include "main/macros.h"
 #include "main/transformfeedback.h"
+#include "main/sse_minmax.h"
+#include "x86/common_x86_asm.h"
 
 #include "vbo_context.h"
 
@@ -119,10 +121,16 @@ vbo_get_minmax_index(struct gl_context *ctx,
          }
       }
       else {
-         for (i = 0; i < count; i++) {
-            if (ui_indices[i] > max_ui) max_ui = ui_indices[i];
-            if (ui_indices[i] < min_ui) min_ui = ui_indices[i];
+#if defined(USE_SSE41)
+         if (cpu_has_sse4_1) {
+            _mesa_uint_array_min_max(ui_indices, &min_ui, &max_ui, count);
          }
+         else
+#endif
+            for (i = 0; i < count; i++) {
+               if (ui_indices[i] > max_ui) max_ui = ui_indices[i];
+               if (ui_indices[i] < min_ui) min_ui = ui_indices[i];
+            }
       }
       *min_index = min_ui;
       *max_index = max_ui;
diff --git a/src/util/Makefile.sources b/src/util/Makefile.sources
index 952b799..9e27424 100644
--- a/src/util/Makefile.sources
+++ b/src/util/Makefile.sources
@@ -3,7 +3,8 @@ MESA_UTIL_FILES :=	\
 	ralloc.c \
 	register_allocate.c \
 	register_allocate.h \
-	rgtc.c
+	rgtc.c \
+	strtod.cpp
 
 MESA_UTIL_GENERATED_FILES = \
 	format_srgb.c
diff --git a/src/util/macros.h b/src/util/macros.h
index ff37a7d..da5daff 100644
--- a/src/util/macros.h
+++ b/src/util/macros.h
@@ -69,6 +69,12 @@ do {                        \
    assert(!str);            \
    __builtin_unreachable(); \
 } while (0)
+#elif _MSC_VER >= 1200
+#define unreachable(str)    \
+do {                        \
+   assert(!str);            \
+   __assume(0);             \
+} while (0)
 #endif
 
 #ifndef unreachable
diff --git a/src/util/strtod.cpp b/src/util/strtod.cpp
new file mode 100644
index 0000000..2b4dd98
--- /dev/null
+++ b/src/util/strtod.cpp
@@ -0,0 +1,75 @@
+/*
+ * Copyright 2010 VMware, Inc.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL VMWARE AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+
+#include <stdlib.h>
+
+#ifdef _GNU_SOURCE
+#include <locale.h>
+#ifdef HAVE_XLOCALE_H
+#include <xlocale.h>
+#endif
+#endif
+
+#include "strtod.h"
+
+
+#if defined(_GNU_SOURCE) && defined(HAVE_XLOCALE_H)
+static struct locale_initializer {
+   locale_initializer() { loc = newlocale(LC_CTYPE_MASK, "C", NULL); }
+   locale_t loc;
+} loc_init;
+#endif
+
+/**
+ * Wrapper around strtod which uses the "C" locale so the decimal
+ * point is always '.'
+ */
+double
+_mesa_strtod(const char *s, char **end)
+{
+#if defined(_GNU_SOURCE) && defined(HAVE_XLOCALE_H)
+   return strtod_l(s, end, loc_init.loc);
+#else
+   return strtod(s, end);
+#endif
+}
+
+
+/**
+ * Wrapper around strtof which uses the "C" locale so the decimal
+ * point is always '.'
+ */
+float
+_mesa_strtof(const char *s, char **end)
+{
+#if defined(_GNU_SOURCE) && defined(HAVE_XLOCALE_H)
+   return strtof_l(s, end, loc_init.loc);
+#elif defined(HAVE_STRTOF)
+   return strtof(s, end);
+#else
+   return (float) strtod(s, end);
+#endif
+}
diff --git a/src/util/strtod.h b/src/util/strtod.h
new file mode 100644
index 0000000..02c25dd
--- /dev/null
+++ b/src/util/strtod.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright 2010 VMware, Inc.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL VMWARE AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+
+#ifndef STRTOD_H
+#define STRTOD_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+extern double
+_mesa_strtod(const char *s, char **end);
+
+extern float
+_mesa_strtof(const char *s, char **end);
+
+
+#ifdef __cplusplus
+}
+#endif
+
+
+#endif
